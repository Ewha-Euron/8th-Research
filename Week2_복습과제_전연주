{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rLFi-SV68cQI"
      ],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Positional Encoding 시각화\n"
      ],
      "metadata": {
        "id": "rLFi-SV68cQI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "rAbb8Y2A44ox",
        "outputId": "09edeb45-21c9-4bab-aa43-e6395f51f2d5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Positional Encoding\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # 위치값 생성(0~max_len -1 정수값)\n",
        "        position = torch.arange(max_len).unsqueeze(1) # (max_len, 1) 크기의 tensor\n",
        "\n",
        "        # 분모값 계산: 10000^(2i/d_model)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
        "        ) # (d_model / 2,) 크기의 텐서\n",
        "\n",
        "        # positional encoding 저장할 텐서 생성\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term) # 짝수 인덱스 (max_len, 1, d_model)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term) # 홀수 인덱스 (max_len, 1, d_model)\n",
        "        self.register_buffer(\"pe\", pe) # parameter 갱신 x 설정 but 모델과 함께 저장\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: s.size(0)]\n",
        "        return self.dropout\n",
        "\n",
        "encoding = PositionalEncoding(d_model=128, max_len=50)\n",
        "\n",
        "plt.pcolormesh(encoding.pe.numpy().squeeze(), cmap=\"RdBu\")\n",
        "plt.xlabel(\"Embedding Dimension\")\n",
        "plt.xlim((0,128))\n",
        "plt.ylabel(\"Position\")\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 실습"
      ],
      "metadata": {
        "id": "6YwlH6cd8j4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset 다운로드 및 전처리"
      ],
      "metadata": {
        "id": "Uyb2Pvuj82KT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03jhRQ9A_Nlm",
        "outputId": "6ecb2332-7c81-4544-cdb6-0e92c14b5e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch                              2.6.0+cu124\n",
            "torchaudio                         2.6.0+cu124\n",
            "torchsummary                       1.5.1\n",
            "torchvision                        0.21.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 대규모 dataset 다루기 쉽게 데이터 불러오기 & 변환 및 배치하는 API 제공\n",
        "!pip install torchdata portalocker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y7S9C4n8n0x",
        "outputId": "ec4198dd-7461-4c5c-d517-c704bd3b3fd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchdata\n",
            "  Downloading torchdata-0.11.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata) (2.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchdata) (2.32.3)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from torchdata) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2->torchdata)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2->torchdata)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2->torchdata)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2->torchdata)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2->torchdata)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2->torchdata)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2->torchdata)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2->torchdata)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2->torchdata)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2->torchdata)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2->torchdata) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2->torchdata) (3.0.2)\n",
            "Downloading torchdata-0.11.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: portalocker, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchdata\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 portalocker-3.1.1 torchdata-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.1.0+cu118 torchtext==0.16.0 --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "id": "845YaX6FAYbT",
        "outputId": "efafa4d6-b8e1-422a-aca6-cc54f21577e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.1.0+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp311-cp311-linux_x86_64.whl (2325.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m923.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.16.0\n",
            "  Downloading https://download.pytorch.org/whl/torchtext-0.16.0%2Bcpu-cp311-cp311-linux_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0+cu118) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0+cu118) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0+cu118) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0+cu118) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0+cu118) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0+cu118) (2024.10.0)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (2.0.2)\n",
            "Collecting torchdata==0.7.0 (from torchtext==0.16.0)\n",
            "  Downloading https://download.pytorch.org/whl/torchdata-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.0->torchtext==0.16.0) (2.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0+cu118) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0+cu118) (1.3.0)\n",
            "Installing collected packages: triton, torch, torchdata, torchtext\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.11.0\n",
            "    Uninstalling torchdata-0.11.0:\n",
            "      Successfully uninstalled torchdata-0.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.1.0+cu118 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.1.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.1.0+cu118 torchdata-0.7.0 torchtext-0.16.0+cpu triton-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "d6ad345e48f64bc080f28a4628dd7787"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import Multi30k # dataset\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzv4gpAm-2Ev",
        "outputId": "a16fc017-0f10-4d78-e756-8cc3147df430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-1-d0916040aab2>\", line 1, in <cell line: 0>\n",
            "    from torchtext.datasets import Multi30k # dataset\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchtext/__init__.py\", line 3, in <module>\n",
            "    from torch.hub import _get_torch_home\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1382, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 7, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download de_core_news_sm # 독일어 말뭉치\n",
        "!python -m spacy download en_core_web_sm # 영어 말뭉치"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZxTKaBUBQR8",
        "outputId": "904f6309-a183-488b-9025-8075b961848f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 148, in _get_module_details\n",
            "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/__init__.py\", line 6, in <module>\n",
            "    from .errors import setup_default_warnings\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/errors.py\", line 3, in <module>\n",
            "    from .compat import Literal\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/compat.py\", line 4, in <module>\n",
            "    from thinc.util import copy_array\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/__init__.py\", line 5, in <module>\n",
            "    from .config import registry\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/config.py\", line 5, in <module>\n",
            "    from .types import Decorator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/types.py\", line 25, in <module>\n",
            "    from .compat import cupy, has_cupy\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/compat.py\", line 35, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1382, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 7, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "Collecting de-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 148, in _get_module_details\n",
            "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/__init__.py\", line 6, in <module>\n",
            "    from .errors import setup_default_warnings\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/errors.py\", line 3, in <module>\n",
            "    from .compat import Literal\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/compat.py\", line 4, in <module>\n",
            "    from thinc.util import copy_array\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/__init__.py\", line 5, in <module>\n",
            "    from .config import registry\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/config.py\", line 5, in <module>\n",
            "    from .types import Decorator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/types.py\", line 25, in <module>\n",
            "    from .compat import cupy, has_cupy\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/compat.py\", line 35, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1382, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 7, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_tokens(text_iter, language):\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for text in text_iter:\n",
        "        yield token_transform[language](text[language_index[language]])\n",
        "\n",
        "SRC_LANGUAGE = \"de\"\n",
        "TGT_LANGUAGE = \"en\"\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
        "\n",
        "# get_tokenizer: 사용자가 지정한 tokenizer를 가져오는 utility 함수로, spaCy 라이브러리로 pretrained-model 가져옴\n",
        "token_transform = {\n",
        "    SRC_LANGUAGE: get_tokenizer(\"spacy\", language=\"de_core_news_sm\"),\n",
        "    TGT_LANGUAGE: get_tokenizer(\"spacy\", language=\"en_core_web_sm\"),\n",
        "}\n",
        "print(\"Token Transform:\")\n",
        "print(token_transform)\n",
        "\n",
        "# vocab_transform: token -> index 변환 함수 저장\n",
        "vocab_transform = {}\n",
        "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    train_iter = Multi30k(split=\"train\", language_pair = (SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    # build_vocab_from_iterator: 생성된 token 이용해 단어 집합 생성\n",
        "    vocab_transform[language] = build_vocab_from_iterator(\n",
        "        generate_tokens(train_iter, language),\n",
        "        min_freq = 1,\n",
        "        specials = special_symbols,\n",
        "        special_first = True, # speical token을 단어 집합의 맨 앞에 추가\n",
        "    )\n",
        "\n",
        "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    vocab_transform[language].set_default_index(UNK_IDX) # 어휘 사전에 없는 UNK_IDX 할당\n",
        "\n",
        "print(\"Vocab Transform:\")\n",
        "print(vocab_transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE-1zOzd8yGj",
        "outputId": "9cebf087-bba8-4687-b75e-329ebc515c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token Transform:\n",
            "{'de': functools.partial(<function _spacy_tokenize at 0x7cccba6ea2a0>, spacy=<spacy.lang.de.German object at 0x7ccca1d9a550>), 'en': functools.partial(<function _spacy_tokenize at 0x7cccba6ea2a0>, spacy=<spacy.lang.en.English object at 0x7ccca110ed90>)}\n",
            "Vocab Transform:\n",
            "{'de': Vocab(), 'en': Vocab()}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer 모델 구성"
      ],
      "metadata": {
        "id": "ORQarTchB24h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
        "        )\n",
        "\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term) # step=2\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "        # (embedding_size)를 곱하는 이유:\n",
        "        # Transformer에서는 임베딩 벡터의 크기가 클수록 값의 분산이 커지므로,\n",
        "        # 이를 조정하기 위해 임베딩 차원의 제곱근을 곱해줌.\n",
        "\n",
        "# TokenEmbedding 클래스로 소스 데이터 + 입력 데이터를 입력 임베딩으로 변환함(src_tok_emb, tgt_tok_emb)\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_encoder_layers,\n",
        "            num_decoder_layers,\n",
        "            emb_size,\n",
        "            max_len,\n",
        "            nhead,\n",
        "            src_vocab_size,\n",
        "            tgt_vocab_size,\n",
        "            dim_feedforward,\n",
        "            dropout=0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # 입력 토큰을 Transformer에 맞게 임베딩 변환\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            d_model = emb_size, max_len = max_len, dropout = dropout\n",
        "        )\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model = emb_size,\n",
        "            nhead = nhead,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        # 마지막 decoder에서 산출되는 벡터를 선형 변환해 어휘 사전에 대한 logit 생성\n",
        "        self.generator = nn.Linear(emb_size,tgt_vocab_size)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            src,\n",
        "            trg,\n",
        "            src_mask,\n",
        "            tgt_mask,\n",
        "            src_padding_mask,\n",
        "            tgt_padding_mask,\n",
        "            memory_key_padding_mask,\n",
        "    ):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        outs = self.transformer(\n",
        "            src=src_emb,\n",
        "            tgt=tgt_emb,\n",
        "            src_mask=src_mask,\n",
        "            tgt_mask=tgt_mask,\n",
        "            memory_mask = None,\n",
        "            src_key_padding_mask=src_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_padding_mask,\n",
        "            memory_key_padding_mask=memory_key_padding_mask,\n",
        "        )\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        return self.transformer.encoder(\n",
        "            self.positional_encoding(self.src_tok_emb(src)), src_mask\n",
        "        )\n",
        "\n",
        "    def decode(self, tgt, memory, tgt_mask):\n",
        "        return self.transformer.decoder(\n",
        "            self.positional_encoding(self.tgt_tok_emb(tgt)), tgt_mask\n",
        "        )"
      ],
      "metadata": {
        "id": "wWlPeL2S4BH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer 클래스"
      ],
      "metadata": {
        "id": "VPdvATpeDcp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = torch.nn.Transformer(\n",
        "    d_model = 512,\n",
        "    nhead=8,\n",
        "    num_encoder_layers=6,\n",
        "    num_decoder_layers=6,\n",
        "    dim_feedforward=2048, # 순방향 신경망의 은닉층 크기\n",
        "    dropout=0.1,\n",
        "    activation=torch.nn.functional.relu,\n",
        "    layer_norm_eps = 1e-05,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DNPnr3JD2Tz",
        "outputId": "6e8a39c5-9e88-4b55-daef-c51fee42b383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer 순방향 메서드"
      ],
      "metadata": {
        "id": "n3KOCtfRDS3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = transformer.forward(\n",
        "    # src, tgt: encoder에 대한 시퀀스 [소스(타깃) 시퀀스 길이, 배치 크기, 임베딩 차원]\n",
        "    src,\n",
        "    tgt,\n",
        "    # [소스(타깃) 시퀀스 길이, 시퀀스 길이] -inf로 마스킹된 위치 정보 무시\n",
        "    src_mask=None,\n",
        "    tgt_mask=None,\n",
        "    # 인코더 출력의 마스크 [tgt 시퀀스 길이, src 시퀀스 길이]\n",
        "    memory_mask=None,\n",
        "    # 패딩 token 위치한 부분 가리는 이진 마스크\n",
        "    src_key_padding_mask=None,\n",
        "    tgt_key_padding_mask=None,\n",
        "    memory_key_padding_mask=None,\n",
        ")"
      ],
      "metadata": {
        "id": "cIPF5bMwD2yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer 모델 구조"
      ],
      "metadata": {
        "id": "I1z4ew-BDhBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = Seq2SeqTransformer(\n",
        "    num_encoder_layers=3,\n",
        "    num_decoder_layers=3,\n",
        "    emb_size=512,\n",
        "    max_len=512,\n",
        "    nhead=8,\n",
        "    src_vocab_size=len(vocab_transform[SRC_LANGUAGE]),\n",
        "    tgt_vocab_size=len(vocab_transform[TGT_LANGUAGE]),\n",
        "    dim_feedforward=512,\n",
        ").to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE) # ignore_idx 값을 PAD_IDX에 할당 -> 무시해야 할 클래스 레이블 지정\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "for main_name, main_module in model.named_children():\n",
        "    print(main_name) # 상위 모듈\n",
        "    for sub_name, sub_module in main_module.named_children():\n",
        "        print(\"L\", sub_name) # 하위 모듈\n",
        "        for ssub_name, ssub_module in sub_module.named_children():\n",
        "            print(\"| L\", ssub_name) # 서브 모듈\n",
        "            for sssub_name, sssub_module in ssub_module.named_children():\n",
        "                print(\"| | L\", sssub_name) # 더 깊은 모듈"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifIrYlRXDrSe",
        "outputId": "a5fcc773-6be0-45e7-b171-35ede2e8e7f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_tok_emb\n",
            "L embedding\n",
            "tgt_tok_emb\n",
            "L embedding\n",
            "positional_encoding\n",
            "L dropout\n",
            "transformer\n",
            "L encoder\n",
            "| L layers\n",
            "| | L 0\n",
            "| | L 1\n",
            "| | L 2\n",
            "| L norm\n",
            "L decoder\n",
            "| L layers\n",
            "| | L 0\n",
            "| | L 1\n",
            "| | L 2\n",
            "| L norm\n",
            "generator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 배치 데이터 생성"
      ],
      "metadata": {
        "id": "FBnY_2mNDohu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# transform을 순차적으로 적용\n",
        "# token_transform, vocab_transform, input_transform\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# 입력 데이터에 시작(BOS), 종료(EOS) 토큰 추가\n",
        "def input_transform(token_ids):\n",
        "    return torch.cat(\n",
        "        (torch.tensor([BOS_IDX]), torch.tensor(token_ids), torch.tensor([EOS_IDX]))\n",
        "    )\n",
        "\n",
        "# mini-batch를 만들기 위한 collate 함수\n",
        "    \"\"\"\n",
        "    DataLoader에서 여러 샘플을 받아 하나의 배치로 변환.\n",
        "\n",
        "    Args:\n",
        "        batch: 리스트 형태 [(src_sentence, tgt_sentence), (src_sentence, tgt_sentence), ...]\n",
        "\n",
        "    Returns:\n",
        "        src_batch: 패딩된 소스 문장 텐서 (배치 크기, 시퀀스 길이)\n",
        "        tgt_batch: 패딩된 타겟 문장 텐서 (배치 크기, 시퀀스 길이)\n",
        "    \"\"\"\n",
        "def collator(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        # 개행 문자 제거 후 변환\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    # 패딩 추가해 시퀀스 길이 맞춤\n",
        "    src_batch = pad_sequence(src_batch, padding_value = PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch\n",
        "\n",
        "# 텍스트 변환\n",
        "text_transform = {}\n",
        "for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    \"\"\"\n",
        "    text_transform[language]는 다음 3가지 변환을 연속으로 수행:\n",
        "    1) 토큰화 (token_transform[language])\n",
        "    2) 단어를 정수 인덱스로 변환 (vocab_transform[language])\n",
        "    3) <bos>와 <eos> 추가 (input_transform)\n",
        "    \"\"\"\n",
        "    text_transform[language] = sequential_transforms(\n",
        "        token_transform[language], vocab_transform[language], input_transform\n",
        "    )\n",
        "\n",
        "data_iter = Multi30k(split=\"valid\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "dataloader = DataLoader(data_iter, batch_size=BATCH_SIZE, collate_fn=collator)\n",
        "source_tensor, target_tensor = next(iter(dataloader)) # 한 개의 batch dataset 불러오기\n",
        "\n",
        "print((\"(source, target):\"))\n",
        "print(next(iter(data_iter))) # 원본 데이터\n",
        "\n",
        "print((\"source_batch:\", source_tensor.shape))\n",
        "print(source_tensor) # 변환된 소스 배치\n",
        "\n",
        "print((\"target_batch:\", target_tensor.shape))\n",
        "print(target_tensor) # 변환된 타겟 배치"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnJFktTzDrt6",
        "outputId": "d048a87f-075d-4b6c-f99e-52d73b6536df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(source, target):\n",
            "('Eine Gruppe von Männern lädt Baumwolle auf einen Lastwagen', 'A group of men are loading cotton onto a truck')\n",
            "('source_batch:', torch.Size([35, 128]))\n",
            "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [  14,    5,    5,  ...,    5,   21,    5],\n",
            "        [  38,   12,   35,  ...,   12, 1750,   69],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]])\n",
            "('target_batch:', torch.Size([30, 128]))\n",
            "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
            "        [   6,    6,    6,  ...,  250,   19,    6],\n",
            "        [  39,   12,   35,  ...,   12, 3254,   61],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 어텐션 마스크 생성"
      ],
      "metadata": {
        "id": "u7pDLsSiDqDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_square_subsequent_mask(s):\n",
        "    mask = (torch.triu(torch.ones((s, s), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = (\n",
        "        mask.float()\n",
        "        .masked_fill(mask == 0, float(\"-inf\"))\n",
        "        .masked_fill(mask == 1, float(0.0))\n",
        "    )\n",
        "    return mask\n",
        "\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n",
        "\n",
        "\n",
        "target_input = target_tensor[:-1, :]\n",
        "target_out = target_tensor[1:, :]\n",
        "\n",
        "source_mask, target_mask, source_padding_mask, target_padding_mask = create_mask(\n",
        "    source_tensor, target_input\n",
        ")\n",
        "\n",
        "print(\"source_mask:\", source_mask.shape)\n",
        "print(source_mask)\n",
        "print(\"target_mask:\", target_mask.shape)\n",
        "print(target_mask)\n",
        "print(\"source_padding_mask:\", source_padding_mask.shape)\n",
        "print(source_padding_mask)\n",
        "print(\"target_padding_mask:\", target_padding_mask.shape)\n",
        "print(target_padding_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_WYQi6dDvKD",
        "outputId": "7c8441be-ae24-4e9d-a18d-462ef2f99b35"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source_mask: torch.Size([35, 35])\n",
            "tensor([[False, False, False,  ..., False, False, False],\n",
            "        [False, False, False,  ..., False, False, False],\n",
            "        [False, False, False,  ..., False, False, False],\n",
            "        ...,\n",
            "        [False, False, False,  ..., False, False, False],\n",
            "        [False, False, False,  ..., False, False, False],\n",
            "        [False, False, False,  ..., False, False, False]], device='cuda:0')\n",
            "target_mask: torch.Size([29, 29])\n",
            "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0.]], device='cuda:0')\n",
            "source_padding_mask: torch.Size([128, 35])\n",
            "tensor([[False, False, False,  ...,  True,  True,  True],\n",
            "        [False, False, False,  ...,  True,  True,  True],\n",
            "        [False, False, False,  ...,  True,  True,  True],\n",
            "        ...,\n",
            "        [False, False, False,  ...,  True,  True,  True],\n",
            "        [False, False, False,  ...,  True,  True,  True],\n",
            "        [False, False, False,  ...,  True,  True,  True]])\n",
            "target_padding_mask: torch.Size([128, 29])\n",
            "tensor([[False, False, False,  ...,  True,  True,  True],\n",
            "        [False, False, False,  ...,  True,  True,  True],\n",
            "        [False, False, False,  ...,  True,  True,  True],\n",
            "        ...,\n",
            "        [False, False, False,  ...,  True,  True,  True],\n",
            "        [False, False, False,  ...,  True,  True,  True],\n",
            "        [False, False, False,  ...,  True,  True,  True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 학습 및 평가"
      ],
      "metadata": {
        "id": "0rgbhxPXDvf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run(model, optimizer, criterion, split):\n",
        "    model.train() if split == \"train\" else model.eval()\n",
        "    data_iter = Multi30k(split=split, language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    dataloader = DataLoader(data_iter, batch_size=BATCH_SIZE, collate_fn=collator)\n",
        "\n",
        "    losses = 0\n",
        "    for source_batch, target_batch in dataloader:\n",
        "        source_batch = source_batch.to(DEVICE)\n",
        "        target_batch = target_batch.to(DEVICE)\n",
        "\n",
        "        target_input = target_batch[:-1, :]\n",
        "        target_output = target_batch[1:, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(\n",
        "            source_batch, target_input\n",
        "        )\n",
        "\n",
        "        logits = model(\n",
        "            src=source_batch,\n",
        "            trg=target_input,\n",
        "            src_mask=src_mask,\n",
        "            tgt_mask=tgt_mask,\n",
        "            src_padding_mask=src_padding_mask,\n",
        "            tgt_padding_mask=tgt_padding_mask,\n",
        "            memory_key_padding_mask=src_padding_mask,\n",
        "        )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(logits.reshape(-1, logits.shape[-1]), target_output.reshape(-1))\n",
        "        if split == \"train\":\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(dataloader))\n",
        "\n",
        "\n",
        "for epoch in range(5):\n",
        "    train_loss = run(model, optimizer, criterion, \"train\")\n",
        "    val_loss = run(model, optimizer, criterion, \"valid\")\n",
        "    print(f\"Epoch: {epoch+1}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_--zzhiXDyH9",
        "outputId": "9f07d24d-1edf-4fc3-8802-385c02388f2f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/datapipes/iter/combining.py:333: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train loss: 2.391, Val loss: 3.718\n",
            "Epoch: 2, Train loss: 2.360, Val loss: 3.735\n",
            "Epoch: 3, Train loss: 2.328, Val loss: 3.737\n",
            "Epoch: 4, Train loss: 2.295, Val loss: 3.762\n",
            "Epoch: 5, Train loss: 2.262, Val loss: 3.815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer 모델 번역 결과\n",
        "## 아무리 노력해도 안되더라.."
      ],
      "metadata": {
        "id": "10aH8_ivDycO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode(model, source_tensor, source_mask, max_len, start_symbol):\n",
        "    source_tensor = source_tensor.to(DEVICE)\n",
        "    source_mask = source_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(source_tensor, source_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len - 1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        target_mask = generate_square_subsequent_mask(ys.size(0))\n",
        "        target_mask = target_mask.type(torch.bool).to(DEVICE)\n",
        "\n",
        "        out = model.decode(ys, memory, target_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat(\n",
        "            [ys, torch.ones(1, 1).type_as(source_tensor.data).fill_(next_word)], dim=0\n",
        "        )\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "\n",
        "def translate(model, source_sentence):\n",
        "    model.eval()\n",
        "    source_tensor = text_transform[SRC_LANGUAGE](source_sentence).view(-1, 1)\n",
        "    num_tokens = source_tensor.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model, source_tensor, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX\n",
        "    ).flatten()\n",
        "    output = vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))[1:-1]\n",
        "    return \" \".join(output)\n",
        "\n",
        "\n",
        "output_oov = translate(model, \"Eine Gruppe von Menschen steht vor einem Iglu .\")\n",
        "output = translate(model, \"Eine Gruppe von Menschen steht vor einem Gebäude .\")\n",
        "print(output_oov)\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "oApudpQ6D1Fw",
        "outputId": "b2473700-2895-47ef-9322-bc0b51df4c31"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "For batched (3-D) `query`, expected `key` and `value` to be 3-D but found 2-D and 2-D tensors respectively",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-e99d7f2bad14>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0moutput_oov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Eine Gruppe von Menschen steht vor einem Iglu .\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Eine Gruppe von Menschen steht vor einem Gebäude .\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_oov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-e99d7f2bad14>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(model, source_sentence)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mnum_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     tgt_tokens = greedy_decode(\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_tokens\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_symbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBOS_IDX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     ).flatten()\n",
            "\u001b[0;32m<ipython-input-55-e99d7f2bad14>\u001b[0m in \u001b[0;36mgreedy_decode\u001b[0;34m(model, source_tensor, source_mask, max_len, start_symbol)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtarget_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-cd5cfaaf21cd>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, tgt, memory, tgt_mask)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         return self.transformer.decoder(\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_tok_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             output = mod(output, memory, tgt_mask=tgt_mask,\n\u001b[0m\u001b[1;32m    461\u001b[0m                          \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                          \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_is_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mha_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_is_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_mha_block\u001b[0;34m(self, x, mem, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    863\u001b[0m     def _mha_block(self, x: Tensor, mem: Tensor,\n\u001b[1;32m    864\u001b[0m                    attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: bool = False) -> Tensor:\n\u001b[0;32m--> 865\u001b[0;31m         x = self.multihead_attn(x, mem, mem,\n\u001b[0m\u001b[1;32m    866\u001b[0m                                 \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m                                 \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 is_causal=is_causal)\n\u001b[1;32m   1240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1242\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5225\u001b[0m         )\n\u001b[1;32m   5226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5227\u001b[0;31m     \u001b[0mis_batched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mha_shape_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5229\u001b[0m     \u001b[0;31m# For unbatched input, we unsqueeze at the expected batch-dim to pretend that the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_mha_shape_check\u001b[0;34m(query, key, value, key_padding_mask, attn_mask, num_heads)\u001b[0m\n\u001b[1;32m   5020\u001b[0m         \u001b[0;31m# Batched Inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5021\u001b[0m         \u001b[0mis_batched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5022\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5023\u001b[0m             (\"For batched (3-D) `query`, expected `key` and `value` to be 3-D\"\n\u001b[1;32m   5024\u001b[0m              f\" but found {key.dim()}-D and {value.dim()}-D tensors respectively\")\n",
            "\u001b[0;31mAssertionError\u001b[0m: For batched (3-D) `query`, expected `key` and `value` to be 3-D but found 2-D and 2-D tensors respectively"
          ]
        }
      ]
    }
  ]
}
