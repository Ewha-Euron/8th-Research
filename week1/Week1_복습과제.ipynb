{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJZL1CWTfId9"
      },
      "source": [
        "### 필요한 라이브러리 호출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_WaSDywQd3AN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "\n",
        "device = torch.device('cuda' if  torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_T2e3PHfC3I"
      },
      "source": [
        "### 이미지 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIiwmGy_e8FI"
      },
      "outputs": [],
      "source": [
        "class ImageTransform():\n",
        "    def __init__(self, resize, mean, std):\n",
        "        self.data_transform = {\n",
        "            'train': transforms.Compose([\n",
        "                transforms.RandomResizedCrop(resize, scale = (0.5, 1.0)),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ]), \n",
        "            'val': transforms.Compose([\n",
        "                transforms.Resize(256),\n",
        "                transforms.CenterCrop(resize),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std)\n",
        "            ]), \n",
        "        }\n",
        "\n",
        "    def __call__(self, img, phase):\n",
        "        return self.data_transform[phase](img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 변수에 대한 값 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vk3xWaMafAHO"
      },
      "outputs": [],
      "source": [
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUor0PA-gGWJ"
      },
      "source": [
        "### 훈련과 테스트 데이터셋 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4wxOQAugESk"
      },
      "outputs": [],
      "source": [
        "cat_directory = r'../chap06/data/dogs-vs-cats/Cat'\n",
        "dog_directory = r'../chap06/data/dogs-vs-cats/Dog'\n",
        "\n",
        "cat_images_filepaths = sorted([os.path.join(cat_directory, f) for f in os.listdir(cat_directory)])\n",
        "dog_images_filepaths = sorted([os.path.join(dog_directory, f) for f in os.listdir(dog_directory)])\n",
        "\n",
        "images_filepaths = [*cat_images_filepaths, *dog_images_filepaths]\n",
        "correct_images_filepaths = [i for i in images_filepaths if cv2.imread(i) is not None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 데이터셋을 훈련, 검증, 테스트 용도로 분리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbS991d_mFfn",
        "outputId": "0600f838-8755-413a-d9eb-f240f7c03096"
      },
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "random.shuffle(correct_images_filepaths)\n",
        "train_images_filepaths = correct_images_filepaths[:400]\n",
        "val_images_filepaths = correct_images_filepaths[400:-10]\n",
        "test_images_filepaths = correct_images_filepaths[-10:]\n",
        "print(len(train_images_filepaths), len(val_images_filepaths),\n",
        "      len(test_images_filepaths))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 이미지에 대한 레이블 구분"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYElYi73mOcW"
      },
      "outputs": [],
      "source": [
        "class DogvsCatDataset(Dataset):\n",
        "    def __init__(self, file_list, transform = None, phase = 'train'):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "        self.phase = phase\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.file_list[idx]\n",
        "        img = Image.open(img_path)\n",
        "        img_transformed = self.transform(img, self.phase)\n",
        "\n",
        "        label = img_path.split('/')[-1].split('.')[0]\n",
        "        if label == 'dog':\n",
        "            label = 1\n",
        "        elif label == 'cat':\n",
        "            label = 0\n",
        "        return img_transformed, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 이미지 데이터셋 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD4t5Uhtodoy",
        "outputId": "3709ab7a-a18b-444e-b37c-188b0b8af8a3"
      },
      "outputs": [],
      "source": [
        "train_dataset = DogvsCatDataset(train_images_filepaths, transform = ImageTransform(size, mean, std), phase = 'train')\n",
        "val_dataset = DogvsCatDataset(val_images_filepaths, transform = ImageTransform(size, mean, std), phase = 'val')\n",
        "\n",
        "index = 0\n",
        "print(train_dataset.__getitem__(index)[0].size())\n",
        "print(train_dataset.__getitem__(index)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 데이터셋의 데이터를 메모리로 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPbirxd7o-kt",
        "outputId": "b22a5608-586e-4688-c3de-8c8bd1279e52"
      },
      "outputs": [],
      "source": [
        "train_iterator = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "valid_iterator = DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n",
        "dataloader_dict = {'train': train_iterator, 'val': valid_iterator}\n",
        "\n",
        "batch_iterator = iter(train_iterator)\n",
        "inputs, label = next(iter(train_iterator))\n",
        "print(inputs.size())\n",
        "print(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XWPuyLEpvxd"
      },
      "source": [
        "### 기본 블록 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ixPax5Vpu_v"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=False):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride=stride, padding=1, bias=False) # 3x3 Conv\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, kernel_size = 3, stride=stride, padding=1, bias=False) # 3x3 Conv\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "\n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride=stride, bias=False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        i = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "\n",
        "        x += I \n",
        "        x = self.relu(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApsiUeIIpx2E"
      },
      "source": [
        "### 병목 블록 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PddS5mzpxgH"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4 \n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=False):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False) # 1x1 conv\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False) # 3x3 conv\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(out_channels, self.expansion*out_channels, kernel_size=1, stride=1, bias = False)\n",
        "\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        if downsample:\n",
        "            conv = nn. Conv2d(in_channels, self.expansion*out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "            bn = nn.BatchNorm2d(self.expansion*out_channels)\n",
        "            downsample = nn. Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        i = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "\n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEa7u2YUp145"
      },
      "source": [
        "### ResNet 모델 네트워크"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R_wuk30p5J3"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, config, output_dim, zero_init_residual = False):\n",
        "        super().__init__()\n",
        "\n",
        "        block, n_blocks, channels = config \n",
        "        self.in_channels = channels[0]\n",
        "        assert len(n_blocks) == len(channels) == 4 \n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn. ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1])\n",
        "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2])\n",
        "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3])\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "\n",
        "       \n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride=1): \n",
        "        layers = []\n",
        "        if self.in_channels != block.expansion * channels: \n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "\n",
        "        \n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(block.expansion*channels, channels))\n",
        "\n",
        "        self.in_channels = block.expansion * channels\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x) \n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x) # 112x112\n",
        "        x = self.layer1(x) # 56x56\n",
        "        x = self.layer2(x) # 28x28\n",
        "        x = self.layer3(x) # 14x14\n",
        "        x = self.layer4(x) # 7x7\n",
        "        x = self.avgpool(x) # 1x1\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "        return x, h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wr7vCTsp5hh"
      },
      "source": [
        "### ResNetConfig 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "rCvAtKRLp_jB"
      },
      "outputs": [],
      "source": [
        "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 기본 블록을 사용해 ResNetConfig 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klKEv_ZyBsLi"
      },
      "outputs": [],
      "source": [
        "resnet18_config = ResNetConfig(block = BasicBlock,\n",
        "                               n_blocks=[2,2,2,2],\n",
        "                               channels=[64,128,256,512])\n",
        "\n",
        "resnet34_config = ResNetConfig(block = BasicBlock,\n",
        "                               n_blocks=[3,4,6,3],\n",
        "                               channels=[64,128,256,512])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### bottleneck 블록을 사용하여 ResNetConfig 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XmEc914CCMK"
      },
      "outputs": [],
      "source": [
        "resnet50_config = ResNetConfig(block = Bottleneck,\n",
        "                               n_blocks=[3,4,6,3],\n",
        "                               channels=[64,128,256,512])\n",
        "\n",
        "resnet101_config = ResNetConfig(block = Bottleneck,\n",
        "                               n_blocks=[3,4,23,3],\n",
        "                               channels=[64,128,256,512])\n",
        "\n",
        "resnet152_config = ResNetConfig(block = Bottleneck,\n",
        "                               n_blocks=[3,8,36,3],\n",
        "                               channels=[64,128,256,512])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw-9h7QtqAA6"
      },
      "source": [
        "### Pre-trained ResNet 모델 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3fw6QvlqEOI",
        "outputId": "5fa483ae-3d15-404a-e989-92a4f08b02a9"
      },
      "outputs": [],
      "source": [
        "pretrained_model = models.resnet50(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hA08oLlCazi",
        "outputId": "2af6aafe-2ca8-4b9c-a16a-9c4d0e0b89c1"
      },
      "outputs": [],
      "source": [
        "print(pretrained_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXOoCa9vqEej"
      },
      "source": [
        "### ResNet50 Config를 사용한 ResNet 모델 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9131if0dqJfD",
        "outputId": "d644517a-37da-4bc4-e40a-e796b9032c9a"
      },
      "outputs": [],
      "source": [
        "OUTPUT_DIM = 2 # 두 개의 class\n",
        "model = ResNet(resnet50_config, OUTPUT_DIM)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoFZccyXqJxS"
      },
      "source": [
        "### 옵티마이저와 손실 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "XUEI4OkFqOxs"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-7)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-S6Z1C2qO-d"
      },
      "source": [
        "### 모델 학습 정확도 측정 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tU3Ys7JYqSLn"
      },
      "outputs": [],
      "source": [
        "def calculate_topk_accuracy(y_pred, y, k=2):\n",
        "    with torch.no_grad():\n",
        "        batch_size = y.shape[0]\n",
        "        _, top_pred = y_pred.topk(k, 1) \n",
        "        top_pred = top_pred.t() \n",
        "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred)) \n",
        "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim=True)\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "        acc_1 = correct_1 / batch_size\n",
        "        acc_k = correct_k / batch_size\n",
        "    return acc_1, acc_k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miYU8fy8qSr4"
      },
      "source": [
        "### 모델 학습 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JS8DGemGqVPP"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, scheduler, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc_1 = 0\n",
        "    epoch_acc_5 = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for (x, y) in iterator:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)\n",
        "        loss = criterion(y_pred[0], y)\n",
        "\n",
        "        acc_1, acc_5 = calculate_topk_accuracy(y_pred[0], y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc_1 += acc_1.item() \n",
        "        epoch_acc_5 += acc_5.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc_1 /= len(iterator)\n",
        "    epoch_acc_5 /= len(iterator)\n",
        "    return epoch_loss, epoch_acc_1, epoch_acc_5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G16khJusqUsm"
      },
      "source": [
        "### 모델 평가 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "UV9LrUcHqXvG"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc_1 = 0\n",
        "    epoch_acc_5 = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (x, y) in iterator:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            y_pred = model(x)\n",
        "            loss = criterion(y_pred[0], y)\n",
        "\n",
        "            acc_1, acc_5 = calculate_topk_accuracy(y_pred[0], y)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc_1 += acc_1.item()\n",
        "            epoch_acc_5 += acc_5.item()\n",
        "\n",
        "        epoch_loss /= len(iterator)\n",
        "        epoch_acc_1 /= len(iterator)\n",
        "        epoch_acc_5 /= len(iterator)\n",
        "        return epoch_loss, epoch_acc_1, epoch_acc_5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSmm_-CMqsDk"
      },
      "source": [
        "### 모델 학습 시간 측정 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "oWecRnitquGr"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elasped_time = end_time - start_time\n",
        "    elasped_mins = int(elasped_time/60)\n",
        "    elasped_secs = int(elasped_time-(elasped_mins*60))\n",
        "    return elasped_mins, elasped_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBNMMAY8qXVw"
      },
      "source": [
        "### 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "DZatvW-mH5Bl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O7DxgNCcqecQ",
        "outputId": "bee5ada5-373c-466b-ff17-8e3cd477841f"
      },
      "outputs": [],
      "source": [
        "best_valid_loss = float('inf')\n",
        "EPOCHS = 50\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start_time = time.monotonic()\n",
        "\n",
        "    train_loss, train_acc_1, train_acc_5 = train(model, train_iterator, optimizer,\n",
        "                                                 criterion, scheduler, device)\n",
        "    val_loss, val_acc_1, val_acc_5 = evaluate(model, valid_iterator,\n",
        "                                                 criterion, device)\n",
        "\n",
        "    if val_loss < best_valid_loss:\n",
        "        best_valid_loss = best_valid_loss\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/ResNet-model.pt')\n",
        "\n",
        "    end_time = time.monotonic()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc @1: {train_acc_1*100:6.2f}% | '\n",
        "        f'Train Acc @5: {train_acc_5*100:6.2f}%')\n",
        "\n",
        "    print(f'\\tValid Loss: {val_loss:.3f} | Valid Acc @1: {val_acc_1*100:6.2f}% | '\n",
        "        f'Valid Acc @5: {val_acc_5*100:6.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx8lxp-Dqes-"
      },
      "source": [
        "### 테스트 데이터셋을 이용한 모델 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "t2QZ3QZjqi3i",
        "outputId": "5b630dcf-4e0c-4148-c329-b32052ff205f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "id_list = []\n",
        "pred_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for test_path in test_images_filepaths:\n",
        "        img = Image.open(test_path)\n",
        "        _id = test_path.split('/')[-1].split('.')[1] \n",
        "        transform = ImageTransform(size, mean, std)\n",
        "        img = transform(img, phase='val')\n",
        "        img = img.unsqueeze(0)\n",
        "        img = img.to(device)\n",
        "\n",
        "        model.eval()\n",
        "        outputs = model(img)\n",
        "        preds = F.softmax(outputs[0], dim=1)[:, 1].tolist()\n",
        "\n",
        "        id_list.append(_id)\n",
        "        pred_list.append(preds[0])\n",
        "\n",
        "res = pd.DataFrame({\n",
        "    'id': id_list,\n",
        "    'label': pred_list\n",
        "})\n",
        "\n",
        "res.sort_values(by='id', inplace=True)\n",
        "res.reset_index(drop=True, inplace=True)\n",
        "\n",
        "res.to_csv('/content/drive/MyDrive/ResNet.csv', index=False)\n",
        "res.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3vxTV6xqjG1"
      },
      "source": [
        "### 모델 예측에 대한 결과 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "NLo1jGS0ql6v",
        "outputId": "20076fc9-16b5-47c6-ef8f-b45dba292419"
      },
      "outputs": [],
      "source": [
        "classes = {0: 'cat', 1: 'dog'}\n",
        "\n",
        "def display_image_grid(images_filepaths, predicted_labels=(), cols=5):\n",
        "    rows = len(images_filepaths) // cols\n",
        "    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n",
        "\n",
        "    for i, image_filepath in enumerate(images_filepaths):\n",
        "        image = cv2.imread(image_filepath)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        a = random.choice(res['id'].values)\n",
        "        label = res.loc[res['id'] == a, 'label'].values[0]\n",
        "\n",
        "        if label > 0.5:\n",
        "            label = 1\n",
        "        else:\n",
        "            label = 0\n",
        "\n",
        "        ax.ravel()[i].imshow(image)\n",
        "        ax.ravel()[i].set_title(classes[label])\n",
        "        ax.ravel()[i].set_axis_off()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "display_image_grid(test_images_filepaths)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
