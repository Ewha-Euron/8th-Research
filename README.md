# ğŸ“ARCHIVE - 2025/04/29

## ğŸ’šë°œì œ ë…¼ë¬¸ğŸ’š  
- [CV] [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/pdf/2010.11929)
- [NLP] [BERT: Pre-training of Deep Bidirectional Transformers for
Language Understanding](https://arxiv.org/pdf/1810.04805)
---

## ğŸ’šë°œí‘œ ìë£ŒğŸ’š
- [ğŸ“šWeek8_1_ê¹€ì§€ì€](https://github.com/user-attachments/files/19940092/Research_ViT.pdf)
- [ğŸ“šWeek8_2_ê¹€ë‚˜í˜„](https://github.com/user-attachments/files/19940098/Week8_BERT_.pdf)


---

## ğŸ’šìš°ìˆ˜ ê³¼ì œğŸ’š
#### 8ì£¼ì°¨ ì˜ˆìŠµê³¼ì œ
- [ğŸŒŸWeek8_1_ì „ì˜ˆì§€](https://github.com/yejiida/-Euron-8th_Research/blob/8a7c715ddde4e94545c4e1e0e00dd60d3258d7ee/%5BEuron%5D%208week_BERT%20_%20Pre-training%20of%20Deep%20Transformers%20for%20Language%20Understanding.pdf)
- [ğŸŒŸWeek8_2_ê°•ë¯¼ì •](https://ionized-fortnight-fd6.notion.site/BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding-1e399124e3fb8087aec7cb44aef83ba3?pvs=4)
#### 5ì£¼ì°¨ ë³µìŠµê³¼ì œ
- [ğŸŒŸWeek5_3_ê¹€ë‚˜í˜„](https://github.com/nuyhan55/8th-Research/blob/ef46d954b1ffea32bbe5f589ca06c1b19e215399/Week5_%EB%B3%B5%EC%8A%B5%EA%B3%BC%EC%A0%9C_%EA%B9%80%EB%82%98%ED%98%84.ipynb)
- [ğŸŒŸWeek5_4_ê°•ë¯¼ì •](https://github.com/minjeon99/8th-Research/blob/b233d79154e4ed45c5544719c596344fa8943694/Week5_%EB%B3%B5%EC%8A%B5%EA%B3%BC%EC%A0%9C_%EA%B0%95%EB%AF%BC%EC%A0%95.ipynb)
