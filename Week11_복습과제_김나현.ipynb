{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Swin Transformer Pytorch**\n",
        "\n",
        "- 깃허브 : [주소](https://github.com/berniwal/swin-transformer-pytorch)"
      ],
      "metadata": {
        "id": "HY5NCPUrWA7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 패키지 설치\n",
        "# einops : tensor 재구성 유틸리티\n",
        "# timm : vision model 모음 패키\n",
        "!pip install einops timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7rNfpKq7xZO",
        "outputId": "cddb6107-882c-4d0c-84b6-ee8551454cf6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.31.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->timm)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# github 저장소 클론\n",
        "!git clone https://github.com/berniwal/swin-transformer-pytorch.git\n",
        "%cd swin-transformer-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyvwJH9h7x5E",
        "outputId": "0b4adb7a-ed3d-4b2a-b49b-074dd25fcb0f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'swin-transformer-pytorch'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 80 (delta 39), reused 62 (delta 21), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (80/80), 194.66 KiB | 4.75 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n",
            "/content/swin-transformer-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# swin_transformer.py\n",
        "import torch\n",
        "from torch import nn, einsum\n",
        "import numpy as np\n",
        "from einops import rearrange, repeat\n",
        "\n",
        "\n",
        "## Cyclic Shift : shifted 윈도우 구현을 위한 cyclic roll - 패치를 반칸씩 옮길 때 사용\n",
        "class CyclicShift(nn.Module):\n",
        "    def __init__(self, displacement):\n",
        "        super().__init__()\n",
        "        self.displacement = displacement # 이동할 픽셀 수 (절반 window_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (B, H, W, C) 형태의 텐서를 H/W 방향으로 cyclic shift\n",
        "        return torch.roll(x, shifts=(self.displacement, self.displacement), dims=(1, 2))\n",
        "\n",
        "\n",
        "\n",
        "# Residual / PreNorm / FeedForward: Transformer 기본 블록 구성 요소\n",
        "## Residual - skip connection\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(x, **kwargs) + x  # 잔차 연결\n",
        "\n",
        "## PreNorm - LayerNorm → 함수 순서로 stability 확보\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "## FeedForward - MLP (dim → hidden_dim → dim)\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # 두 개의 선형 레이어와 GELU 활성화\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "# Mask 생성 및 상대 위치 인덱스 계산 유틸리티\n",
        "## create_mask 함수 - shifted window 시 경계 간 attention 차단(윈도우 내에서만 계)\n",
        "def create_mask(window_size, displacement, upper_lower, left_right):\n",
        "    # (M^2, M^2) 형태의 mask 텐서. -inf 할당으로 attention 차단\n",
        "    mask = torch.zeros(window_size ** 2, window_size ** 2)\n",
        "\n",
        "    if upper_lower:\n",
        "        # 상하 블록끼리 attention 못 하게 마스킹\n",
        "        mask[-displacement * window_size:, :-displacement * window_size] = float('-inf')\n",
        "        mask[:-displacement * window_size, -displacement * window_size:] = float('-inf')\n",
        "\n",
        "    if left_right:\n",
        "        # 좌우 블록끼리 attention 못 하게 마스킹\n",
        "        mask = rearrange(mask, '(h1 w1) (h2 w2) -> h1 w1 h2 w2', h1=window_size, h2=window_size)\n",
        "        mask[:, -displacement:, :, :-displacement] = float('-inf')\n",
        "        mask[:, :-displacement, :, -displacement:] = float('-inf')\n",
        "        mask = rearrange(mask, 'h1 w1 h2 w2 -> (h1 w1) (h2 w2)')\n",
        "\n",
        "    return mask\n",
        "\n",
        "## get_relative_distances 함수 - 상대적 좌표 차 계산 (pos bias 용)\n",
        "def get_relative_distances(window_size):\n",
        "    # M^2 x 2 좌표 인덱스 생성 → (M^2, M^2, 2) shape의 거리 텐서 반환\n",
        "    indices = torch.tensor(np.array([ [x, y] for x in range(window_size) for y in range(window_size)]))\n",
        "    distances = indices[None, :, :] - indices[:, None, :]\n",
        "    return distances\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## WindowAttention - local window self-attention + shifted window 구현\n",
        "class WindowAttention(nn.Module):\n",
        "    def __init__(self, dim, heads, head_dim, shifted, window_size, relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        inner_dim = head_dim * heads\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        self.window_size = window_size\n",
        "        self.relative_pos_embedding = relative_pos_embedding\n",
        "        self.shifted = shifted\n",
        "\n",
        "        # shifted window의 경우 cyclic shift와 boundary mask 준비\n",
        "        if self.shifted:\n",
        "            displacement = window_size // 2\n",
        "            self.cyclic_shift = CyclicShift(-displacement)\n",
        "            self.cyclic_back_shift = CyclicShift(displacement)\n",
        "            self.upper_lower_mask = nn.Parameter(create_mask(window_size=window_size, displacement=displacement,\n",
        "                                                             upper_lower=True, left_right=False), requires_grad=False)\n",
        "            self.left_right_mask = nn.Parameter(create_mask(window_size=window_size, displacement=displacement,\n",
        "                                                            upper_lower=False, left_right=True), requires_grad=False)\n",
        "\n",
        "            # Q, K, V projection\n",
        "            self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
        "\n",
        "            # 위치 바이어스\n",
        "            if self.relative_pos_embedding:\n",
        "                # (2M-1, 2M-1) 크기의 learnable bias\n",
        "                self.relative_indices = get_relative_distances(window_size) + window_size - 1\n",
        "                self.pos_embedding = nn.Parameter(torch.randn(2 * window_size - 1, 2 * window_size - 1))\n",
        "            else:\n",
        "                # (M^2, M^2) 크기 absolute pos embedding\n",
        "                self.pos_embedding = nn.Parameter( torch.randn(window_size **2, window_size **2))\n",
        "\n",
        "            self.to_out = nn.Linear(inner_dim, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, H, W, C)\n",
        "        if self.shifted:\n",
        "            x = self.cyclic_shift(x)  # cyclic shift 적용\n",
        "\n",
        "        b, n_h, n_w, _, h = *x.shape, self.heads\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=-1)  # Q, K, V 분할\n",
        "\n",
        "        # 윈도우 단위로 reshape\n",
        "        nw_h = n_h // self.window_size\n",
        "        nw_w = n_w // self.window_size\n",
        "\n",
        "        q, k, v = map(\n",
        "            lambda t: rearrange(t, 'b (nw_h w_h) (nw_w w_w) (h d) -> b h (nw_h nw_w) (w_h w_w) d',\n",
        "                                h=h, w_h=self.window_size, w_w=self.window_size), qkv)\n",
        "\n",
        "        # scaled dot-product attention\n",
        "        dots = einsum('b h w i d, b h w j d -> b h w i j', q, k) * self.scale\n",
        "\n",
        "\n",
        "        # 위치 바이어스 더하기\n",
        "        if self.relative_pos_embedding:\n",
        "            dots += self.pos_embedding[self.relative_indices[:, :, 0], self.relative_indices[:, :, 1]]\n",
        "        else:\n",
        "            dots += self.pos_embedding\n",
        "\n",
        "        # shifted window mask 적용 (윈도우 간 attention 차단)\n",
        "        if self.shifted:\n",
        "            dots[:, :, -nw_w:] += self.upper_lower_mask\n",
        "            dots[:, :, nw_w - 1::nw_w] += self.left_right_mask\n",
        "\n",
        "        attn = dots.softmax(dim=-1)\n",
        "\n",
        "        # attention 결과와 V 결합\n",
        "        out = einsum('b h w i j, b h w j d -> b h w i d', attn, v)\n",
        "        out = rearrange(out, 'b h (nw_h nw_w) (w_h w_w) d -> b (nw_h w_h) (nw_w w_w) (h d)',\n",
        "                        h=h, w_h=self.window_size, w_w=self.window_size, nw_h=nw_h, nw_w=nw_w)\n",
        "        out = self.to_out(out)\n",
        "\n",
        "        if self.shifted:\n",
        "            out = self.cyclic_back_shift(out)  # 원위치 복구\n",
        "        return out"
      ],
      "metadata": {
        "id": "rNE6VYh7NNXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## SwinBlock - 하나의 Transformer block\n",
        "#    - PreNorm → WindowAttention (regular or shifted) → Residual\n",
        "#    - PreNorm → FeedForward → Residual\n",
        "class SwinBlock(nn.Module):\n",
        "    def __init__(self, dim, heads, head_dim, mlp_dim, shifted, window_size, relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.attention_block = Residual(PreNorm(dim, WindowAttention(dim=dim,\n",
        "                                                                     heads=heads,\n",
        "                                                                     head_dim=head_dim,\n",
        "                                                                     shifted = shifted,\n",
        "                                                                     window_size=window_size,\n",
        "                                                                     relative_pos_embedding=relative_pos_embedding)))\n",
        "        self.mlp_block = Residual(PreNorm(dim, FeedForward(dim, mlp_dim)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.attention_block(x)\n",
        "        x = self.mlp_block(x)\n",
        "        return x\n",
        "\n",
        "## PatchMergeing - CNN의 stride=2와 유사한 다운샘플링\n",
        "#    - 2×2 패치를 한 토큰으로 병합 → 채널 수 4배 → Linear projection\n",
        "#    - 해상도는 1/2, 토큰 수는 1/4로 줄어듦.\n",
        "class PatchMerging(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downscaling_factor):\n",
        "        super().__init__()\n",
        "        self.downscaling_factor = downscaling_factor\n",
        "        self.patch_merge = nn.Unfold(kernel_size=downscaling_factor, stride=downscaling_factor, padding=0)\n",
        "        self.linear = nn.Linear(in_channels * downscaling_factor ** 2, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, C, H, W)\n",
        "        b, c, h, w = x.shape\n",
        "        x = self.patch_merge(x)\n",
        "        new_h, new_w = h // self.downscaling_factor, w // self.downscaling_factor\n",
        "        # Unfold → (B, C*fs^2, new_h*new_w) → reshape\n",
        "        x = self.patch_merge(x).view(b, -1, new_h, new_w).permute(0, 2, 3, 1)\n",
        "        x = self.linear(x)  # 채널 수 projection\n",
        "        return x\n",
        "\n",
        "## StageModule - Swin의 한 스테이지(계층)\n",
        "#    - PatchMerging → (Regular SwinBlock → Shifted SwinBlock) × (layers/2) 반복\n",
        "class StageModule(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        assert layers % 2 == 0, 'Stage layers need to be divisible by 2 for regular and shifted blocks!'\n",
        "\n",
        "        # 다운샘플링\n",
        "        self.patch_partition = PatchMerging(in_channels=in_channels, out_channels=hidden_dimension,\n",
        "                                            downscaling_factor=downscaling_factor)\n",
        "\n",
        "        # regular + shifted 블록 쌍을 반복\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(layers // 2):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                SwinBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "                SwinBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=True, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_partition(x)\n",
        "        for regular_block, shifted_block in self.layers:\n",
        "            x = regular_block(x)\n",
        "            x = shifted_block(x)\n",
        "        # (B, H', W', C) → (B, C, H', W')\n",
        "        return x.permute(0, 3, 1, 2)\n",
        "\n",
        "## SwinTransformer - 전체 모델 정의\n",
        "#    - 4개의 StageModule → global average pooling → MLP classification head\n",
        "class SwinTransformer(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, layers, heads, channels, num_classes, head_dim, window_size,\n",
        "                 downscaling_factors, relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # 각 Stage\n",
        "        self.stage1 = StageModule(in_channels=channels, hidden_dimension=hidden_dim, layers=layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = StageModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, layers=layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = StageModule(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, layers=layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = StageModule(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, layers=layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "        # 분류 헤드: LayerNorm → Linear\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim * 8),  # 층 정규화\n",
        "            nn.Linear(hidden_dim * 8, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = self.stage1(img)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = x.mean(dim=[2, 3])  # Global Average Pooling\n",
        "        return self.mlp_head(x)\n",
        "\n",
        "\n",
        "## swin_t, swin_s, swin_b, swin_l - Tiny/Small/Base/Large 모델 생성\n",
        "def swin_t(hidden_dim=96, layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return SwinTransformer(hidden_dim=hidden_dim, layers=layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def swin_s(hidden_dim=96, layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return SwinTransformer(hidden_dim=hidden_dim, layers=layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def swin_b(hidden_dim=128, layers=(2, 2, 18, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return SwinTransformer(hidden_dim=hidden_dim, layers=layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def swin_l(hidden_dim=192, layers=(2, 2, 18, 2), heads=(6, 12, 24, 48), **kwargs):\n",
        "    return SwinTransformer(hidden_dim=hidden_dim, layers=layers, heads=heads, **kwargs)"
      ],
      "metadata": {
        "id": "d0AE8Y4_SUoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **swin_transformer.py**\n",
        "\n",
        "1. `CyclicShift`\n",
        "\n",
        "    - `torch.roll`을 이용해 feature map을 cyclic하게 shift\n",
        "\n",
        "    - Shifted Window Attention 구현 시 효율적인 윈도우 경계 처리용\n",
        "\n",
        "2. `create_mask, get_relative_distances`\n",
        "    - Shifted Window에서 윈도우 경계 간 정보 누수 방지용 마스킹 생성\n",
        "\n",
        "    - 상대 위치 바이어스를 위한 거리 인덱스 생성\n",
        "\n",
        "3. `WindowAttention`\n",
        "    - 윈도우 단위로 self-attention 계산 (Shifted 여부 포함)\n",
        "\n",
        "    - `relative_pos_embedding` 옵션으로 상대 위치 바이어스 적용 가능\n",
        "\n",
        "    - 연산량: 선형에 가까운 수준으로 최적화됨\n",
        "\n",
        "4. `SwinBlock`\n",
        "    - Swin의 기본 블록:\n",
        "\n",
        "    (1) Window Attention → residual → LayerNorm\n",
        "\n",
        "    (2) FeedForward MLP → residual → LayerNorm\n",
        "\n",
        "    - shifted 플래그로 Shifted Window 여부를 제어\n",
        "\n",
        "5. `PatchMerging`\n",
        "    - CNN의 stride=2와 유사하게 feature map 다운샘플링\n",
        "\n",
        "    - 2×2 패치를 병합 → 채널 수 4배 → Linear로 원하는 차원으로 축소\n",
        "\n",
        "    - 해상도 ↓, 채널 수 ↑\n",
        "\n",
        "6. `StageModule`\n",
        "    - 하나의 Swin Stage를 구성 (ex: Stage1~4)\n",
        "\n",
        "    - 내부에 Patch Merging → N개의 SwinBlock 쌍 (regular, shifted)\n",
        "\n",
        "    예: layers=6이면 → SwinBlock 6개 = 3쌍 (regular → shifted) 반복\n",
        "\n",
        "7. `SwinTransformer`\n",
        "    - 전체 모델 구조를 통합\n",
        "\n",
        "    - 입력: 이미지\n",
        "\n",
        "    - 구성: Stage1~4 + Global Average Pooling + Linear Head (Classification)\n",
        "\n",
        "    - `mean(dim=[2, 3])`으로 GAP 수행\n",
        "\n",
        "8. `swin_t, swin_s, swin_b, swin_l` 함수\n",
        "    - Swin의 Tiny, Small, Base, Large 모델 생성기\n",
        "\n",
        "    - 각각 hidden_dim, layers, heads 값만 다름\n",
        "    (논문에 정의된 구조 그대로 반영)\n"
      ],
      "metadata": {
        "id": "3I6ORB00CIlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install swin-transformer-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDzt312T-G-T",
        "outputId": "1435f05c-016c-4cc8-e723-fee5e0f0ae4d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting swin-transformer-pytorch\n",
            "  Downloading swin_transformer_pytorch-0.4.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from swin-transformer-pytorch) (2.6.0+cu124)\n",
            "Requirement already satisfied: einops>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from swin-transformer-pytorch) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.1->swin-transformer-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.1->swin-transformer-pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.1->swin-transformer-pytorch) (3.0.2)\n",
            "Downloading swin_transformer_pytorch-0.4.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: swin-transformer-pytorch\n",
            "Successfully installed swin-transformer-pytorch-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 불러오기(example.py)\n",
        "\n",
        "import torch\n",
        "from swin_transformer_pytorch import SwinTransformer\n",
        "\n",
        "net = SwinTransformer(\n",
        "    hidden_dim=96,\n",
        "    layers=(2, 2, 6, 2),\n",
        "    heads=(3, 6, 12, 24),\n",
        "    channels=3,\n",
        "    num_classes=10,         # CIFAR-10에 맞게 클래스 수 변경\n",
        "    head_dim=32,\n",
        "    window_size=7,\n",
        "    downscaling_factors=(4, 2, 2, 2),\n",
        "    relative_pos_embedding=True\n",
        ")\n",
        "\n",
        "dummy_x = torch.randn(1, 3, 224, 224)\n",
        "logits = net(dummy_x)\n",
        "print(net)\n",
        "print(logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxSCZepK8VaV",
        "outputId": "2a233e89-5933-43a6-a789-90dc50e4e804"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SwinTransformer(\n",
            "  (stage1): StageModule(\n",
            "    (patch_partition): PatchMerging(\n",
            "      (patch_merge): Unfold(kernel_size=4, dilation=1, padding=0, stride=4)\n",
            "      (linear): Linear(in_features=48, out_features=96, bias=True)\n",
            "    )\n",
            "    (layers): ModuleList(\n",
            "      (0): ModuleList(\n",
            "        (0): SwinBlock(\n",
            "          (attention_block): Residual(\n",
            "            (fn): PreNorm(\n",
            "              (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "              (fn): WindowAttention(\n",
            "                (to_qkv): Linear(in_features=96, out_features=288, bias=False)\n",
            "                (to_out): Linear(in_features=96, out_features=96, bias=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (mlp_block): Residual(\n",
            "            (fn): PreNorm(\n",
            "              (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "              (fn): FeedForward(\n",
            "                (net): Sequential(\n",
            "                  (0): Linear(in_features=96, out_features=384, bias=True)\n",
            "                  (1): GELU(approximate='none')\n",
            "                  (2): Linear(in_features=384, out_features=96, bias=True)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): SwinBlock(\n",
            "          (attention_block): Residual(\n",
            "            (fn): PreNorm(\n",
            "              (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "              (fn): WindowAttention(\n",
            "                (cyclic_shift): CyclicShift()\n",
            "                (cyclic_back_shift): CyclicShift()\n",
            "                (to_qkv): Linear(in_features=96, out_features=288, bias=False)\n",
            "                (to_out): Linear(in_features=96, out_features=96, bias=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (mlp_block): Residual(\n",
            "            (fn): PreNorm(\n",
            "              (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "              (fn): FeedForward(\n",
            "                (net): Sequential(\n",
            "                  (0): Linear(in_features=96, out_features=384, bias=True)\n",
            "                  (1): GELU(approximate='none')\n",
            "                  (2): Linear(in_features=384, out_features=96, bias=True)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage2): StageModule(\n",
            "    (patch_partition): PatchMerging(\n",
            "      (patch_merge): Unfold(kernel_size=2, dilation=1, padding=0, stride=2)\n",
            "      (linear): Linear(in_features=384, out_features=192, bias=True)\n",
            "    )\n",
            "    (layers): ModuleList(\n",
            "      (0): ModuleList(\n",
            "        (0): SwinBlock(\n",
            "          (attention_block): Residual(\n",
            "            (fn): PreNorm(\n",
            "              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "              (fn): WindowAttention(\n",
            "                (to_qkv): Linear(in_features=192, out_features=576, bias=False)\n",
            "                (to_out): Linear(in_features=192, out_features=192, bias=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (mlp_block): Residual(\n",
            "            (fn): PreNorm(\n",
            "              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "              (fn): FeedForward(\n",
            "                (net): Sequential(\n",
            "                  (0): Linear(in_features=192, out_features=768, bias=True)\n",
            "                  (1): GELU(approximate='none')\n",
            "                  (2): Linear(in_features=768, out_features=192, bias=True)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): SwinBlock(\n",
            "          (attention_block): Residual(\n",
            "            (fn): PreNorm(\n",
            "              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "              (fn): WindowAttention(\n",
            "                (cyclic_shift): CyclicShift()\n",
            "                (cyclic_back_shift): CyclicShift()\n",
            "                (to_qkv): Linear(in_features=192, out_features=576, bias=False)\n",
            "                (to_out): Linear(in_features=192, out_features=192, bias=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (mlp_block): Residual(\n",
            "            (fn): PreNorm(\n",
            "              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "              (fn): FeedForward(\n",
            "                (net): Sequential(\n",
            "                  (0): Linear(in_features=192, out_features=768, bias=True)\n",
            "                  (1): GELU(approximate='none')\n",
            "                  (2): Linear(in_features=768, out_features=192, bias=True)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage3): StageModule(\n",
            "    (patch_partition): PatchMerging(\n",
            "      (patch_merge): Unfold(kernel_size=2, dilation=1, padding=0, stride=2)\n",
            "      (linear): Linear(in_features=768, out_features=384, bias=True)\n",
            "    )\n",
            "    (layers): ModuleList(\n",
            "      (0-2): 3 x ModuleList(\n",
            "        (0): SwinBlock(\n",
            "          (attention_block): Residual(\n",
            "            (fn): PreNorm(\n",
            "              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "              (fn): WindowAttention(\n",
            "                (to_qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
            "                (to_out): Linear(in_features=384, out_features=384, bias=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (mlp_block): Residual(\n",
            "            (fn): PreNorm(\n",
            "              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "              (fn): FeedForward(\n",
            "                (net): Sequential(\n",
            "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "                  (1): GELU(approximate='none')\n",
            "                  (2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): SwinBlock(\n",
            "          (attention_block): Residual(\n",
            "            (fn): PreNorm(\n",
            "              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "              (fn): WindowAttention(\n",
            "                (cyclic_shift): CyclicShift()\n",
            "                (cyclic_back_shift): CyclicShift()\n",
            "                (to_qkv): Linear(in_features=384, out_features=1152, bias=False)\n",
            "                (to_out): Linear(in_features=384, out_features=384, bias=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (mlp_block): Residual(\n",
            "            (fn): PreNorm(\n",
            "              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "              (fn): FeedForward(\n",
            "                (net): Sequential(\n",
            "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "                  (1): GELU(approximate='none')\n",
            "                  (2): Linear(in_features=1536, out_features=384, bias=True)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (stage4): StageModule(\n",
            "    (patch_partition): PatchMerging(\n",
            "      (patch_merge): Unfold(kernel_size=2, dilation=1, padding=0, stride=2)\n",
            "      (linear): Linear(in_features=1536, out_features=768, bias=True)\n",
            "    )\n",
            "    (layers): ModuleList(\n",
            "      (0): ModuleList(\n",
            "        (0): SwinBlock(\n",
            "          (attention_block): Residual(\n",
            "            (fn): PreNorm(\n",
            "              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (fn): WindowAttention(\n",
            "                (to_qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
            "                (to_out): Linear(in_features=768, out_features=768, bias=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (mlp_block): Residual(\n",
            "            (fn): PreNorm(\n",
            "              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (fn): FeedForward(\n",
            "                (net): Sequential(\n",
            "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                  (1): GELU(approximate='none')\n",
            "                  (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): SwinBlock(\n",
            "          (attention_block): Residual(\n",
            "            (fn): PreNorm(\n",
            "              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (fn): WindowAttention(\n",
            "                (cyclic_shift): CyclicShift()\n",
            "                (cyclic_back_shift): CyclicShift()\n",
            "                (to_qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
            "                (to_out): Linear(in_features=768, out_features=768, bias=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (mlp_block): Residual(\n",
            "            (fn): PreNorm(\n",
            "              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (fn): FeedForward(\n",
            "                (net): Sequential(\n",
            "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                  (1): GELU(approximate='none')\n",
            "                  (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mlp_head): Sequential(\n",
            "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (1): Linear(in_features=768, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "tensor([[-0.5575, -0.7881, -0.8555,  0.2936, -0.1730,  0.2848,  0.9421, -0.2055,\n",
            "          0.2337, -0.4628]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Parameters**\n",
        "- `hidden_dim` : int -> 논문에서 C로 언급된 아키텍처에 사용하려는 hidden dimension\n",
        "\n",
        "- `layers` : 4-tuple of ints(짝수) -> 각 단계에서 적용할 레이어 수. 항상 일반 swin block과 shifted swin block을 함께 적용하기 때문에 모든 int는 2로 나눌 수 있어야 함.\n",
        "\n",
        "- `heads` : 4-tuple of ints -> 각 단계에서 적용할 헤드 수.\n",
        "\n",
        "- `channels` : int -> 입력 채널 수.\n",
        "\n",
        "- `num_classes` : int -> 출력에 포함되어야 할 Num 클래스.\n",
        "\n",
        "- `head_dim` : int -> 각 헤드가 가져야 할 차원.\n",
        "\n",
        "- `window_size` : int -> 어떤 윈도우 크기를 사용할 것인지. 각 다룬 스케일링 후에도 이미지 크기가 여전히 윈도우 크기로 나눌 수 있는지 확인.\n",
        "\n",
        "- `downscaling_factors` : int -> 4-tuple of ints -> 각 단계에서 사용할 다운스케일링 요소. 이미지 크기가 다운스케일링 요소보다 충분히 큰지 확인.\n",
        "\n",
        "- `relative_pos_embedding` : bool -> 학습 가능한 상대 위치 임베딩$(2M-1)$x$(2M-1)$ 또는 전체 위치 임베딩 $(M^2$x$ M^2)$ 사용할지 여부.\n"
      ],
      "metadata": {
        "id": "lUJNaOip-dnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델 학습 및 테스트"
      ],
      "metadata": {
        "id": "tLBnfNGcDvTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "# CIFAR10 데이터셋 불러오기\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Swin은 224x224 입력\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxDFD_2VBagy",
        "outputId": "d981ff40-c6dd-4170-c063-5a3f6b27731d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 62.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Swin Transformer 모델 생성 (클래스 수 10)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = net.to(device)\n",
        "\n",
        "# 손실 함수 & 옵티마이저\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "# 학습 루프\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in tqdm(trainloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"[Epoch {epoch+1}] Loss: {running_loss/len(trainloader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj9oyqGDDuXN",
        "outputId": "be366d61-7e0b-474a-f9db-82ca34b099bf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 782/782 [10:32<00:00,  1.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] Loss: 1.7773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 782/782 [10:46<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 2] Loss: 1.3389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 782/782 [10:40<00:00,  1.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 3] Loss: 1.1288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 782/782 [10:44<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 4] Loss: 0.9777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 782/782 [10:39<00:00,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 5] Loss: 0.8552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 정확도 측정\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ45Qgg2KDNu",
        "outputId": "d5c787cc-eeb1-4e2d-fa01-b678bd698733"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 67.03%\n"
          ]
        }
      ]
    }
  ]
}