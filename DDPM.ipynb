{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MarceloGennari/diffusion_mnist.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKJJpzH1KC33",
        "outputId": "0e15237d-24d7-406a-e1e4-d8dbbf85cc0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusion_mnist'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 90 (delta 48), reused 63 (delta 29), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (90/90), 20.72 KiB | 20.72 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd diffusion_mnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk7rG1N-KEzB",
        "outputId": "2f88b6e1-fe2a-4f1e-aa85-17b86671e2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/diffusion_mnist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfzaBEH7KR5R",
        "outputId": "6e63a9d8-c905-4104-ca40-208c15a7e5ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\t\t    inference_unet_DDIM.py  LICENSE  mnist_dataset.py  __pycache__\n",
            "diffusion_model.py  inference_unet.py\t    main.py  models\t       README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# models/common.py\n",
        "\n",
        "import torch\n",
        "import math\n",
        "from einops import rearrange\n",
        "\n",
        "class SinusoidalPositionEmbeddings(torch.nn.Module):\n",
        "    def __init__(self, dim: int):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time: torch.Tensor) -> torch.Tensor:\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = math.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class TemporalEmbedding(torch.nn.Module):\n",
        "    def __init__(self, dim_emb: int, dim_out: int):\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(dim_emb, dim_out)\n",
        "        self.temb = SinusoidalPositionEmbeddings(dim_emb)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, time: torch.Tensor) -> torch.Tensor:\n",
        "        temb = self.temb(time)\n",
        "        emb = self.linear(temb)\n",
        "        emb = emb[:, :, None, None]\n",
        "        out = x + emb\n",
        "        return out\n",
        "\n",
        "\n",
        "class LabelEmbedding(torch.nn.Module):\n",
        "    def __init__(self, dim_emb: int, dim_out: int) -> None:\n",
        "        super().__init__()\n",
        "        self.linear = torch.nn.Linear(dim_emb, dim_out)\n",
        "        self.lemb = torch.nn.Embedding(10, dim_emb)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, label: torch.Tensor) -> torch.Tensor:\n",
        "        lemb = self.lemb(label)\n",
        "        emb = self.linear(lemb)\n",
        "        emb = emb[:, :, None, None]\n",
        "        out = x + emb\n",
        "        return out\n",
        "\n",
        "\n",
        "class LayerNorm(torch.nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.g = torch.nn.Parameter(torch.ones(1, dim, 1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-5 if x.dtype == torch.float32 else 1e-3\n",
        "        var = torch.var(x, dim=1, unbiased=False, keepdim=True)\n",
        "        mean = torch.mean(x, dim=1, keepdim=True)\n",
        "        return (x - mean) * (var + eps).rsqrt() * self.g\n",
        "\n",
        "\n",
        "class LinearAttention(torch.nn.Module):\n",
        "    def __init__(self, dim, heads=4, dim_head=32):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head**-0.5\n",
        "        self.heads = heads\n",
        "        hidden_dim = dim_head * heads\n",
        "        self.to_qkv = torch.nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
        "\n",
        "        self.to_out = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(hidden_dim, dim, 1), LayerNorm(dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
        "        q, k, v = map(\n",
        "            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n",
        "        )\n",
        "\n",
        "        q = q.softmax(dim=-2)\n",
        "        k = k.softmax(dim=-1)\n",
        "\n",
        "        q = q * self.scale\n",
        "        v = v / (h * w)\n",
        "\n",
        "        context = torch.einsum(\"b h d n, b h e n -> b h d e\", k, v)\n",
        "\n",
        "        out = torch.einsum(\"b h d e, b h d n -> b h e n\", context, q)\n",
        "        out = rearrange(out, \"b h c (x y) -> b (h c) x y\", h=self.heads, x=h, y=w)\n",
        "        return self.to_out(out)\n",
        "\n"
      ],
      "metadata": {
        "id": "RqTps9EKQSKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# models/unet.py\n",
        "\n",
        "from torch import nn, Tensor\n",
        "\n",
        "class ResConvGroupNorm(nn.Module):\n",
        "    def __init__(self, in_channels: int, out_channels: int) -> None:\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False)\n",
        "        batch1 = nn.BatchNorm2d(out_channels)\n",
        "        relu1 = nn.LeakyReLU()\n",
        "\n",
        "        conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False)\n",
        "        batch2 = nn.BatchNorm2d(out_channels)\n",
        "        relu2 = nn.LeakyReLU()\n",
        "\n",
        "        layers = [batch1, relu1, conv2, batch2, relu2]\n",
        "\n",
        "        self.feat = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.conv1(x)\n",
        "        return x + self.feat(x)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, dim_emb: int = 1024):\n",
        "        super().__init__()\n",
        "        ch = [64, 128, 128, 64]\n",
        "        self.ch = ch\n",
        "        # Positional Embedding\n",
        "        self.embedding1 = TemporalEmbedding(dim_emb, 1)\n",
        "\n",
        "        # Input is 1x28x28\n",
        "        self.block1 = ResConvGroupNorm(1, ch[0])\n",
        "        self.down1 = nn.Conv2d(ch[0], ch[0], 4, stride=2, padding=1, bias=False)\n",
        "\n",
        "        # Now input is 32x14x14\n",
        "        self.embedding2 = TemporalEmbedding(dim_emb, ch[0])\n",
        "        self.block2 = ResConvGroupNorm(ch[0], ch[1])\n",
        "        self.down2 = nn.Conv2d(ch[1], ch[1], 4, stride=2, padding=1, bias=False)\n",
        "\n",
        "        # Now input is 64x7x7\n",
        "        self.embedding3 = TemporalEmbedding(dim_emb, ch[1])\n",
        "        self.block3 = ResConvGroupNorm(ch[1], ch[2])\n",
        "        self.attention1 = LinearAttention(ch[2])\n",
        "        self.up1 = nn.ConvTranspose2d(ch[2], ch[2], 4, stride=2, padding=1, bias=False)\n",
        "\n",
        "        # Now input is 64x14x14\n",
        "        new_ch = ch[2] + ch[1]\n",
        "        self.embedding4 = TemporalEmbedding(dim_emb, new_ch)\n",
        "        self.block4 = ResConvGroupNorm(new_ch, ch[3])\n",
        "        self.up2 = nn.ConvTranspose2d(ch[3], ch[3], 4, stride=2, padding=1, bias=False)\n",
        "\n",
        "        # Now input is 16x28x28\n",
        "        new_ch = ch[3] + ch[0]\n",
        "        self.embedding5 = TemporalEmbedding(dim_emb, new_ch)\n",
        "        self.block5 = ResConvGroupNorm(new_ch, 1)\n",
        "        self.out = nn.Conv2d(1, 1, 1)\n",
        "\n",
        "    def forward(self, x: Tensor, t: Tensor) -> Tensor:\n",
        "        x0 = self.embedding1(x, t)\n",
        "        x1 = self.block1(x0)\n",
        "        x1 = self.embedding2(x1, t)\n",
        "        x2 = self.block2(self.down1(x1))\n",
        "        x2 = self.embedding3(x2, t)\n",
        "        x3 = self.up1(self.attention1(self.block3(self.down2(x2))))\n",
        "        x4 = torch.cat([x2, x3], dim=1)\n",
        "        x4 = self.embedding4(x4, t)\n",
        "        x5 = self.up2(self.block4(x4))\n",
        "        x6 = torch.cat([x5, x1], dim=1)\n",
        "        x6 = self.embedding5(x6, t)\n",
        "        out = self.out(self.block5(x6))\n",
        "        return out\n",
        "\n",
        "\n",
        "class ConditionalUNet(UNet):\n",
        "    def __init__(self, dim_emb: int = 1024):\n",
        "        super().__init__(dim_emb)\n",
        "        self.label_emb1 = LabelEmbedding(dim_emb, self.ch[0])\n",
        "        self.label_emb2 = LabelEmbedding(dim_emb, self.ch[1])\n",
        "        self.label_emb3 = LabelEmbedding(dim_emb, self.ch[2])\n",
        "        self.label_emb4 = LabelEmbedding(dim_emb, self.ch[3])\n",
        "        self.label_emb5 = LabelEmbedding(dim_emb, self.ch[3] + self.ch[0])\n",
        "\n",
        "    def forward(self, x: Tensor, t: Tensor, label: Tensor) -> Tensor:\n",
        "        x0 = self.embedding1(x, t)\n",
        "        x1 = self.block1(x0)\n",
        "        x1 = self.label_emb1(x1, label)\n",
        "        x1 = self.embedding2(x1, t)\n",
        "        x2 = self.block2(self.down1(x1))\n",
        "        x2 = self.label_emb2(x2, label)\n",
        "        x2 = self.embedding3(x2, t)\n",
        "        crossed = self.label_emb3(self.block3(self.down2(x2)), label)\n",
        "        x3 = self.up1(self.attention1(crossed))\n",
        "        x4 = torch.cat([x2, x3], dim=1)\n",
        "        x4 = self.embedding4(x4, t)\n",
        "        x5 = self.up2(self.label_emb4(self.block4(x4), label))\n",
        "        x6 = torch.cat([x5, x1], dim=1)\n",
        "        x6 = self.label_emb5(x6, label)\n",
        "        x6 = self.embedding5(x6, t)\n",
        "        out = self.out(self.block5(x6))\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "IYJP7_teQSDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# diffusion_model.py\n",
        "\n",
        "\"\"\"\n",
        "Marcelo Gennari do Nascimento, 2022\n",
        "marcelogennari@outlook.com\n",
        "\"\"\"\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class DiffusionProcess:\n",
        "    \"\"\"\n",
        "    Class that implements the forward and inverse diffusion process according to\n",
        "    the DDPM paper: https://arxiv.org/pdf/2006.11239.pdf\n",
        "\n",
        "    Attributes:\n",
        "        variance_schedule (torch.Tensor): list with the variance value at each\n",
        "            timestep according to DDPM paper\n",
        "        alpha (torch.Tensor): list of \"complement\" values for variance defined\n",
        "            in the DDPM paper. It is the same as 1-variance_schedule\n",
        "        alpha_bar (torch.Tensor): cummulative product defined int he DDPM\n",
        "            paper above. It is derived directly from the variance schedule\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, variance_schedule: List[float] = None) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            variance_schedule (list): list with the variance value at each\n",
        "                timestep according to DDPM paper. If left None, it will default\n",
        "                to a list of linearly increasing variance from 1e-4 to 0.02 in\n",
        "                1000 steps\n",
        "        \"\"\"\n",
        "        if variance_schedule is None:\n",
        "            variance_schedule = torch.linspace(1e-4, 0.01, steps=1000)\n",
        "        self.variance_schedule = Tensor(variance_schedule)\n",
        "        self.alpha = 1 - self.variance_schedule\n",
        "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
        "\n",
        "    def forward(self, x_0: Tensor, time_step: Tensor, noise: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        This applies the forward diffusion process to original image ``x`` to\n",
        "        timestamp ``time_step``, using a sample ``noise`` from a zero mean, unit\n",
        "        variance gaussian distribution. The formula for the forward propagation,\n",
        "        given step time_step and original tensor x is:\n",
        "            p(x_t | x_0) = N(sqrt(alpha_t) * x_0, (1-alpha_t) * I)\n",
        "        where I is the identity matrix. This can be reparameterised as following:\n",
        "            p(x_t | x_0) = sqrt(alpha_t) * x_0 + sqrt(1-alpha_t) * noise\n",
        "        where ``noise``~N(0, I). This is the expression used in this function.\n",
        "\n",
        "        Args:\n",
        "            x_0 (torch.Tensor): original image. It can be of any shape, since\n",
        "                diffusion is independent and identically distributed (iid)\n",
        "            time_step (torch.Tensor): which step to diffuse the original image.\n",
        "                It is a Tensor with numbers between 0 and len(self.alpha_bar). It\n",
        "                also has to have the same batch size as ``x_0``\n",
        "            noise (torch.Tensor): the noise to be added at this ``time_step``. It\n",
        "                has to be a tensor sampled from a zero-mean unit-variance normal\n",
        "                distribution.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: the result of diffusig original image ``x_0`` to\n",
        "                ``time_step`` using the variance schedule :attr:alpha_bar\n",
        "        \"\"\"\n",
        "        # Checking for validity of input\n",
        "        assert torch.all(time_step >= 0).item()\n",
        "        assert torch.all(time_step < len(self.alpha_bar)).item()\n",
        "        assert time_step.shape[0] == x_0.shape[0]\n",
        "        std_dev = torch.sqrt(1 - self.alpha_bar[time_step])\n",
        "        mean_multiplier = torch.sqrt(self.alpha_bar[time_step])\n",
        "\n",
        "        # This makes sure that variance and mean multiplier are both broadcastable\n",
        "        std_dev = std_dev[:, None, None, None].to(x_0.device)\n",
        "        mean_multiplier = mean_multiplier[:, None, None, None].to(x_0.device)\n",
        "\n",
        "        diffused_images = mean_multiplier * x_0 + std_dev * noise\n",
        "        return diffused_images\n",
        "\n",
        "    def inverse(self, xt: Tensor, et: Tensor, t: int) -> Tensor:\n",
        "        \"\"\"\n",
        "        This applies the unconditional sampling of the diffusion step. It uses the\n",
        "        equation as follow:\n",
        "            p(x_{t-1}| x_t) = mu_t + std_dev_t * N(0, I)\n",
        "            mu_t = (1/sqrt(alpha_t)) * (xt - noise_scale * et)\n",
        "            noise_scale = (1-alpha_t) / sqrt(1-alpha_bar_t)\n",
        "            std_dev_t = sqrt(variance_schedule)\n",
        "        this is from the DDPM paper.\n",
        "\n",
        "        Args:\n",
        "            xt (torch.Tensor): noisy image at time ``t``.\n",
        "            et (torch.Tensor): predicted error from diffusion model, which is\n",
        "                usually the output of the trained UNet architecture\n",
        "            t (int): the time ``t`` of the diffusion process\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: the result of the sampling x_{t-1}\n",
        "        \"\"\"\n",
        "        scale = 1 / torch.sqrt(self.alpha[t])\n",
        "        noise_scale = (1 - self.alpha[t]) / torch.sqrt(1 - self.alpha_bar[t])\n",
        "        std_dev = torch.sqrt(self.variance_schedule[t])\n",
        "        mu_t = scale * (xt - noise_scale * et)\n",
        "\n",
        "        z = torch.randn(xt.shape) if t > 1 else torch.Tensor([0])\n",
        "        xt = mu_t + std_dev * z  # remove noise from image\n",
        "        return xt\n",
        "\n",
        "    def inverse_DDIM(self, xt: Tensor, et: Tensor, t: int) -> Tensor:\n",
        "        \"\"\"\n",
        "        This applies the unconditional sampling of the diffusion step using the\n",
        "        DDIM method: https://arxiv.org/abs/2010.02502\n",
        "        f_theta acts as an approximation for x_0, and the rest follows equation\n",
        "        (7) in the paper. For DDIM, we have that std_dev = 0\n",
        "        This solves the problem of stochasticity, and it is supposed to be 10x\n",
        "        to 100x quicker than the DDPM method\n",
        "        \"\"\"\n",
        "        den = 1 / torch.sqrt(self.alpha_bar[t])\n",
        "        f_theta = (xt - torch.sqrt(1 - self.alpha_bar[t]) * et) * den\n",
        "        if t > 0:\n",
        "            part1 = torch.sqrt(self.alpha_bar[t - 1]) * f_theta\n",
        "            part2 = torch.sqrt(1 - self.alpha_bar[t - 1])\n",
        "            den = 1 / torch.sqrt(1 - self.alpha_bar[t])\n",
        "            scale = (xt - torch.sqrt(self.alpha_bar[t]) * f_theta) * den\n",
        "            xt = part1 + part2 * scale\n",
        "        else:\n",
        "            xt = f_theta\n",
        "\n",
        "        return xt\n"
      ],
      "metadata": {
        "id": "ldu_W-t8QR9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mnist_dataset.py\n",
        "\n",
        "\"\"\"\n",
        "Marcelo Gennari do Nascimento, 2022\n",
        "marcelogennari@outlook.com\n",
        "\n",
        "This script has been adapted from https://nextjournal.com/gkoehler/pytorch-mnist\n",
        "\"\"\"\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from typing import Tuple\n",
        "\n",
        "\n",
        "def get_mnist_dataloader(batch_size: int = 256) -> Tuple[DataLoader, DataLoader]:\n",
        "    \"\"\"\n",
        "    Convenient helper function to get the loaders for the mnist dataset\n",
        "    Args:\n",
        "        batch_size (int): the size of batches\n",
        "\n",
        "    Returns:\n",
        "        Tuple[DataLoader, DataLoader]: train loader and test loader respectively\n",
        "    \"\"\"\n",
        "    to_tensor = torchvision.transforms.ToTensor()\n",
        "    normalize = torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "    transform = torchvision.transforms.Compose([to_tensor, normalize])\n",
        "\n",
        "    trainset = MNIST(\"./data/\", train=True, download=True, transform=transform)\n",
        "    testset = MNIST(\"./data/\", train=False, download=True, transform=transform)\n",
        "\n",
        "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return trainloader, testloader"
      ],
      "metadata": {
        "id": "zZFGmUb7PAhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "\n",
        "\"\"\"\n",
        "Marcelo Gennari do Nascimento, 2022\n",
        "marcelogennari@outlook.com\n",
        "\n",
        "This script is used to train the UNet to predict the noise at different\n",
        "timestamps of the diffusion process. The loss function is a simple mean\n",
        "squared error between the actual noise and the predicted noise based on\n",
        "the diffused image, according to the original paper:\n",
        "https://arxiv.org/pdf/2006.11239.pdf\n",
        "\"\"\"\n",
        "\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Prepare images\n",
        "    trainloader, testloader = get_mnist_dataloader()\n",
        "    idx, (images, labels) = next(enumerate(testloader))\n",
        "\n",
        "    # Prepare model and training\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = ConditionalUNet().to(device)\n",
        "    process = DiffusionProcess()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, 80)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    # Training Loop\n",
        "    epochs = 100\n",
        "    for e in trange(epochs):\n",
        "        running_loss = 0\n",
        "        progress_bar = tqdm(trainloader, leave=False)\n",
        "        for image, label in progress_bar:\n",
        "            # Sampling t, epsilon, and diffused image\n",
        "            t = torch.randint(0, 1000, (image.shape[0],))\n",
        "            epsilon = torch.randn(image.shape)\n",
        "            diffused_image = process.forward(image, t, epsilon)\n",
        "\n",
        "            # Backprop\n",
        "            optimizer.zero_grad()\n",
        "            output = model(diffused_image.to(device), t.to(device), label.to(device))\n",
        "            loss = criterion(epsilon.to(device), output)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_value = loss.cpu().item()\n",
        "            running_loss += loss_value\n",
        "            progress_bar.set_description(f\"Loss: {loss_value:.4f}\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Save model after every epoch\n",
        "        torch.save(model.state_dict(), \"unet_mnist.pth\")\n",
        "\n",
        "        # Logging results\n",
        "        running_loss /= len(trainloader)\n",
        "        tqdm.write(f\"Mean loss for Epoch {e + 1}: {running_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5PEBvBB4PtiI",
        "outputId": "dda00ac9-665e-4255-9f9f-23dcf0511b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]\n",
            "  0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 1.9735:   0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 1.9735:   0%|          | 1/235 [00:00<02:38,  1.47it/s]\u001b[A\n",
            "Loss: 1.7515:   0%|          | 1/235 [00:00<02:38,  1.47it/s]\u001b[A\n",
            "Loss: 1.5715:   0%|          | 1/235 [00:00<02:38,  1.47it/s]\u001b[A\n",
            "Loss: 1.5715:   1%|▏         | 3/235 [00:00<00:53,  4.34it/s]\u001b[A\n",
            "Loss: 1.4014:   1%|▏         | 3/235 [00:00<00:53,  4.34it/s]\u001b[A\n",
            "Loss: 1.2146:   1%|▏         | 3/235 [00:00<00:53,  4.34it/s]\u001b[A\n",
            "Loss: 1.2146:   2%|▏         | 5/235 [00:00<00:34,  6.66it/s]\u001b[A\n",
            "Loss: 1.0663:   2%|▏         | 5/235 [00:01<00:34,  6.66it/s]\u001b[A\n",
            "Loss: 0.9834:   2%|▏         | 5/235 [00:01<00:34,  6.66it/s]\u001b[A\n",
            "Loss: 0.9834:   3%|▎         | 7/235 [00:01<00:26,  8.49it/s]\u001b[A\n",
            "Loss: 1.0120:   3%|▎         | 7/235 [00:01<00:26,  8.49it/s]\u001b[A\n",
            "Loss: 1.0736:   3%|▎         | 7/235 [00:01<00:26,  8.49it/s]\u001b[A\n",
            "Loss: 1.0736:   4%|▍         | 9/235 [00:01<00:22,  9.92it/s]\u001b[A\n",
            "Loss: 1.0556:   4%|▍         | 9/235 [00:01<00:22,  9.92it/s]\u001b[A\n",
            "Loss: 1.0010:   4%|▍         | 9/235 [00:01<00:22,  9.92it/s]\u001b[A\n",
            "Loss: 1.0010:   5%|▍         | 11/235 [00:01<00:20, 11.04it/s]\u001b[A\n",
            "Loss: 0.9423:   5%|▍         | 11/235 [00:01<00:20, 11.04it/s]\u001b[A\n",
            "Loss: 0.9117:   5%|▍         | 11/235 [00:01<00:20, 11.04it/s]\u001b[A\n",
            "Loss: 0.9117:   6%|▌         | 13/235 [00:01<00:18, 11.77it/s]\u001b[A\n",
            "Loss: 0.8896:   6%|▌         | 13/235 [00:01<00:18, 11.77it/s]\u001b[A\n",
            "Loss: 0.8890:   6%|▌         | 13/235 [00:01<00:18, 11.77it/s]\u001b[A\n",
            "Loss: 0.8890:   6%|▋         | 15/235 [00:01<00:17, 12.32it/s]\u001b[A\n",
            "Loss: 0.8826:   6%|▋         | 15/235 [00:01<00:17, 12.32it/s]\u001b[A\n",
            "Loss: 0.8797:   6%|▋         | 15/235 [00:01<00:17, 12.32it/s]\u001b[A\n",
            "Loss: 0.8797:   7%|▋         | 17/235 [00:01<00:16, 12.83it/s]\u001b[A\n",
            "Loss: 0.8738:   7%|▋         | 17/235 [00:01<00:16, 12.83it/s]\u001b[A\n",
            "Loss: 0.8612:   7%|▋         | 17/235 [00:01<00:16, 12.83it/s]\u001b[A\n",
            "Loss: 0.8612:   8%|▊         | 19/235 [00:01<00:16, 13.17it/s]\u001b[A\n",
            "Loss: 0.8483:   8%|▊         | 19/235 [00:02<00:16, 13.17it/s]\u001b[A\n",
            "Loss: 0.8360:   8%|▊         | 19/235 [00:02<00:16, 13.17it/s]\u001b[A\n",
            "Loss: 0.8360:   9%|▉         | 21/235 [00:02<00:16, 13.30it/s]\u001b[A\n",
            "Loss: 0.8236:   9%|▉         | 21/235 [00:02<00:16, 13.30it/s]\u001b[A\n",
            "Loss: 0.8210:   9%|▉         | 21/235 [00:02<00:16, 13.30it/s]\u001b[A\n",
            "Loss: 0.8210:  10%|▉         | 23/235 [00:02<00:15, 13.43it/s]\u001b[A\n",
            "Loss: 0.8140:  10%|▉         | 23/235 [00:02<00:15, 13.43it/s]\u001b[A\n",
            "Loss: 0.8022:  10%|▉         | 23/235 [00:02<00:15, 13.43it/s]\u001b[A\n",
            "Loss: 0.8022:  11%|█         | 25/235 [00:02<00:15, 13.56it/s]\u001b[A\n",
            "Loss: 0.7968:  11%|█         | 25/235 [00:02<00:15, 13.56it/s]\u001b[A\n",
            "Loss: 0.7909:  11%|█         | 25/235 [00:02<00:15, 13.56it/s]\u001b[A\n",
            "Loss: 0.7909:  11%|█▏        | 27/235 [00:02<00:15, 13.57it/s]\u001b[A\n",
            "Loss: 0.7883:  11%|█▏        | 27/235 [00:02<00:15, 13.57it/s]\u001b[A\n",
            "Loss: 0.7811:  11%|█▏        | 27/235 [00:02<00:15, 13.57it/s]\u001b[A\n",
            "Loss: 0.7811:  12%|█▏        | 29/235 [00:02<00:15, 13.53it/s]\u001b[A\n",
            "Loss: 0.7779:  12%|█▏        | 29/235 [00:02<00:15, 13.53it/s]\u001b[A\n",
            "Loss: 0.7718:  12%|█▏        | 29/235 [00:02<00:15, 13.53it/s]\u001b[A\n",
            "Loss: 0.7718:  13%|█▎        | 31/235 [00:02<00:15, 13.52it/s]\u001b[A\n",
            "Loss: 0.7500:  13%|█▎        | 31/235 [00:02<00:15, 13.52it/s]\u001b[A\n",
            "Loss: 0.7501:  13%|█▎        | 31/235 [00:03<00:15, 13.52it/s]\u001b[A\n",
            "Loss: 0.7501:  14%|█▍        | 33/235 [00:03<00:14, 13.58it/s]\u001b[A\n",
            "Loss: 0.7247:  14%|█▍        | 33/235 [00:03<00:14, 13.58it/s]\u001b[A\n",
            "Loss: 0.7438:  14%|█▍        | 33/235 [00:03<00:14, 13.58it/s]\u001b[A\n",
            "Loss: 0.7438:  15%|█▍        | 35/235 [00:03<00:14, 13.57it/s]\u001b[A\n",
            "Loss: 0.7277:  15%|█▍        | 35/235 [00:03<00:14, 13.57it/s]\u001b[A\n",
            "Loss: 0.7260:  15%|█▍        | 35/235 [00:03<00:14, 13.57it/s]\u001b[A\n",
            "Loss: 0.7260:  16%|█▌        | 37/235 [00:03<00:14, 13.69it/s]\u001b[A\n",
            "Loss: 0.7092:  16%|█▌        | 37/235 [00:03<00:14, 13.69it/s]\u001b[A\n",
            "Loss: 0.7187:  16%|█▌        | 37/235 [00:03<00:14, 13.69it/s]\u001b[A\n",
            "Loss: 0.7187:  17%|█▋        | 39/235 [00:03<00:14, 13.81it/s]\u001b[A\n",
            "Loss: 0.7130:  17%|█▋        | 39/235 [00:03<00:14, 13.81it/s]\u001b[A\n",
            "Loss: 0.6941:  17%|█▋        | 39/235 [00:03<00:14, 13.81it/s]\u001b[A\n",
            "Loss: 0.6941:  17%|█▋        | 41/235 [00:03<00:14, 13.83it/s]\u001b[A\n",
            "Loss: 0.6859:  17%|█▋        | 41/235 [00:03<00:14, 13.83it/s]\u001b[A\n",
            "Loss: 0.6821:  17%|█▋        | 41/235 [00:03<00:14, 13.83it/s]\u001b[A\n",
            "Loss: 0.6821:  18%|█▊        | 43/235 [00:03<00:13, 13.83it/s]\u001b[A\n",
            "Loss: 0.6919:  18%|█▊        | 43/235 [00:03<00:13, 13.83it/s]\u001b[A\n",
            "Loss: 0.6806:  18%|█▊        | 43/235 [00:03<00:13, 13.83it/s]\u001b[A\n",
            "Loss: 0.6806:  19%|█▉        | 45/235 [00:03<00:13, 13.88it/s]\u001b[A\n",
            "Loss: 0.6618:  19%|█▉        | 45/235 [00:03<00:13, 13.88it/s]\u001b[A\n",
            "Loss: 0.6561:  19%|█▉        | 45/235 [00:04<00:13, 13.88it/s]\u001b[A\n",
            "Loss: 0.6561:  20%|██        | 47/235 [00:04<00:13, 13.78it/s]\u001b[A\n",
            "Loss: 0.6408:  20%|██        | 47/235 [00:04<00:13, 13.78it/s]\u001b[A\n",
            "Loss: 0.6577:  20%|██        | 47/235 [00:04<00:13, 13.78it/s]\u001b[A\n",
            "Loss: 0.6577:  21%|██        | 49/235 [00:04<00:13, 13.86it/s]\u001b[A\n",
            "Loss: 0.6453:  21%|██        | 49/235 [00:04<00:13, 13.86it/s]\u001b[A\n",
            "Loss: 0.6337:  21%|██        | 49/235 [00:04<00:13, 13.86it/s]\u001b[A\n",
            "Loss: 0.6337:  22%|██▏       | 51/235 [00:04<00:13, 13.89it/s]\u001b[A\n",
            "Loss: 0.6271:  22%|██▏       | 51/235 [00:04<00:13, 13.89it/s]\u001b[A\n",
            "Loss: 0.6249:  22%|██▏       | 51/235 [00:04<00:13, 13.89it/s]\u001b[A\n",
            "Loss: 0.6249:  23%|██▎       | 53/235 [00:04<00:13, 13.88it/s]\u001b[A\n",
            "Loss: 0.6068:  23%|██▎       | 53/235 [00:04<00:13, 13.88it/s]\u001b[A\n",
            "Loss: 0.6144:  23%|██▎       | 53/235 [00:04<00:13, 13.88it/s]\u001b[A\n",
            "Loss: 0.6144:  23%|██▎       | 55/235 [00:04<00:13, 13.75it/s]\u001b[A\n",
            "Loss: 0.5918:  23%|██▎       | 55/235 [00:04<00:13, 13.75it/s]\u001b[A\n",
            "Loss: 0.5929:  23%|██▎       | 55/235 [00:04<00:13, 13.75it/s]\u001b[A\n",
            "Loss: 0.5929:  24%|██▍       | 57/235 [00:04<00:12, 13.76it/s]\u001b[A\n",
            "Loss: 0.5793:  24%|██▍       | 57/235 [00:04<00:12, 13.76it/s]\u001b[A\n",
            "Loss: 0.5854:  24%|██▍       | 57/235 [00:04<00:12, 13.76it/s]\u001b[A\n",
            "Loss: 0.5854:  25%|██▌       | 59/235 [00:04<00:12, 13.82it/s]\u001b[A\n",
            "Loss: 0.5855:  25%|██▌       | 59/235 [00:04<00:12, 13.82it/s]\u001b[A\n",
            "Loss: 0.5663:  25%|██▌       | 59/235 [00:05<00:12, 13.82it/s]\u001b[A\n",
            "Loss: 0.5663:  26%|██▌       | 61/235 [00:05<00:12, 13.81it/s]\u001b[A\n",
            "Loss: 0.5728:  26%|██▌       | 61/235 [00:05<00:12, 13.81it/s]\u001b[A\n",
            "Loss: 0.5540:  26%|██▌       | 61/235 [00:05<00:12, 13.81it/s]\u001b[A\n",
            "Loss: 0.5540:  27%|██▋       | 63/235 [00:05<00:12, 13.76it/s]\u001b[A\n",
            "Loss: 0.5553:  27%|██▋       | 63/235 [00:05<00:12, 13.76it/s]\u001b[A\n",
            "Loss: 0.5378:  27%|██▋       | 63/235 [00:05<00:12, 13.76it/s]\u001b[A\n",
            "Loss: 0.5378:  28%|██▊       | 65/235 [00:05<00:12, 13.60it/s]\u001b[A\n",
            "Loss: 0.5343:  28%|██▊       | 65/235 [00:05<00:12, 13.60it/s]\u001b[A\n",
            "Loss: 0.5411:  28%|██▊       | 65/235 [00:05<00:12, 13.60it/s]\u001b[A\n",
            "Loss: 0.5411:  29%|██▊       | 67/235 [00:05<00:12, 13.41it/s]\u001b[A\n",
            "Loss: 0.5334:  29%|██▊       | 67/235 [00:05<00:12, 13.41it/s]\u001b[A\n",
            "Loss: 0.5221:  29%|██▊       | 67/235 [00:05<00:12, 13.41it/s]\u001b[A\n",
            "Loss: 0.5221:  29%|██▉       | 69/235 [00:05<00:12, 13.42it/s]\u001b[A\n",
            "Loss: 0.5066:  29%|██▉       | 69/235 [00:05<00:12, 13.42it/s]\u001b[A\n",
            "Loss: 0.4932:  29%|██▉       | 69/235 [00:05<00:12, 13.42it/s]\u001b[A\n",
            "Loss: 0.4932:  30%|███       | 71/235 [00:05<00:12, 13.44it/s]\u001b[A\n",
            "Loss: 0.5025:  30%|███       | 71/235 [00:05<00:12, 13.44it/s]\u001b[A\n",
            "Loss: 0.4776:  30%|███       | 71/235 [00:05<00:12, 13.44it/s]\u001b[A\n",
            "Loss: 0.4776:  31%|███       | 73/235 [00:05<00:11, 13.58it/s]\u001b[A\n",
            "Loss: 0.4813:  31%|███       | 73/235 [00:06<00:11, 13.58it/s]\u001b[A\n",
            "Loss: 0.4663:  31%|███       | 73/235 [00:06<00:11, 13.58it/s]\u001b[A\n",
            "Loss: 0.4663:  32%|███▏      | 75/235 [00:06<00:11, 13.67it/s]\u001b[A\n",
            "Loss: 0.4551:  32%|███▏      | 75/235 [00:06<00:11, 13.67it/s]\u001b[A\n",
            "Loss: 0.4487:  32%|███▏      | 75/235 [00:06<00:11, 13.67it/s]\u001b[A\n",
            "Loss: 0.4487:  33%|███▎      | 77/235 [00:06<00:11, 13.53it/s]\u001b[A\n",
            "Loss: 0.4452:  33%|███▎      | 77/235 [00:06<00:11, 13.53it/s]\u001b[A\n",
            "Loss: 0.4571:  33%|███▎      | 77/235 [00:06<00:11, 13.53it/s]\u001b[A\n",
            "Loss: 0.4571:  34%|███▎      | 79/235 [00:06<00:11, 13.44it/s]\u001b[A\n",
            "Loss: 0.4306:  34%|███▎      | 79/235 [00:06<00:11, 13.44it/s]\u001b[A\n",
            "Loss: 0.4304:  34%|███▎      | 79/235 [00:06<00:11, 13.44it/s]\u001b[A\n",
            "Loss: 0.4304:  34%|███▍      | 81/235 [00:06<00:11, 13.43it/s]\u001b[A\n",
            "Loss: 0.4103:  34%|███▍      | 81/235 [00:06<00:11, 13.43it/s]\u001b[A\n",
            "Loss: 0.3962:  34%|███▍      | 81/235 [00:06<00:11, 13.43it/s]\u001b[A\n",
            "Loss: 0.3962:  35%|███▌      | 83/235 [00:06<00:11, 13.46it/s]\u001b[A\n",
            "Loss: 0.4037:  35%|███▌      | 83/235 [00:06<00:11, 13.46it/s]\u001b[A\n",
            "Loss: 0.3889:  35%|███▌      | 83/235 [00:06<00:11, 13.46it/s]\u001b[A\n",
            "Loss: 0.3889:  36%|███▌      | 85/235 [00:06<00:11, 13.55it/s]\u001b[A\n",
            "Loss: 0.3964:  36%|███▌      | 85/235 [00:06<00:11, 13.55it/s]\u001b[A\n",
            "Loss: 0.3976:  36%|███▌      | 85/235 [00:06<00:11, 13.55it/s]\u001b[A\n",
            "Loss: 0.3976:  37%|███▋      | 87/235 [00:06<00:10, 13.57it/s]\u001b[A\n",
            "Loss: 0.3603:  37%|███▋      | 87/235 [00:07<00:10, 13.57it/s]\u001b[A\n",
            "Loss: 0.3462:  37%|███▋      | 87/235 [00:07<00:10, 13.57it/s]\u001b[A\n",
            "Loss: 0.3462:  38%|███▊      | 89/235 [00:07<00:10, 13.66it/s]\u001b[A\n",
            "Loss: 0.3724:  38%|███▊      | 89/235 [00:07<00:10, 13.66it/s]\u001b[A\n",
            "Loss: 0.3438:  38%|███▊      | 89/235 [00:07<00:10, 13.66it/s]\u001b[A\n",
            "Loss: 0.3438:  39%|███▊      | 91/235 [00:07<00:10, 13.72it/s]\u001b[A\n",
            "Loss: 0.3248:  39%|███▊      | 91/235 [00:07<00:10, 13.72it/s]\u001b[A\n",
            "Loss: 0.3368:  39%|███▊      | 91/235 [00:07<00:10, 13.72it/s]\u001b[A\n",
            "Loss: 0.3368:  40%|███▉      | 93/235 [00:07<00:10, 13.77it/s]\u001b[A\n",
            "Loss: 0.2936:  40%|███▉      | 93/235 [00:07<00:10, 13.77it/s]\u001b[A\n",
            "Loss: 0.3043:  40%|███▉      | 93/235 [00:07<00:10, 13.77it/s]\u001b[A\n",
            "Loss: 0.3043:  40%|████      | 95/235 [00:07<00:10, 13.78it/s]\u001b[A\n",
            "Loss: 0.3102:  40%|████      | 95/235 [00:07<00:10, 13.78it/s]\u001b[A\n",
            "Loss: 0.3146:  40%|████      | 95/235 [00:07<00:10, 13.78it/s]\u001b[A\n",
            "Loss: 0.3146:  41%|████▏     | 97/235 [00:07<00:10, 13.72it/s]\u001b[A\n",
            "Loss: 0.2885:  41%|████▏     | 97/235 [00:07<00:10, 13.72it/s]\u001b[A\n",
            "Loss: 0.2890:  41%|████▏     | 97/235 [00:07<00:10, 13.72it/s]\u001b[A\n",
            "Loss: 0.2890:  42%|████▏     | 99/235 [00:07<00:09, 13.78it/s]\u001b[A\n",
            "Loss: 0.2889:  42%|████▏     | 99/235 [00:07<00:09, 13.78it/s]\u001b[A\n",
            "Loss: 0.2737:  42%|████▏     | 99/235 [00:07<00:09, 13.78it/s]\u001b[A\n",
            "Loss: 0.2737:  43%|████▎     | 101/235 [00:07<00:09, 13.57it/s]\u001b[A\n",
            "Loss: 0.2803:  43%|████▎     | 101/235 [00:08<00:09, 13.57it/s]\u001b[A\n",
            "Loss: 0.2890:  43%|████▎     | 101/235 [00:08<00:09, 13.57it/s]\u001b[A\n",
            "Loss: 0.2890:  44%|████▍     | 103/235 [00:08<00:09, 13.60it/s]\u001b[A\n",
            "Loss: 0.2514:  44%|████▍     | 103/235 [00:08<00:09, 13.60it/s]\u001b[A\n",
            "Loss: 0.2399:  44%|████▍     | 103/235 [00:08<00:09, 13.60it/s]\u001b[A\n",
            "Loss: 0.2399:  45%|████▍     | 105/235 [00:08<00:09, 13.53it/s]\u001b[A\n",
            "Loss: 0.2692:  45%|████▍     | 105/235 [00:08<00:09, 13.53it/s]\u001b[A\n",
            "Loss: 0.2709:  45%|████▍     | 105/235 [00:08<00:09, 13.53it/s]\u001b[A\n",
            "Loss: 0.2709:  46%|████▌     | 107/235 [00:08<00:09, 13.60it/s]\u001b[A\n",
            "Loss: 0.2659:  46%|████▌     | 107/235 [00:08<00:09, 13.60it/s]\u001b[A\n",
            "Loss: 0.2462:  46%|████▌     | 107/235 [00:08<00:09, 13.60it/s]\u001b[A\n",
            "Loss: 0.2462:  46%|████▋     | 109/235 [00:08<00:09, 13.55it/s]\u001b[A\n",
            "Loss: 0.2082:  46%|████▋     | 109/235 [00:08<00:09, 13.55it/s]\u001b[A\n",
            "Loss: 0.2467:  46%|████▋     | 109/235 [00:08<00:09, 13.55it/s]\u001b[A\n",
            "Loss: 0.2467:  47%|████▋     | 111/235 [00:08<00:09, 13.52it/s]\u001b[A\n",
            "Loss: 0.2228:  47%|████▋     | 111/235 [00:08<00:09, 13.52it/s]\u001b[A\n",
            "Loss: 0.2212:  47%|████▋     | 111/235 [00:08<00:09, 13.52it/s]\u001b[A\n",
            "Loss: 0.2212:  48%|████▊     | 113/235 [00:08<00:08, 13.61it/s]\u001b[A\n",
            "Loss: 0.2293:  48%|████▊     | 113/235 [00:08<00:08, 13.61it/s]\u001b[A\n",
            "Loss: 0.2333:  48%|████▊     | 113/235 [00:09<00:08, 13.61it/s]\u001b[A\n",
            "Loss: 0.2333:  49%|████▉     | 115/235 [00:09<00:08, 13.73it/s]\u001b[A\n",
            "Loss: 0.2347:  49%|████▉     | 115/235 [00:09<00:08, 13.73it/s]\u001b[A\n",
            "Loss: 0.2139:  49%|████▉     | 115/235 [00:09<00:08, 13.73it/s]\u001b[A\n",
            "Loss: 0.2139:  50%|████▉     | 117/235 [00:09<00:08, 13.69it/s]\u001b[A\n",
            "Loss: 0.2167:  50%|████▉     | 117/235 [00:09<00:08, 13.69it/s]\u001b[A\n",
            "Loss: 0.2135:  50%|████▉     | 117/235 [00:09<00:08, 13.69it/s]\u001b[A\n",
            "Loss: 0.2135:  51%|█████     | 119/235 [00:09<00:08, 13.76it/s]\u001b[A\n",
            "Loss: 0.2321:  51%|█████     | 119/235 [00:09<00:08, 13.76it/s]\u001b[A\n",
            "Loss: 0.2134:  51%|█████     | 119/235 [00:09<00:08, 13.76it/s]\u001b[A\n",
            "Loss: 0.2134:  51%|█████▏    | 121/235 [00:09<00:08, 13.75it/s]\u001b[A\n",
            "Loss: 0.2174:  51%|█████▏    | 121/235 [00:09<00:08, 13.75it/s]\u001b[A\n",
            "Loss: 0.1951:  51%|█████▏    | 121/235 [00:09<00:08, 13.75it/s]\u001b[A\n",
            "Loss: 0.1951:  52%|█████▏    | 123/235 [00:09<00:08, 13.68it/s]\u001b[A\n",
            "Loss: 0.2102:  52%|█████▏    | 123/235 [00:09<00:08, 13.68it/s]\u001b[A\n",
            "Loss: 0.2207:  52%|█████▏    | 123/235 [00:09<00:08, 13.68it/s]\u001b[A\n",
            "Loss: 0.2207:  53%|█████▎    | 125/235 [00:09<00:08, 13.62it/s]\u001b[A\n",
            "Loss: 0.2104:  53%|█████▎    | 125/235 [00:09<00:08, 13.62it/s]\u001b[A\n",
            "Loss: 0.2242:  53%|█████▎    | 125/235 [00:09<00:08, 13.62it/s]\u001b[A\n",
            "Loss: 0.2242:  54%|█████▍    | 127/235 [00:09<00:07, 13.62it/s]\u001b[A\n",
            "Loss: 0.2207:  54%|█████▍    | 127/235 [00:09<00:07, 13.62it/s]\u001b[A\n",
            "Loss: 0.1877:  54%|█████▍    | 127/235 [00:10<00:07, 13.62it/s]\u001b[A\n",
            "Loss: 0.1877:  55%|█████▍    | 129/235 [00:10<00:07, 13.59it/s]\u001b[A\n",
            "Loss: 0.1926:  55%|█████▍    | 129/235 [00:10<00:07, 13.59it/s]\u001b[A\n",
            "Loss: 0.2101:  55%|█████▍    | 129/235 [00:10<00:07, 13.59it/s]\u001b[A\n",
            "Loss: 0.2101:  56%|█████▌    | 131/235 [00:10<00:07, 13.61it/s]\u001b[A\n",
            "Loss: 0.2075:  56%|█████▌    | 131/235 [00:10<00:07, 13.61it/s]\u001b[A\n",
            "Loss: 0.2014:  56%|█████▌    | 131/235 [00:10<00:07, 13.61it/s]\u001b[A\n",
            "Loss: 0.2014:  57%|█████▋    | 133/235 [00:10<00:07, 13.63it/s]\u001b[A\n",
            "Loss: 0.2213:  57%|█████▋    | 133/235 [00:10<00:07, 13.63it/s]\u001b[A\n",
            "Loss: 0.1919:  57%|█████▋    | 133/235 [00:10<00:07, 13.63it/s]\u001b[A\n",
            "Loss: 0.1919:  57%|█████▋    | 135/235 [00:10<00:07, 13.66it/s]\u001b[A\n",
            "Loss: 0.1970:  57%|█████▋    | 135/235 [00:10<00:07, 13.66it/s]\u001b[A\n",
            "Loss: 0.2275:  57%|█████▋    | 135/235 [00:10<00:07, 13.66it/s]\u001b[A\n",
            "Loss: 0.2275:  58%|█████▊    | 137/235 [00:10<00:07, 13.69it/s]\u001b[A\n",
            "Loss: 0.1837:  58%|█████▊    | 137/235 [00:10<00:07, 13.69it/s]\u001b[A\n",
            "Loss: 0.2007:  58%|█████▊    | 137/235 [00:10<00:07, 13.69it/s]\u001b[A\n",
            "Loss: 0.2007:  59%|█████▉    | 139/235 [00:10<00:06, 13.77it/s]\u001b[A\n",
            "Loss: 0.1907:  59%|█████▉    | 139/235 [00:10<00:06, 13.77it/s]\u001b[A\n",
            "Loss: 0.1732:  59%|█████▉    | 139/235 [00:10<00:06, 13.77it/s]\u001b[A\n",
            "Loss: 0.1732:  60%|██████    | 141/235 [00:10<00:06, 13.72it/s]\u001b[A\n",
            "Loss: 0.1892:  60%|██████    | 141/235 [00:10<00:06, 13.72it/s]\u001b[A\n",
            "Loss: 0.1881:  60%|██████    | 141/235 [00:11<00:06, 13.72it/s]\u001b[A\n",
            "Loss: 0.1881:  61%|██████    | 143/235 [00:11<00:06, 13.72it/s]\u001b[A\n",
            "Loss: 0.1964:  61%|██████    | 143/235 [00:11<00:06, 13.72it/s]\u001b[A\n",
            "Loss: 0.2093:  61%|██████    | 143/235 [00:11<00:06, 13.72it/s]\u001b[A\n",
            "Loss: 0.2093:  62%|██████▏   | 145/235 [00:11<00:06, 13.74it/s]\u001b[A\n",
            "Loss: 0.1915:  62%|██████▏   | 145/235 [00:11<00:06, 13.74it/s]\u001b[A\n",
            "Loss: 0.1901:  62%|██████▏   | 145/235 [00:11<00:06, 13.74it/s]\u001b[A\n",
            "Loss: 0.1901:  63%|██████▎   | 147/235 [00:11<00:06, 13.77it/s]\u001b[A\n",
            "Loss: 0.1939:  63%|██████▎   | 147/235 [00:11<00:06, 13.77it/s]\u001b[A\n",
            "Loss: 0.1841:  63%|██████▎   | 147/235 [00:11<00:06, 13.77it/s]\u001b[A\n",
            "Loss: 0.1841:  63%|██████▎   | 149/235 [00:11<00:06, 13.77it/s]\u001b[A\n",
            "Loss: 0.1955:  63%|██████▎   | 149/235 [00:11<00:06, 13.77it/s]\u001b[A\n",
            "Loss: 0.1926:  63%|██████▎   | 149/235 [00:11<00:06, 13.77it/s]\u001b[A\n",
            "Loss: 0.1926:  64%|██████▍   | 151/235 [00:11<00:06, 13.82it/s]\u001b[A\n",
            "Loss: 0.1916:  64%|██████▍   | 151/235 [00:11<00:06, 13.82it/s]\u001b[A\n",
            "Loss: 0.1803:  64%|██████▍   | 151/235 [00:11<00:06, 13.82it/s]\u001b[A\n",
            "Loss: 0.1803:  65%|██████▌   | 153/235 [00:11<00:05, 13.74it/s]\u001b[A\n",
            "Loss: 0.1884:  65%|██████▌   | 153/235 [00:11<00:05, 13.74it/s]\u001b[A\n",
            "Loss: 0.1826:  65%|██████▌   | 153/235 [00:11<00:05, 13.74it/s]\u001b[A\n",
            "Loss: 0.1826:  66%|██████▌   | 155/235 [00:11<00:05, 13.74it/s]\u001b[A\n",
            "Loss: 0.1888:  66%|██████▌   | 155/235 [00:12<00:05, 13.74it/s]\u001b[A\n",
            "Loss: 0.1707:  66%|██████▌   | 155/235 [00:12<00:05, 13.74it/s]\u001b[A\n",
            "Loss: 0.1707:  67%|██████▋   | 157/235 [00:12<00:05, 13.73it/s]\u001b[A\n",
            "Loss: 0.1850:  67%|██████▋   | 157/235 [00:12<00:05, 13.73it/s]\u001b[A\n",
            "Loss: 0.1596:  67%|██████▋   | 157/235 [00:12<00:05, 13.73it/s]\u001b[A\n",
            "Loss: 0.1596:  68%|██████▊   | 159/235 [00:12<00:05, 13.81it/s]\u001b[A\n",
            "Loss: 0.1709:  68%|██████▊   | 159/235 [00:12<00:05, 13.81it/s]\u001b[A\n",
            "Loss: 0.1680:  68%|██████▊   | 159/235 [00:12<00:05, 13.81it/s]\u001b[A\n",
            "Loss: 0.1680:  69%|██████▊   | 161/235 [00:12<00:05, 13.84it/s]\u001b[A\n",
            "Loss: 0.1521:  69%|██████▊   | 161/235 [00:12<00:05, 13.84it/s]\u001b[A\n",
            "Loss: 0.1810:  69%|██████▊   | 161/235 [00:12<00:05, 13.84it/s]\u001b[A\n",
            "Loss: 0.1810:  69%|██████▉   | 163/235 [00:12<00:05, 13.91it/s]\u001b[A\n",
            "Loss: 0.1518:  69%|██████▉   | 163/235 [00:12<00:05, 13.91it/s]\u001b[A\n",
            "Loss: 0.1583:  69%|██████▉   | 163/235 [00:12<00:05, 13.91it/s]\u001b[A\n",
            "Loss: 0.1583:  70%|███████   | 165/235 [00:12<00:05, 13.90it/s]\u001b[A\n",
            "Loss: 0.1760:  70%|███████   | 165/235 [00:12<00:05, 13.90it/s]\u001b[A\n",
            "Loss: 0.1635:  70%|███████   | 165/235 [00:12<00:05, 13.90it/s]\u001b[A\n",
            "Loss: 0.1635:  71%|███████   | 167/235 [00:12<00:04, 13.88it/s]\u001b[A\n",
            "Loss: 0.1652:  71%|███████   | 167/235 [00:12<00:04, 13.88it/s]\u001b[A\n",
            "Loss: 0.1737:  71%|███████   | 167/235 [00:12<00:04, 13.88it/s]\u001b[A\n",
            "Loss: 0.1737:  72%|███████▏  | 169/235 [00:12<00:04, 13.84it/s]\u001b[A\n",
            "Loss: 0.1620:  72%|███████▏  | 169/235 [00:13<00:04, 13.84it/s]\u001b[A\n",
            "Loss: 0.1555:  72%|███████▏  | 169/235 [00:13<00:04, 13.84it/s]\u001b[A\n",
            "Loss: 0.1555:  73%|███████▎  | 171/235 [00:13<00:04, 13.69it/s]\u001b[A\n",
            "Loss: 0.1639:  73%|███████▎  | 171/235 [00:13<00:04, 13.69it/s]\u001b[A\n",
            "Loss: 0.1741:  73%|███████▎  | 171/235 [00:13<00:04, 13.69it/s]\u001b[A\n",
            "Loss: 0.1741:  74%|███████▎  | 173/235 [00:13<00:04, 13.72it/s]\u001b[A\n",
            "Loss: 0.1586:  74%|███████▎  | 173/235 [00:13<00:04, 13.72it/s]\u001b[A\n",
            "Loss: 0.1481:  74%|███████▎  | 173/235 [00:13<00:04, 13.72it/s]\u001b[A\n",
            "Loss: 0.1481:  74%|███████▍  | 175/235 [00:13<00:04, 13.74it/s]\u001b[A\n",
            "Loss: 0.1659:  74%|███████▍  | 175/235 [00:13<00:04, 13.74it/s]\u001b[A\n",
            "Loss: 0.1606:  74%|███████▍  | 175/235 [00:13<00:04, 13.74it/s]\u001b[A\n",
            "Loss: 0.1606:  75%|███████▌  | 177/235 [00:13<00:04, 13.70it/s]\u001b[A\n",
            "Loss: 0.1463:  75%|███████▌  | 177/235 [00:13<00:04, 13.70it/s]\u001b[A\n",
            "Loss: 0.1558:  75%|███████▌  | 177/235 [00:13<00:04, 13.70it/s]\u001b[A\n",
            "Loss: 0.1558:  76%|███████▌  | 179/235 [00:13<00:04, 13.69it/s]\u001b[A\n",
            "Loss: 0.1479:  76%|███████▌  | 179/235 [00:13<00:04, 13.69it/s]\u001b[A\n",
            "Loss: 0.1532:  76%|███████▌  | 179/235 [00:13<00:04, 13.69it/s]\u001b[A\n",
            "Loss: 0.1532:  77%|███████▋  | 181/235 [00:13<00:03, 13.64it/s]\u001b[A\n",
            "Loss: 0.1419:  77%|███████▋  | 181/235 [00:13<00:03, 13.64it/s]\u001b[A\n",
            "Loss: 0.1406:  77%|███████▋  | 181/235 [00:13<00:03, 13.64it/s]\u001b[A\n",
            "Loss: 0.1406:  78%|███████▊  | 183/235 [00:13<00:03, 13.64it/s]\u001b[A\n",
            "Loss: 0.1746:  78%|███████▊  | 183/235 [00:14<00:03, 13.64it/s]\u001b[A\n",
            "Loss: 0.1517:  78%|███████▊  | 183/235 [00:14<00:03, 13.64it/s]\u001b[A\n",
            "Loss: 0.1517:  79%|███████▊  | 185/235 [00:14<00:03, 13.58it/s]\u001b[A\n",
            "Loss: 0.1624:  79%|███████▊  | 185/235 [00:14<00:03, 13.58it/s]\u001b[A\n",
            "Loss: 0.1499:  79%|███████▊  | 185/235 [00:14<00:03, 13.58it/s]\u001b[A\n",
            "Loss: 0.1499:  80%|███████▉  | 187/235 [00:14<00:03, 13.64it/s]\u001b[A\n",
            "Loss: 0.1657:  80%|███████▉  | 187/235 [00:14<00:03, 13.64it/s]\u001b[A\n",
            "Loss: 0.1568:  80%|███████▉  | 187/235 [00:14<00:03, 13.64it/s]\u001b[A\n",
            "Loss: 0.1568:  80%|████████  | 189/235 [00:14<00:03, 13.66it/s]\u001b[A\n",
            "Loss: 0.1652:  80%|████████  | 189/235 [00:14<00:03, 13.66it/s]\u001b[A\n",
            "Loss: 0.1624:  80%|████████  | 189/235 [00:14<00:03, 13.66it/s]\u001b[A\n",
            "Loss: 0.1624:  81%|████████▏ | 191/235 [00:14<00:03, 13.64it/s]\u001b[A\n",
            "Loss: 0.1599:  81%|████████▏ | 191/235 [00:14<00:03, 13.64it/s]\u001b[A\n",
            "Loss: 0.1557:  81%|████████▏ | 191/235 [00:14<00:03, 13.64it/s]\u001b[A\n",
            "Loss: 0.1557:  82%|████████▏ | 193/235 [00:14<00:03, 13.70it/s]\u001b[A\n",
            "Loss: 0.1516:  82%|████████▏ | 193/235 [00:14<00:03, 13.70it/s]\u001b[A\n",
            "Loss: 0.1473:  82%|████████▏ | 193/235 [00:14<00:03, 13.70it/s]\u001b[A\n",
            "Loss: 0.1473:  83%|████████▎ | 195/235 [00:14<00:02, 13.74it/s]\u001b[A\n",
            "Loss: 0.1616:  83%|████████▎ | 195/235 [00:14<00:02, 13.74it/s]\u001b[A\n",
            "Loss: 0.1498:  83%|████████▎ | 195/235 [00:14<00:02, 13.74it/s]\u001b[A\n",
            "Loss: 0.1498:  84%|████████▍ | 197/235 [00:14<00:02, 13.72it/s]\u001b[A\n",
            "Loss: 0.1307:  84%|████████▍ | 197/235 [00:15<00:02, 13.72it/s]\u001b[A\n",
            "Loss: 0.1561:  84%|████████▍ | 197/235 [00:15<00:02, 13.72it/s]\u001b[A\n",
            "Loss: 0.1561:  85%|████████▍ | 199/235 [00:15<00:02, 13.72it/s]\u001b[A\n",
            "Loss: 0.1515:  85%|████████▍ | 199/235 [00:15<00:02, 13.72it/s]\u001b[A\n",
            "Loss: 0.1313:  85%|████████▍ | 199/235 [00:15<00:02, 13.72it/s]\u001b[A\n",
            "Loss: 0.1313:  86%|████████▌ | 201/235 [00:15<00:02, 13.68it/s]\u001b[A\n",
            "Loss: 0.1431:  86%|████████▌ | 201/235 [00:15<00:02, 13.68it/s]\u001b[A\n",
            "Loss: 0.1384:  86%|████████▌ | 201/235 [00:15<00:02, 13.68it/s]\u001b[A\n",
            "Loss: 0.1384:  86%|████████▋ | 203/235 [00:15<00:02, 13.70it/s]\u001b[A\n",
            "Loss: 0.1447:  86%|████████▋ | 203/235 [00:15<00:02, 13.70it/s]\u001b[A\n",
            "Loss: 0.1333:  86%|████████▋ | 203/235 [00:15<00:02, 13.70it/s]\u001b[A\n",
            "Loss: 0.1333:  87%|████████▋ | 205/235 [00:15<00:02, 13.72it/s]\u001b[A\n",
            "Loss: 0.1481:  87%|████████▋ | 205/235 [00:15<00:02, 13.72it/s]\u001b[A\n",
            "Loss: 0.1469:  87%|████████▋ | 205/235 [00:15<00:02, 13.72it/s]\u001b[A\n",
            "Loss: 0.1469:  88%|████████▊ | 207/235 [00:15<00:02, 13.64it/s]\u001b[A\n",
            "Loss: 0.1470:  88%|████████▊ | 207/235 [00:15<00:02, 13.64it/s]\u001b[A\n",
            "Loss: 0.1500:  88%|████████▊ | 207/235 [00:15<00:02, 13.64it/s]\u001b[A\n",
            "Loss: 0.1500:  89%|████████▉ | 209/235 [00:15<00:01, 13.67it/s]\u001b[A\n",
            "Loss: 0.1354:  89%|████████▉ | 209/235 [00:15<00:01, 13.67it/s]\u001b[A\n",
            "Loss: 0.1340:  89%|████████▉ | 209/235 [00:16<00:01, 13.67it/s]\u001b[A\n",
            "Loss: 0.1340:  90%|████████▉ | 211/235 [00:16<00:01, 13.60it/s]\u001b[A\n",
            "Loss: 0.1279:  90%|████████▉ | 211/235 [00:16<00:01, 13.60it/s]\u001b[A\n",
            "Loss: 0.1443:  90%|████████▉ | 211/235 [00:16<00:01, 13.60it/s]\u001b[A\n",
            "Loss: 0.1443:  91%|█████████ | 213/235 [00:16<00:01, 13.67it/s]\u001b[A\n",
            "Loss: 0.1447:  91%|█████████ | 213/235 [00:16<00:01, 13.67it/s]\u001b[A\n",
            "Loss: 0.1452:  91%|█████████ | 213/235 [00:16<00:01, 13.67it/s]\u001b[A\n",
            "Loss: 0.1452:  91%|█████████▏| 215/235 [00:16<00:01, 13.71it/s]\u001b[A\n",
            "Loss: 0.1275:  91%|█████████▏| 215/235 [00:16<00:01, 13.71it/s]\u001b[A\n",
            "Loss: 0.1303:  91%|█████████▏| 215/235 [00:16<00:01, 13.71it/s]\u001b[A\n",
            "Loss: 0.1303:  92%|█████████▏| 217/235 [00:16<00:01, 13.78it/s]\u001b[A\n",
            "Loss: 0.1418:  92%|█████████▏| 217/235 [00:16<00:01, 13.78it/s]\u001b[A\n",
            "Loss: 0.1256:  92%|█████████▏| 217/235 [00:16<00:01, 13.78it/s]\u001b[A\n",
            "Loss: 0.1256:  93%|█████████▎| 219/235 [00:16<00:01, 13.72it/s]\u001b[A\n",
            "Loss: 0.1302:  93%|█████████▎| 219/235 [00:16<00:01, 13.72it/s]\u001b[A\n",
            "Loss: 0.1291:  93%|█████████▎| 219/235 [00:16<00:01, 13.72it/s]\u001b[A\n",
            "Loss: 0.1291:  94%|█████████▍| 221/235 [00:16<00:01, 13.40it/s]\u001b[A\n",
            "Loss: 0.1305:  94%|█████████▍| 221/235 [00:16<00:01, 13.40it/s]\u001b[A\n",
            "Loss: 0.1377:  94%|█████████▍| 221/235 [00:16<00:01, 13.40it/s]\u001b[A\n",
            "Loss: 0.1377:  95%|█████████▍| 223/235 [00:16<00:00, 13.43it/s]\u001b[A\n",
            "Loss: 0.1440:  95%|█████████▍| 223/235 [00:16<00:00, 13.43it/s]\u001b[A\n",
            "Loss: 0.1327:  95%|█████████▍| 223/235 [00:17<00:00, 13.43it/s]\u001b[A\n",
            "Loss: 0.1327:  96%|█████████▌| 225/235 [00:17<00:00, 13.43it/s]\u001b[A\n",
            "Loss: 0.1339:  96%|█████████▌| 225/235 [00:17<00:00, 13.43it/s]\u001b[A\n",
            "Loss: 0.1442:  96%|█████████▌| 225/235 [00:17<00:00, 13.43it/s]\u001b[A\n",
            "Loss: 0.1442:  97%|█████████▋| 227/235 [00:17<00:00, 13.45it/s]\u001b[A\n",
            "Loss: 0.1425:  97%|█████████▋| 227/235 [00:17<00:00, 13.45it/s]\u001b[A\n",
            "Loss: 0.1332:  97%|█████████▋| 227/235 [00:17<00:00, 13.45it/s]\u001b[A\n",
            "Loss: 0.1332:  97%|█████████▋| 229/235 [00:17<00:00, 13.50it/s]\u001b[A\n",
            "Loss: 0.1363:  97%|█████████▋| 229/235 [00:17<00:00, 13.50it/s]\u001b[A\n",
            "Loss: 0.1370:  97%|█████████▋| 229/235 [00:17<00:00, 13.50it/s]\u001b[A\n",
            "Loss: 0.1370:  98%|█████████▊| 231/235 [00:17<00:00, 13.55it/s]\u001b[A\n",
            "Loss: 0.1266:  98%|█████████▊| 231/235 [00:17<00:00, 13.55it/s]\u001b[A\n",
            "Loss: 0.1373:  98%|█████████▊| 231/235 [00:17<00:00, 13.55it/s]\u001b[A\n",
            "Loss: 0.1373:  99%|█████████▉| 233/235 [00:17<00:00, 13.41it/s]\u001b[A\n",
            "Loss: 0.1204:  99%|█████████▉| 233/235 [00:17<00:00, 13.41it/s]\u001b[A\n",
            "Loss: 0.1360:  99%|█████████▉| 233/235 [00:17<00:00, 13.41it/s]\u001b[A\n",
            "Loss: 0.1360: 100%|██████████| 235/235 [00:17<00:00, 13.15it/s]\u001b[A\n",
            "  1%|          | 1/100 [00:17<29:26, 17.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean loss for Epoch 1: 0.3876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 0.1420:   0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 0.1291:   0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 0.1291:   1%|          | 2/235 [00:00<00:17, 13.26it/s]\u001b[A\n",
            "Loss: 0.1307:   1%|          | 2/235 [00:00<00:17, 13.26it/s]\u001b[A\n",
            "Loss: 0.1217:   1%|          | 2/235 [00:00<00:17, 13.26it/s]\u001b[A\n",
            "Loss: 0.1217:   2%|▏         | 4/235 [00:00<00:17, 13.55it/s]\u001b[A\n",
            "Loss: 0.1254:   2%|▏         | 4/235 [00:00<00:17, 13.55it/s]\u001b[A\n",
            "Loss: 0.1206:   2%|▏         | 4/235 [00:00<00:17, 13.55it/s]\u001b[A\n",
            "Loss: 0.1206:   3%|▎         | 6/235 [00:00<00:16, 13.72it/s]\u001b[A\n",
            "Loss: 0.1258:   3%|▎         | 6/235 [00:00<00:16, 13.72it/s]\u001b[A\n",
            "Loss: 0.1284:   3%|▎         | 6/235 [00:00<00:16, 13.72it/s]\u001b[A\n",
            "Loss: 0.1284:   3%|▎         | 8/235 [00:00<00:16, 13.81it/s]\u001b[A\n",
            "Loss: 0.1281:   3%|▎         | 8/235 [00:00<00:16, 13.81it/s]\u001b[A\n",
            "Loss: 0.1307:   3%|▎         | 8/235 [00:00<00:16, 13.81it/s]\u001b[A\n",
            "Loss: 0.1307:   4%|▍         | 10/235 [00:00<00:16, 13.83it/s]\u001b[A\n",
            "Loss: 0.1213:   4%|▍         | 10/235 [00:00<00:16, 13.83it/s]\u001b[A\n",
            "Loss: 0.1167:   4%|▍         | 10/235 [00:00<00:16, 13.83it/s]\u001b[A\n",
            "Loss: 0.1167:   5%|▌         | 12/235 [00:00<00:16, 13.80it/s]\u001b[A\n",
            "Loss: 0.1297:   5%|▌         | 12/235 [00:00<00:16, 13.80it/s]\u001b[A\n",
            "Loss: 0.1158:   5%|▌         | 12/235 [00:01<00:16, 13.80it/s]\u001b[A\n",
            "Loss: 0.1158:   6%|▌         | 14/235 [00:01<00:15, 13.82it/s]\u001b[A\n",
            "Loss: 0.1175:   6%|▌         | 14/235 [00:01<00:15, 13.82it/s]\u001b[A\n",
            "Loss: 0.1330:   6%|▌         | 14/235 [00:01<00:15, 13.82it/s]\u001b[A\n",
            "Loss: 0.1330:   7%|▋         | 16/235 [00:01<00:15, 13.72it/s]\u001b[A\n",
            "Loss: 0.1222:   7%|▋         | 16/235 [00:01<00:15, 13.72it/s]\u001b[A\n",
            "Loss: 0.1283:   7%|▋         | 16/235 [00:01<00:15, 13.72it/s]\u001b[A\n",
            "Loss: 0.1283:   8%|▊         | 18/235 [00:01<00:15, 13.73it/s]\u001b[A\n",
            "Loss: 0.1122:   8%|▊         | 18/235 [00:01<00:15, 13.73it/s]\u001b[A\n",
            "Loss: 0.1201:   8%|▊         | 18/235 [00:01<00:15, 13.73it/s]\u001b[A\n",
            "Loss: 0.1201:   9%|▊         | 20/235 [00:01<00:15, 13.79it/s]\u001b[A\n",
            "Loss: 0.1252:   9%|▊         | 20/235 [00:01<00:15, 13.79it/s]\u001b[A\n",
            "Loss: 0.1208:   9%|▊         | 20/235 [00:01<00:15, 13.79it/s]\u001b[A\n",
            "Loss: 0.1208:   9%|▉         | 22/235 [00:01<00:15, 13.81it/s]\u001b[A\n",
            "Loss: 0.1187:   9%|▉         | 22/235 [00:01<00:15, 13.81it/s]\u001b[A\n",
            "Loss: 0.1178:   9%|▉         | 22/235 [00:01<00:15, 13.81it/s]\u001b[A\n",
            "Loss: 0.1178:  10%|█         | 24/235 [00:01<00:15, 13.77it/s]\u001b[A\n",
            "Loss: 0.1308:  10%|█         | 24/235 [00:01<00:15, 13.77it/s]\u001b[A\n",
            "Loss: 0.1267:  10%|█         | 24/235 [00:01<00:15, 13.77it/s]\u001b[A\n",
            "Loss: 0.1267:  11%|█         | 26/235 [00:01<00:15, 13.82it/s]\u001b[A\n",
            "Loss: 0.1224:  11%|█         | 26/235 [00:01<00:15, 13.82it/s]\u001b[A\n",
            "Loss: 0.1242:  11%|█         | 26/235 [00:02<00:15, 13.82it/s]\u001b[A\n",
            "Loss: 0.1242:  12%|█▏        | 28/235 [00:02<00:14, 13.84it/s]\u001b[A\n",
            "Loss: 0.1109:  12%|█▏        | 28/235 [00:02<00:14, 13.84it/s]\u001b[A\n",
            "Loss: 0.1192:  12%|█▏        | 28/235 [00:02<00:14, 13.84it/s]\u001b[A\n",
            "Loss: 0.1192:  13%|█▎        | 30/235 [00:02<00:14, 13.78it/s]\u001b[A\n",
            "Loss: 0.1231:  13%|█▎        | 30/235 [00:02<00:14, 13.78it/s]\u001b[A\n",
            "Loss: 0.1076:  13%|█▎        | 30/235 [00:02<00:14, 13.78it/s]\u001b[A\n",
            "Loss: 0.1076:  14%|█▎        | 32/235 [00:02<00:14, 13.80it/s]\u001b[A\n",
            "Loss: 0.1092:  14%|█▎        | 32/235 [00:02<00:14, 13.80it/s]\u001b[A\n",
            "Loss: 0.1074:  14%|█▎        | 32/235 [00:02<00:14, 13.80it/s]\u001b[A\n",
            "Loss: 0.1074:  14%|█▍        | 34/235 [00:02<00:14, 13.83it/s]\u001b[A\n",
            "Loss: 0.1122:  14%|█▍        | 34/235 [00:02<00:14, 13.83it/s]\u001b[A\n",
            "Loss: 0.1095:  14%|█▍        | 34/235 [00:02<00:14, 13.83it/s]\u001b[A\n",
            "Loss: 0.1095:  15%|█▌        | 36/235 [00:02<00:14, 13.86it/s]\u001b[A\n",
            "Loss: 0.1191:  15%|█▌        | 36/235 [00:02<00:14, 13.86it/s]\u001b[A\n",
            "Loss: 0.1161:  15%|█▌        | 36/235 [00:02<00:14, 13.86it/s]\u001b[A\n",
            "Loss: 0.1161:  16%|█▌        | 38/235 [00:02<00:14, 13.80it/s]\u001b[A\n",
            "Loss: 0.1267:  16%|█▌        | 38/235 [00:02<00:14, 13.80it/s]\u001b[A\n",
            "Loss: 0.1121:  16%|█▌        | 38/235 [00:02<00:14, 13.80it/s]\u001b[A\n",
            "Loss: 0.1121:  17%|█▋        | 40/235 [00:02<00:14, 13.83it/s]\u001b[A\n",
            "Loss: 0.1160:  17%|█▋        | 40/235 [00:02<00:14, 13.83it/s]\u001b[A\n",
            "Loss: 0.1294:  17%|█▋        | 40/235 [00:03<00:14, 13.83it/s]\u001b[A\n",
            "Loss: 0.1294:  18%|█▊        | 42/235 [00:03<00:13, 13.86it/s]\u001b[A\n",
            "Loss: 0.1096:  18%|█▊        | 42/235 [00:03<00:13, 13.86it/s]\u001b[A\n",
            "Loss: 0.1294:  18%|█▊        | 42/235 [00:03<00:13, 13.86it/s]\u001b[A\n",
            "Loss: 0.1294:  19%|█▊        | 44/235 [00:03<00:13, 13.82it/s]\u001b[A\n",
            "Loss: 0.1176:  19%|█▊        | 44/235 [00:03<00:13, 13.82it/s]\u001b[A\n",
            "Loss: 0.1040:  19%|█▊        | 44/235 [00:03<00:13, 13.82it/s]\u001b[A\n",
            "Loss: 0.1040:  20%|█▉        | 46/235 [00:03<00:13, 13.81it/s]\u001b[A\n",
            "Loss: 0.1199:  20%|█▉        | 46/235 [00:03<00:13, 13.81it/s]\u001b[A\n",
            "Loss: 0.1138:  20%|█▉        | 46/235 [00:03<00:13, 13.81it/s]\u001b[A\n",
            "Loss: 0.1138:  20%|██        | 48/235 [00:03<00:13, 13.83it/s]\u001b[A\n",
            "Loss: 0.1087:  20%|██        | 48/235 [00:03<00:13, 13.83it/s]\u001b[A\n",
            "Loss: 0.1143:  20%|██        | 48/235 [00:03<00:13, 13.83it/s]\u001b[A\n",
            "Loss: 0.1143:  21%|██▏       | 50/235 [00:03<00:13, 13.83it/s]\u001b[A\n",
            "Loss: 0.1168:  21%|██▏       | 50/235 [00:03<00:13, 13.83it/s]\u001b[A\n",
            "Loss: 0.1109:  21%|██▏       | 50/235 [00:03<00:13, 13.83it/s]\u001b[A\n",
            "Loss: 0.1109:  22%|██▏       | 52/235 [00:03<00:13, 13.83it/s]\u001b[A\n",
            "Loss: 0.1149:  22%|██▏       | 52/235 [00:03<00:13, 13.83it/s]\u001b[A\n",
            "Loss: 0.1071:  22%|██▏       | 52/235 [00:03<00:13, 13.83it/s]\u001b[A\n",
            "Loss: 0.1071:  23%|██▎       | 54/235 [00:03<00:13, 13.80it/s]\u001b[A\n",
            "Loss: 0.1254:  23%|██▎       | 54/235 [00:03<00:13, 13.80it/s]\u001b[A\n",
            "Loss: 0.1176:  23%|██▎       | 54/235 [00:04<00:13, 13.80it/s]\u001b[A\n",
            "Loss: 0.1176:  24%|██▍       | 56/235 [00:04<00:12, 13.83it/s]\u001b[A\n",
            "Loss: 0.1087:  24%|██▍       | 56/235 [00:04<00:12, 13.83it/s]\u001b[A\n",
            "Loss: 0.1132:  24%|██▍       | 56/235 [00:04<00:12, 13.83it/s]\u001b[A\n",
            "Loss: 0.1132:  25%|██▍       | 58/235 [00:04<00:12, 13.68it/s]\u001b[A\n",
            "Loss: 0.1105:  25%|██▍       | 58/235 [00:04<00:12, 13.68it/s]\u001b[A\n",
            "Loss: 0.1132:  25%|██▍       | 58/235 [00:04<00:12, 13.68it/s]\u001b[A\n",
            "Loss: 0.1132:  26%|██▌       | 60/235 [00:04<00:12, 13.70it/s]\u001b[A\n",
            "Loss: 0.1121:  26%|██▌       | 60/235 [00:04<00:12, 13.70it/s]\u001b[A\n",
            "Loss: 0.1018:  26%|██▌       | 60/235 [00:04<00:12, 13.70it/s]\u001b[A\n",
            "Loss: 0.1018:  26%|██▋       | 62/235 [00:04<00:12, 13.68it/s]\u001b[A\n",
            "Loss: 0.1177:  26%|██▋       | 62/235 [00:04<00:12, 13.68it/s]\u001b[A\n",
            "Loss: 0.1134:  26%|██▋       | 62/235 [00:04<00:12, 13.68it/s]\u001b[A\n",
            "Loss: 0.1134:  27%|██▋       | 64/235 [00:04<00:12, 13.67it/s]\u001b[A\n",
            "Loss: 0.1136:  27%|██▋       | 64/235 [00:04<00:12, 13.67it/s]\u001b[A\n",
            "Loss: 0.1153:  27%|██▋       | 64/235 [00:04<00:12, 13.67it/s]\u001b[A\n",
            "Loss: 0.1153:  28%|██▊       | 66/235 [00:04<00:12, 13.74it/s]\u001b[A\n",
            "Loss: 0.0902:  28%|██▊       | 66/235 [00:04<00:12, 13.74it/s]\u001b[A\n",
            "Loss: 0.1282:  28%|██▊       | 66/235 [00:04<00:12, 13.74it/s]\u001b[A\n",
            "Loss: 0.1282:  29%|██▉       | 68/235 [00:04<00:12, 13.80it/s]\u001b[A\n",
            "Loss: 0.1174:  29%|██▉       | 68/235 [00:05<00:12, 13.80it/s]\u001b[A\n",
            "Loss: 0.1052:  29%|██▉       | 68/235 [00:05<00:12, 13.80it/s]\u001b[A\n",
            "Loss: 0.1052:  30%|██▉       | 70/235 [00:05<00:11, 13.81it/s]\u001b[A\n",
            "Loss: 0.1049:  30%|██▉       | 70/235 [00:05<00:11, 13.81it/s]\u001b[A\n",
            "Loss: 0.1106:  30%|██▉       | 70/235 [00:05<00:11, 13.81it/s]\u001b[A\n",
            "Loss: 0.1106:  31%|███       | 72/235 [00:05<00:11, 13.73it/s]\u001b[A\n",
            "Loss: 0.1045:  31%|███       | 72/235 [00:05<00:11, 13.73it/s]\u001b[A\n",
            "Loss: 0.1043:  31%|███       | 72/235 [00:05<00:11, 13.73it/s]\u001b[A\n",
            "Loss: 0.1043:  31%|███▏      | 74/235 [00:05<00:11, 13.76it/s]\u001b[A\n",
            "Loss: 0.1062:  31%|███▏      | 74/235 [00:05<00:11, 13.76it/s]\u001b[A\n",
            "Loss: 0.1067:  31%|███▏      | 74/235 [00:05<00:11, 13.76it/s]\u001b[A\n",
            "Loss: 0.1067:  32%|███▏      | 76/235 [00:05<00:11, 13.82it/s]\u001b[A\n",
            "Loss: 0.1034:  32%|███▏      | 76/235 [00:05<00:11, 13.82it/s]\u001b[A\n",
            "Loss: 0.1090:  32%|███▏      | 76/235 [00:05<00:11, 13.82it/s]\u001b[A\n",
            "Loss: 0.1090:  33%|███▎      | 78/235 [00:05<00:11, 13.74it/s]\u001b[A\n",
            "Loss: 0.1036:  33%|███▎      | 78/235 [00:05<00:11, 13.74it/s]\u001b[A\n",
            "Loss: 0.1153:  33%|███▎      | 78/235 [00:05<00:11, 13.74it/s]\u001b[A\n",
            "Loss: 0.1153:  34%|███▍      | 80/235 [00:05<00:11, 13.80it/s]\u001b[A\n",
            "Loss: 0.1136:  34%|███▍      | 80/235 [00:05<00:11, 13.80it/s]\u001b[A\n",
            "Loss: 0.1056:  34%|███▍      | 80/235 [00:05<00:11, 13.80it/s]\u001b[A\n",
            "Loss: 0.1056:  35%|███▍      | 82/235 [00:05<00:11, 13.77it/s]\u001b[A\n",
            "Loss: 0.0990:  35%|███▍      | 82/235 [00:06<00:11, 13.77it/s]\u001b[A\n",
            "Loss: 0.1060:  35%|███▍      | 82/235 [00:06<00:11, 13.77it/s]\u001b[A\n",
            "Loss: 0.1060:  36%|███▌      | 84/235 [00:06<00:11, 13.70it/s]\u001b[A\n",
            "Loss: 0.0918:  36%|███▌      | 84/235 [00:06<00:11, 13.70it/s]\u001b[A\n",
            "Loss: 0.1059:  36%|███▌      | 84/235 [00:06<00:11, 13.70it/s]\u001b[A\n",
            "Loss: 0.1059:  37%|███▋      | 86/235 [00:06<00:10, 13.71it/s]\u001b[A\n",
            "Loss: 0.1014:  37%|███▋      | 86/235 [00:06<00:10, 13.71it/s]\u001b[A\n",
            "Loss: 0.1138:  37%|███▋      | 86/235 [00:06<00:10, 13.71it/s]\u001b[A\n",
            "Loss: 0.1138:  37%|███▋      | 88/235 [00:06<00:10, 13.75it/s]\u001b[A\n",
            "Loss: 0.1093:  37%|███▋      | 88/235 [00:06<00:10, 13.75it/s]\u001b[A\n",
            "Loss: 0.1031:  37%|███▋      | 88/235 [00:06<00:10, 13.75it/s]\u001b[A\n",
            "Loss: 0.1031:  38%|███▊      | 90/235 [00:06<00:10, 13.73it/s]\u001b[A\n",
            "Loss: 0.1059:  38%|███▊      | 90/235 [00:06<00:10, 13.73it/s]\u001b[A\n",
            "Loss: 0.1046:  38%|███▊      | 90/235 [00:06<00:10, 13.73it/s]\u001b[A\n",
            "Loss: 0.1046:  39%|███▉      | 92/235 [00:06<00:10, 13.78it/s]\u001b[A\n",
            "Loss: 0.0966:  39%|███▉      | 92/235 [00:06<00:10, 13.78it/s]\u001b[A\n",
            "Loss: 0.1001:  39%|███▉      | 92/235 [00:06<00:10, 13.78it/s]\u001b[A\n",
            "Loss: 0.1001:  40%|████      | 94/235 [00:06<00:10, 13.82it/s]\u001b[A\n",
            "Loss: 0.0999:  40%|████      | 94/235 [00:06<00:10, 13.82it/s]\u001b[A\n",
            "Loss: 0.1219:  40%|████      | 94/235 [00:06<00:10, 13.82it/s]\u001b[A\n",
            "Loss: 0.1219:  41%|████      | 96/235 [00:06<00:10, 13.78it/s]\u001b[A\n",
            "Loss: 0.1126:  41%|████      | 96/235 [00:07<00:10, 13.78it/s]\u001b[A\n",
            "Loss: 0.1040:  41%|████      | 96/235 [00:07<00:10, 13.78it/s]\u001b[A\n",
            "Loss: 0.1040:  42%|████▏     | 98/235 [00:07<00:09, 13.78it/s]\u001b[A\n",
            "Loss: 0.1112:  42%|████▏     | 98/235 [00:07<00:09, 13.78it/s]\u001b[A\n",
            "Loss: 0.1016:  42%|████▏     | 98/235 [00:07<00:09, 13.78it/s]\u001b[A\n",
            "Loss: 0.1016:  43%|████▎     | 100/235 [00:07<00:09, 13.81it/s]\u001b[A\n",
            "Loss: 0.1049:  43%|████▎     | 100/235 [00:07<00:09, 13.81it/s]\u001b[A\n",
            "Loss: 0.1104:  43%|████▎     | 100/235 [00:07<00:09, 13.81it/s]\u001b[A\n",
            "Loss: 0.1104:  43%|████▎     | 102/235 [00:07<00:09, 13.80it/s]\u001b[A\n",
            "Loss: 0.0961:  43%|████▎     | 102/235 [00:07<00:09, 13.80it/s]\u001b[A\n",
            "Loss: 0.1024:  43%|████▎     | 102/235 [00:07<00:09, 13.80it/s]\u001b[A\n",
            "Loss: 0.1024:  44%|████▍     | 104/235 [00:07<00:09, 13.79it/s]\u001b[A\n",
            "Loss: 0.1163:  44%|████▍     | 104/235 [00:07<00:09, 13.79it/s]\u001b[A\n",
            "Loss: 0.0918:  44%|████▍     | 104/235 [00:07<00:09, 13.79it/s]\u001b[A\n",
            "Loss: 0.0918:  45%|████▌     | 106/235 [00:07<00:09, 13.82it/s]\u001b[A\n",
            "Loss: 0.1149:  45%|████▌     | 106/235 [00:07<00:09, 13.82it/s]\u001b[A\n",
            "Loss: 0.1012:  45%|████▌     | 106/235 [00:07<00:09, 13.82it/s]\u001b[A\n",
            "Loss: 0.1012:  46%|████▌     | 108/235 [00:07<00:09, 13.77it/s]\u001b[A\n",
            "Loss: 0.1103:  46%|████▌     | 108/235 [00:07<00:09, 13.77it/s]\u001b[A\n",
            "Loss: 0.1045:  46%|████▌     | 108/235 [00:07<00:09, 13.77it/s]\u001b[A\n",
            "Loss: 0.1045:  47%|████▋     | 110/235 [00:07<00:09, 13.81it/s]\u001b[A\n",
            "Loss: 0.0998:  47%|████▋     | 110/235 [00:08<00:09, 13.81it/s]\u001b[A\n",
            "Loss: 0.1015:  47%|████▋     | 110/235 [00:08<00:09, 13.81it/s]\u001b[A\n",
            "Loss: 0.1015:  48%|████▊     | 112/235 [00:08<00:08, 13.80it/s]\u001b[A\n",
            "Loss: 0.1037:  48%|████▊     | 112/235 [00:08<00:08, 13.80it/s]\u001b[A\n",
            "Loss: 0.1040:  48%|████▊     | 112/235 [00:08<00:08, 13.80it/s]\u001b[A\n",
            "Loss: 0.1040:  49%|████▊     | 114/235 [00:08<00:08, 13.85it/s]\u001b[A\n",
            "Loss: 0.0990:  49%|████▊     | 114/235 [00:08<00:08, 13.85it/s]\u001b[A\n",
            "Loss: 0.1174:  49%|████▊     | 114/235 [00:08<00:08, 13.85it/s]\u001b[A\n",
            "Loss: 0.1174:  49%|████▉     | 116/235 [00:08<00:08, 13.86it/s]\u001b[A\n",
            "Loss: 0.1052:  49%|████▉     | 116/235 [00:08<00:08, 13.86it/s]\u001b[A\n",
            "Loss: 0.1136:  49%|████▉     | 116/235 [00:08<00:08, 13.86it/s]\u001b[A\n",
            "Loss: 0.1136:  50%|█████     | 118/235 [00:08<00:08, 13.86it/s]\u001b[A\n",
            "Loss: 0.1056:  50%|█████     | 118/235 [00:08<00:08, 13.86it/s]\u001b[A\n",
            "Loss: 0.0996:  50%|█████     | 118/235 [00:08<00:08, 13.86it/s]\u001b[A\n",
            "Loss: 0.0996:  51%|█████     | 120/235 [00:08<00:08, 13.87it/s]\u001b[A\n",
            "Loss: 0.1024:  51%|█████     | 120/235 [00:08<00:08, 13.87it/s]\u001b[A\n",
            "Loss: 0.1067:  51%|█████     | 120/235 [00:08<00:08, 13.87it/s]\u001b[A\n",
            "Loss: 0.1067:  52%|█████▏    | 122/235 [00:08<00:08, 13.87it/s]\u001b[A\n",
            "Loss: 0.1006:  52%|█████▏    | 122/235 [00:08<00:08, 13.87it/s]\u001b[A\n",
            "Loss: 0.1084:  52%|█████▏    | 122/235 [00:08<00:08, 13.87it/s]\u001b[A\n",
            "Loss: 0.1084:  53%|█████▎    | 124/235 [00:08<00:08, 13.75it/s]\u001b[A\n",
            "Loss: 0.0999:  53%|█████▎    | 124/235 [00:09<00:08, 13.75it/s]\u001b[A\n",
            "Loss: 0.0956:  53%|█████▎    | 124/235 [00:09<00:08, 13.75it/s]\u001b[A\n",
            "Loss: 0.0956:  54%|█████▎    | 126/235 [00:09<00:07, 13.64it/s]\u001b[A\n",
            "Loss: 0.0897:  54%|█████▎    | 126/235 [00:09<00:07, 13.64it/s]\u001b[A\n",
            "Loss: 0.1089:  54%|█████▎    | 126/235 [00:09<00:07, 13.64it/s]\u001b[A\n",
            "Loss: 0.1089:  54%|█████▍    | 128/235 [00:09<00:07, 13.65it/s]\u001b[A\n",
            "Loss: 0.0911:  54%|█████▍    | 128/235 [00:09<00:07, 13.65it/s]\u001b[A\n",
            "Loss: 0.1000:  54%|█████▍    | 128/235 [00:09<00:07, 13.65it/s]\u001b[A\n",
            "Loss: 0.1000:  55%|█████▌    | 130/235 [00:09<00:07, 13.68it/s]\u001b[A\n",
            "Loss: 0.0983:  55%|█████▌    | 130/235 [00:09<00:07, 13.68it/s]\u001b[A\n",
            "Loss: 0.0955:  55%|█████▌    | 130/235 [00:09<00:07, 13.68it/s]\u001b[A\n",
            "Loss: 0.0955:  56%|█████▌    | 132/235 [00:09<00:07, 13.72it/s]\u001b[A\n",
            "Loss: 0.0943:  56%|█████▌    | 132/235 [00:09<00:07, 13.72it/s]\u001b[A\n",
            "Loss: 0.1090:  56%|█████▌    | 132/235 [00:09<00:07, 13.72it/s]\u001b[A\n",
            "Loss: 0.1090:  57%|█████▋    | 134/235 [00:09<00:07, 13.79it/s]\u001b[A\n",
            "Loss: 0.1065:  57%|█████▋    | 134/235 [00:09<00:07, 13.79it/s]\u001b[A\n",
            "Loss: 0.0975:  57%|█████▋    | 134/235 [00:09<00:07, 13.79it/s]\u001b[A\n",
            "Loss: 0.0975:  58%|█████▊    | 136/235 [00:09<00:07, 13.70it/s]\u001b[A\n",
            "Loss: 0.1015:  58%|█████▊    | 136/235 [00:09<00:07, 13.70it/s]\u001b[A\n",
            "Loss: 0.1011:  58%|█████▊    | 136/235 [00:10<00:07, 13.70it/s]\u001b[A\n",
            "Loss: 0.1011:  59%|█████▊    | 138/235 [00:10<00:07, 13.72it/s]\u001b[A\n",
            "Loss: 0.0946:  59%|█████▊    | 138/235 [00:10<00:07, 13.72it/s]\u001b[A\n",
            "Loss: 0.0968:  59%|█████▊    | 138/235 [00:10<00:07, 13.72it/s]\u001b[A\n",
            "Loss: 0.0968:  60%|█████▉    | 140/235 [00:10<00:06, 13.65it/s]\u001b[A\n",
            "Loss: 0.0991:  60%|█████▉    | 140/235 [00:10<00:06, 13.65it/s]\u001b[A\n",
            "Loss: 0.0951:  60%|█████▉    | 140/235 [00:10<00:06, 13.65it/s]\u001b[A\n",
            "Loss: 0.0951:  60%|██████    | 142/235 [00:10<00:06, 13.48it/s]\u001b[A\n",
            "Loss: 0.0913:  60%|██████    | 142/235 [00:10<00:06, 13.48it/s]\u001b[A\n",
            "Loss: 0.0928:  60%|██████    | 142/235 [00:10<00:06, 13.48it/s]\u001b[A\n",
            "Loss: 0.0928:  61%|██████▏   | 144/235 [00:10<00:06, 13.53it/s]\u001b[A\n",
            "Loss: 0.0919:  61%|██████▏   | 144/235 [00:10<00:06, 13.53it/s]\u001b[A\n",
            "Loss: 0.0984:  61%|██████▏   | 144/235 [00:10<00:06, 13.53it/s]\u001b[A\n",
            "Loss: 0.0984:  62%|██████▏   | 146/235 [00:10<00:06, 13.54it/s]\u001b[A\n",
            "Loss: 0.0950:  62%|██████▏   | 146/235 [00:10<00:06, 13.54it/s]\u001b[A\n",
            "Loss: 0.0928:  62%|██████▏   | 146/235 [00:10<00:06, 13.54it/s]\u001b[A\n",
            "Loss: 0.0928:  63%|██████▎   | 148/235 [00:10<00:06, 13.51it/s]\u001b[A\n",
            "Loss: 0.0955:  63%|██████▎   | 148/235 [00:10<00:06, 13.51it/s]\u001b[A\n",
            "Loss: 0.0967:  63%|██████▎   | 148/235 [00:10<00:06, 13.51it/s]\u001b[A\n",
            "Loss: 0.0967:  64%|██████▍   | 150/235 [00:10<00:06, 13.57it/s]\u001b[A\n",
            "Loss: 0.1112:  64%|██████▍   | 150/235 [00:10<00:06, 13.57it/s]\u001b[A\n",
            "Loss: 0.0952:  64%|██████▍   | 150/235 [00:11<00:06, 13.57it/s]\u001b[A\n",
            "Loss: 0.0952:  65%|██████▍   | 152/235 [00:11<00:06, 13.52it/s]\u001b[A\n",
            "Loss: 0.0931:  65%|██████▍   | 152/235 [00:11<00:06, 13.52it/s]\u001b[A\n",
            "Loss: 0.0911:  65%|██████▍   | 152/235 [00:11<00:06, 13.52it/s]\u001b[A\n",
            "Loss: 0.0911:  66%|██████▌   | 154/235 [00:11<00:06, 13.34it/s]\u001b[A\n",
            "Loss: 0.1098:  66%|██████▌   | 154/235 [00:11<00:06, 13.34it/s]\u001b[A\n",
            "Loss: 0.1076:  66%|██████▌   | 154/235 [00:11<00:06, 13.34it/s]\u001b[A\n",
            "Loss: 0.1076:  66%|██████▋   | 156/235 [00:11<00:05, 13.38it/s]\u001b[A\n",
            "Loss: 0.0914:  66%|██████▋   | 156/235 [00:11<00:05, 13.38it/s]\u001b[A\n",
            "Loss: 0.0994:  66%|██████▋   | 156/235 [00:11<00:05, 13.38it/s]\u001b[A\n",
            "Loss: 0.0994:  67%|██████▋   | 158/235 [00:11<00:05, 12.95it/s]\u001b[A\n",
            "Loss: 0.0956:  67%|██████▋   | 158/235 [00:11<00:05, 12.95it/s]\u001b[A\n",
            "Loss: 0.0906:  67%|██████▋   | 158/235 [00:11<00:05, 12.95it/s]\u001b[A\n",
            "Loss: 0.0906:  68%|██████▊   | 160/235 [00:11<00:05, 13.07it/s]\u001b[A\n",
            "Loss: 0.0919:  68%|██████▊   | 160/235 [00:11<00:05, 13.07it/s]\u001b[A\n",
            "Loss: 0.1092:  68%|██████▊   | 160/235 [00:11<00:05, 13.07it/s]\u001b[A\n",
            "Loss: 0.1092:  69%|██████▉   | 162/235 [00:11<00:05, 13.30it/s]\u001b[A\n",
            "Loss: 0.0874:  69%|██████▉   | 162/235 [00:11<00:05, 13.30it/s]\u001b[A\n",
            "Loss: 0.1059:  69%|██████▉   | 162/235 [00:11<00:05, 13.30it/s]\u001b[A\n",
            "Loss: 0.1059:  70%|██████▉   | 164/235 [00:11<00:05, 13.44it/s]\u001b[A\n",
            "Loss: 0.0967:  70%|██████▉   | 164/235 [00:12<00:05, 13.44it/s]\u001b[A\n",
            "Loss: 0.1074:  70%|██████▉   | 164/235 [00:12<00:05, 13.44it/s]\u001b[A\n",
            "Loss: 0.1074:  71%|███████   | 166/235 [00:12<00:05, 13.49it/s]\u001b[A\n",
            "Loss: 0.0972:  71%|███████   | 166/235 [00:12<00:05, 13.49it/s]\u001b[A\n",
            "Loss: 0.0946:  71%|███████   | 166/235 [00:12<00:05, 13.49it/s]\u001b[A\n",
            "Loss: 0.0946:  71%|███████▏  | 168/235 [00:12<00:04, 13.60it/s]\u001b[A\n",
            "Loss: 0.0904:  71%|███████▏  | 168/235 [00:12<00:04, 13.60it/s]\u001b[A\n",
            "Loss: 0.0889:  71%|███████▏  | 168/235 [00:12<00:04, 13.60it/s]\u001b[A\n",
            "Loss: 0.0889:  72%|███████▏  | 170/235 [00:12<00:04, 13.69it/s]\u001b[A\n",
            "Loss: 0.0984:  72%|███████▏  | 170/235 [00:12<00:04, 13.69it/s]\u001b[A\n",
            "Loss: 0.1107:  72%|███████▏  | 170/235 [00:12<00:04, 13.69it/s]\u001b[A\n",
            "Loss: 0.1107:  73%|███████▎  | 172/235 [00:12<00:04, 13.63it/s]\u001b[A\n",
            "Loss: 0.0941:  73%|███████▎  | 172/235 [00:12<00:04, 13.63it/s]\u001b[A\n",
            "Loss: 0.0897:  73%|███████▎  | 172/235 [00:12<00:04, 13.63it/s]\u001b[A\n",
            "Loss: 0.0897:  74%|███████▍  | 174/235 [00:12<00:04, 13.68it/s]\u001b[A\n",
            "Loss: 0.0926:  74%|███████▍  | 174/235 [00:12<00:04, 13.68it/s]\u001b[A\n",
            "Loss: 0.1064:  74%|███████▍  | 174/235 [00:12<00:04, 13.68it/s]\u001b[A\n",
            "Loss: 0.1064:  75%|███████▍  | 176/235 [00:12<00:04, 13.72it/s]\u001b[A\n",
            "Loss: 0.0957:  75%|███████▍  | 176/235 [00:12<00:04, 13.72it/s]\u001b[A\n",
            "Loss: 0.0989:  75%|███████▍  | 176/235 [00:12<00:04, 13.72it/s]\u001b[A\n",
            "Loss: 0.0989:  76%|███████▌  | 178/235 [00:12<00:04, 13.78it/s]\u001b[A\n",
            "Loss: 0.0917:  76%|███████▌  | 178/235 [00:13<00:04, 13.78it/s]\u001b[A\n",
            "Loss: 0.0911:  76%|███████▌  | 178/235 [00:13<00:04, 13.78it/s]\u001b[A\n",
            "Loss: 0.0911:  77%|███████▋  | 180/235 [00:13<00:03, 13.76it/s]\u001b[A\n",
            "Loss: 0.0910:  77%|███████▋  | 180/235 [00:13<00:03, 13.76it/s]\u001b[A\n",
            "Loss: 0.0886:  77%|███████▋  | 180/235 [00:13<00:03, 13.76it/s]\u001b[A\n",
            "Loss: 0.0886:  77%|███████▋  | 182/235 [00:13<00:03, 13.77it/s]\u001b[A\n",
            "Loss: 0.1001:  77%|███████▋  | 182/235 [00:13<00:03, 13.77it/s]\u001b[A\n",
            "Loss: 0.1055:  77%|███████▋  | 182/235 [00:13<00:03, 13.77it/s]\u001b[A\n",
            "Loss: 0.1055:  78%|███████▊  | 184/235 [00:13<00:03, 13.81it/s]\u001b[A\n",
            "Loss: 0.0941:  78%|███████▊  | 184/235 [00:13<00:03, 13.81it/s]\u001b[A\n",
            "Loss: 0.0947:  78%|███████▊  | 184/235 [00:13<00:03, 13.81it/s]\u001b[A\n",
            "Loss: 0.0947:  79%|███████▉  | 186/235 [00:13<00:03, 13.83it/s]\u001b[A\n",
            "Loss: 0.0845:  79%|███████▉  | 186/235 [00:13<00:03, 13.83it/s]\u001b[A\n",
            "Loss: 0.0967:  79%|███████▉  | 186/235 [00:13<00:03, 13.83it/s]\u001b[A\n",
            "Loss: 0.0967:  80%|████████  | 188/235 [00:13<00:03, 13.75it/s]\u001b[A\n",
            "Loss: 0.0990:  80%|████████  | 188/235 [00:13<00:03, 13.75it/s]\u001b[A\n",
            "Loss: 0.1165:  80%|████████  | 188/235 [00:13<00:03, 13.75it/s]\u001b[A\n",
            "Loss: 0.1165:  81%|████████  | 190/235 [00:13<00:03, 13.64it/s]\u001b[A\n",
            "Loss: 0.1086:  81%|████████  | 190/235 [00:13<00:03, 13.64it/s]\u001b[A\n",
            "Loss: 0.0923:  81%|████████  | 190/235 [00:14<00:03, 13.64it/s]\u001b[A\n",
            "Loss: 0.0923:  82%|████████▏ | 192/235 [00:14<00:03, 13.52it/s]\u001b[A\n",
            "Loss: 0.0974:  82%|████████▏ | 192/235 [00:14<00:03, 13.52it/s]\u001b[A\n",
            "Loss: 0.0837:  82%|████████▏ | 192/235 [00:14<00:03, 13.52it/s]\u001b[A\n",
            "Loss: 0.0837:  83%|████████▎ | 194/235 [00:14<00:03, 13.28it/s]\u001b[A\n",
            "Loss: 0.0967:  83%|████████▎ | 194/235 [00:14<00:03, 13.28it/s]\u001b[A\n",
            "Loss: 0.1055:  83%|████████▎ | 194/235 [00:14<00:03, 13.28it/s]\u001b[A\n",
            "Loss: 0.1055:  83%|████████▎ | 196/235 [00:14<00:02, 13.32it/s]\u001b[A\n",
            "Loss: 0.1041:  83%|████████▎ | 196/235 [00:14<00:02, 13.32it/s]\u001b[A\n",
            "Loss: 0.0975:  83%|████████▎ | 196/235 [00:14<00:02, 13.32it/s]\u001b[A\n",
            "Loss: 0.0975:  84%|████████▍ | 198/235 [00:14<00:02, 13.21it/s]\u001b[A\n",
            "Loss: 0.0973:  84%|████████▍ | 198/235 [00:14<00:02, 13.21it/s]\u001b[A\n",
            "Loss: 0.0957:  84%|████████▍ | 198/235 [00:14<00:02, 13.21it/s]\u001b[A\n",
            "Loss: 0.0957:  85%|████████▌ | 200/235 [00:14<00:02, 13.14it/s]\u001b[A\n",
            "Loss: 0.1037:  85%|████████▌ | 200/235 [00:14<00:02, 13.14it/s]\u001b[A\n",
            "Loss: 0.0941:  85%|████████▌ | 200/235 [00:14<00:02, 13.14it/s]\u001b[A\n",
            "Loss: 0.0941:  86%|████████▌ | 202/235 [00:14<00:02, 13.17it/s]\u001b[A\n",
            "Loss: 0.0926:  86%|████████▌ | 202/235 [00:14<00:02, 13.17it/s]\u001b[A\n",
            "Loss: 0.1068:  86%|████████▌ | 202/235 [00:14<00:02, 13.17it/s]\u001b[A\n",
            "Loss: 0.1068:  87%|████████▋ | 204/235 [00:14<00:02, 13.32it/s]\u001b[A\n",
            "Loss: 0.0929:  87%|████████▋ | 204/235 [00:14<00:02, 13.32it/s]\u001b[A\n",
            "Loss: 0.0947:  87%|████████▋ | 204/235 [00:15<00:02, 13.32it/s]\u001b[A\n",
            "Loss: 0.0947:  88%|████████▊ | 206/235 [00:15<00:02, 13.44it/s]\u001b[A\n",
            "Loss: 0.0935:  88%|████████▊ | 206/235 [00:15<00:02, 13.44it/s]\u001b[A\n",
            "Loss: 0.0876:  88%|████████▊ | 206/235 [00:15<00:02, 13.44it/s]\u001b[A\n",
            "Loss: 0.0876:  89%|████████▊ | 208/235 [00:15<00:02, 13.46it/s]\u001b[A\n",
            "Loss: 0.0887:  89%|████████▊ | 208/235 [00:15<00:02, 13.46it/s]\u001b[A\n",
            "Loss: 0.0958:  89%|████████▊ | 208/235 [00:15<00:02, 13.46it/s]\u001b[A\n",
            "Loss: 0.0958:  89%|████████▉ | 210/235 [00:15<00:01, 13.57it/s]\u001b[A\n",
            "Loss: 0.1044:  89%|████████▉ | 210/235 [00:15<00:01, 13.57it/s]\u001b[A\n",
            "Loss: 0.0899:  89%|████████▉ | 210/235 [00:15<00:01, 13.57it/s]\u001b[A\n",
            "Loss: 0.0899:  90%|█████████ | 212/235 [00:15<00:01, 13.61it/s]\u001b[A\n",
            "Loss: 0.0844:  90%|█████████ | 212/235 [00:15<00:01, 13.61it/s]\u001b[A\n",
            "Loss: 0.0991:  90%|█████████ | 212/235 [00:15<00:01, 13.61it/s]\u001b[A\n",
            "Loss: 0.0991:  91%|█████████ | 214/235 [00:15<00:01, 13.61it/s]\u001b[A\n",
            "Loss: 0.0945:  91%|█████████ | 214/235 [00:15<00:01, 13.61it/s]\u001b[A\n",
            "Loss: 0.0973:  91%|█████████ | 214/235 [00:15<00:01, 13.61it/s]\u001b[A\n",
            "Loss: 0.0973:  92%|█████████▏| 216/235 [00:15<00:01, 13.68it/s]\u001b[A\n",
            "Loss: 0.0955:  92%|█████████▏| 216/235 [00:15<00:01, 13.68it/s]\u001b[A\n",
            "Loss: 0.1049:  92%|█████████▏| 216/235 [00:15<00:01, 13.68it/s]\u001b[A\n",
            "Loss: 0.1049:  93%|█████████▎| 218/235 [00:15<00:01, 13.53it/s]\u001b[A\n",
            "Loss: 0.0975:  93%|█████████▎| 218/235 [00:16<00:01, 13.53it/s]\u001b[A\n",
            "Loss: 0.0883:  93%|█████████▎| 218/235 [00:16<00:01, 13.53it/s]\u001b[A\n",
            "Loss: 0.0883:  94%|█████████▎| 220/235 [00:16<00:01, 13.53it/s]\u001b[A\n",
            "Loss: 0.0958:  94%|█████████▎| 220/235 [00:16<00:01, 13.53it/s]\u001b[A\n",
            "Loss: 0.1030:  94%|█████████▎| 220/235 [00:16<00:01, 13.53it/s]\u001b[A\n",
            "Loss: 0.1030:  94%|█████████▍| 222/235 [00:16<00:00, 13.54it/s]\u001b[A\n",
            "Loss: 0.0995:  94%|█████████▍| 222/235 [00:16<00:00, 13.54it/s]\u001b[A\n",
            "Loss: 0.0989:  94%|█████████▍| 222/235 [00:16<00:00, 13.54it/s]\u001b[A\n",
            "Loss: 0.0989:  95%|█████████▌| 224/235 [00:16<00:00, 13.54it/s]\u001b[A\n",
            "Loss: 0.0906:  95%|█████████▌| 224/235 [00:16<00:00, 13.54it/s]\u001b[A\n",
            "Loss: 0.0863:  95%|█████████▌| 224/235 [00:16<00:00, 13.54it/s]\u001b[A\n",
            "Loss: 0.0863:  96%|█████████▌| 226/235 [00:16<00:00, 13.42it/s]\u001b[A\n",
            "Loss: 0.1012:  96%|█████████▌| 226/235 [00:16<00:00, 13.42it/s]\u001b[A\n",
            "Loss: 0.0994:  96%|█████████▌| 226/235 [00:16<00:00, 13.42it/s]\u001b[A\n",
            "Loss: 0.0994:  97%|█████████▋| 228/235 [00:16<00:00, 13.30it/s]\u001b[A\n",
            "Loss: 0.0939:  97%|█████████▋| 228/235 [00:16<00:00, 13.30it/s]\u001b[A\n",
            "Loss: 0.0926:  97%|█████████▋| 228/235 [00:16<00:00, 13.30it/s]\u001b[A\n",
            "Loss: 0.0926:  98%|█████████▊| 230/235 [00:16<00:00, 13.32it/s]\u001b[A\n",
            "Loss: 0.0981:  98%|█████████▊| 230/235 [00:16<00:00, 13.32it/s]\u001b[A\n",
            "Loss: 0.1032:  98%|█████████▊| 230/235 [00:17<00:00, 13.32it/s]\u001b[A\n",
            "Loss: 0.1032:  99%|█████████▊| 232/235 [00:17<00:00, 13.14it/s]\u001b[A\n",
            "Loss: 0.1001:  99%|█████████▊| 232/235 [00:17<00:00, 13.14it/s]\u001b[A\n",
            "Loss: 0.0883:  99%|█████████▊| 232/235 [00:17<00:00, 13.14it/s]\u001b[A\n",
            "Loss: 0.0883: 100%|█████████▉| 234/235 [00:17<00:00, 13.17it/s]\u001b[A\n",
            "Loss: 0.0893: 100%|█████████▉| 234/235 [00:17<00:00, 13.17it/s]\u001b[A\n",
            "  2%|▏         | 2/100 [00:35<28:33, 17.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean loss for Epoch 2: 0.1052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 0.0906:   0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 0.0959:   0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 0.0959:   1%|          | 2/235 [00:00<00:17, 13.32it/s]\u001b[A\n",
            "Loss: 0.0784:   1%|          | 2/235 [00:00<00:17, 13.32it/s]\u001b[A\n",
            "Loss: 0.0860:   1%|          | 2/235 [00:00<00:17, 13.32it/s]\u001b[A\n",
            "Loss: 0.0860:   2%|▏         | 4/235 [00:00<00:17, 13.44it/s]\u001b[A\n",
            "Loss: 0.0965:   2%|▏         | 4/235 [00:00<00:17, 13.44it/s]\u001b[A\n",
            "Loss: 0.0873:   2%|▏         | 4/235 [00:00<00:17, 13.44it/s]\u001b[A\n",
            "Loss: 0.0873:   3%|▎         | 6/235 [00:00<00:17, 12.98it/s]\u001b[A\n",
            "Loss: 0.0886:   3%|▎         | 6/235 [00:00<00:17, 12.98it/s]\u001b[A\n",
            "Loss: 0.0925:   3%|▎         | 6/235 [00:00<00:17, 12.98it/s]\u001b[A\n",
            "Loss: 0.0925:   3%|▎         | 8/235 [00:00<00:17, 12.82it/s]\u001b[A\n",
            "Loss: 0.0951:   3%|▎         | 8/235 [00:00<00:17, 12.82it/s]\u001b[A\n",
            "Loss: 0.0962:   3%|▎         | 8/235 [00:00<00:17, 12.82it/s]\u001b[A\n",
            "Loss: 0.0962:   4%|▍         | 10/235 [00:00<00:17, 12.97it/s]\u001b[A\n",
            "Loss: 0.0868:   4%|▍         | 10/235 [00:00<00:17, 12.97it/s]\u001b[A\n",
            "Loss: 0.0899:   4%|▍         | 10/235 [00:00<00:17, 12.97it/s]\u001b[A\n",
            "Loss: 0.0899:   5%|▌         | 12/235 [00:00<00:16, 13.15it/s]\u001b[A\n",
            "Loss: 0.0775:   5%|▌         | 12/235 [00:00<00:16, 13.15it/s]\u001b[A\n",
            "Loss: 0.0902:   5%|▌         | 12/235 [00:01<00:16, 13.15it/s]\u001b[A\n",
            "Loss: 0.0902:   6%|▌         | 14/235 [00:01<00:16, 13.21it/s]\u001b[A\n",
            "Loss: 0.0914:   6%|▌         | 14/235 [00:01<00:16, 13.21it/s]\u001b[A\n",
            "Loss: 0.0986:   6%|▌         | 14/235 [00:01<00:16, 13.21it/s]\u001b[A\n",
            "Loss: 0.0986:   7%|▋         | 16/235 [00:01<00:16, 13.34it/s]\u001b[A\n",
            "Loss: 0.0949:   7%|▋         | 16/235 [00:01<00:16, 13.34it/s]\u001b[A\n",
            "Loss: 0.0910:   7%|▋         | 16/235 [00:01<00:16, 13.34it/s]\u001b[A\n",
            "Loss: 0.0910:   8%|▊         | 18/235 [00:01<00:16, 13.39it/s]\u001b[A\n",
            "Loss: 0.1017:   8%|▊         | 18/235 [00:01<00:16, 13.39it/s]\u001b[A\n",
            "Loss: 0.0961:   8%|▊         | 18/235 [00:01<00:16, 13.39it/s]\u001b[A\n",
            "Loss: 0.0961:   9%|▊         | 20/235 [00:01<00:15, 13.47it/s]\u001b[A\n",
            "Loss: 0.0930:   9%|▊         | 20/235 [00:01<00:15, 13.47it/s]\u001b[A\n",
            "Loss: 0.0876:   9%|▊         | 20/235 [00:01<00:15, 13.47it/s]\u001b[A\n",
            "Loss: 0.0876:   9%|▉         | 22/235 [00:01<00:15, 13.46it/s]\u001b[A\n",
            "Loss: 0.0953:   9%|▉         | 22/235 [00:01<00:15, 13.46it/s]\u001b[A\n",
            "Loss: 0.0946:   9%|▉         | 22/235 [00:01<00:15, 13.46it/s]\u001b[A\n",
            "Loss: 0.0946:  10%|█         | 24/235 [00:01<00:15, 13.47it/s]\u001b[A\n",
            "Loss: 0.0960:  10%|█         | 24/235 [00:01<00:15, 13.47it/s]\u001b[A\n",
            "Loss: 0.0903:  10%|█         | 24/235 [00:01<00:15, 13.47it/s]\u001b[A\n",
            "Loss: 0.0903:  11%|█         | 26/235 [00:01<00:15, 13.51it/s]\u001b[A\n",
            "Loss: 0.0931:  11%|█         | 26/235 [00:02<00:15, 13.51it/s]\u001b[A\n",
            "Loss: 0.0878:  11%|█         | 26/235 [00:02<00:15, 13.51it/s]\u001b[A\n",
            "Loss: 0.0878:  12%|█▏        | 28/235 [00:02<00:15, 13.63it/s]\u001b[A\n",
            "Loss: 0.0990:  12%|█▏        | 28/235 [00:02<00:15, 13.63it/s]\u001b[A\n",
            "Loss: 0.0908:  12%|█▏        | 28/235 [00:02<00:15, 13.63it/s]\u001b[A\n",
            "Loss: 0.0908:  13%|█▎        | 30/235 [00:02<00:15, 13.63it/s]\u001b[A\n",
            "Loss: 0.0853:  13%|█▎        | 30/235 [00:02<00:15, 13.63it/s]\u001b[A\n",
            "Loss: 0.0905:  13%|█▎        | 30/235 [00:02<00:15, 13.63it/s]\u001b[A\n",
            "Loss: 0.0905:  14%|█▎        | 32/235 [00:02<00:14, 13.56it/s]\u001b[A\n",
            "Loss: 0.0839:  14%|█▎        | 32/235 [00:02<00:14, 13.56it/s]\u001b[A\n",
            "Loss: 0.0976:  14%|█▎        | 32/235 [00:02<00:14, 13.56it/s]\u001b[A\n",
            "Loss: 0.0976:  14%|█▍        | 34/235 [00:02<00:14, 13.55it/s]\u001b[A\n",
            "Loss: 0.0877:  14%|█▍        | 34/235 [00:02<00:14, 13.55it/s]\u001b[A\n",
            "Loss: 0.0773:  14%|█▍        | 34/235 [00:02<00:14, 13.55it/s]\u001b[A\n",
            "Loss: 0.0773:  15%|█▌        | 36/235 [00:02<00:14, 13.62it/s]\u001b[A\n",
            "Loss: 0.0857:  15%|█▌        | 36/235 [00:02<00:14, 13.62it/s]\u001b[A\n",
            "Loss: 0.0909:  15%|█▌        | 36/235 [00:02<00:14, 13.62it/s]\u001b[A\n",
            "Loss: 0.0909:  16%|█▌        | 38/235 [00:02<00:14, 13.67it/s]\u001b[A\n",
            "Loss: 0.0936:  16%|█▌        | 38/235 [00:02<00:14, 13.67it/s]\u001b[A\n",
            "Loss: 0.0891:  16%|█▌        | 38/235 [00:02<00:14, 13.67it/s]\u001b[A\n",
            "Loss: 0.0891:  17%|█▋        | 40/235 [00:02<00:14, 13.66it/s]\u001b[A\n",
            "Loss: 0.1001:  17%|█▋        | 40/235 [00:03<00:14, 13.66it/s]\u001b[A\n",
            "Loss: 0.0969:  17%|█▋        | 40/235 [00:03<00:14, 13.66it/s]\u001b[A\n",
            "Loss: 0.0969:  18%|█▊        | 42/235 [00:03<00:14, 13.69it/s]\u001b[A\n",
            "Loss: 0.0844:  18%|█▊        | 42/235 [00:03<00:14, 13.69it/s]\u001b[A\n",
            "Loss: 0.0915:  18%|█▊        | 42/235 [00:03<00:14, 13.69it/s]\u001b[A\n",
            "Loss: 0.0915:  19%|█▊        | 44/235 [00:03<00:13, 13.67it/s]\u001b[A\n",
            "Loss: 0.0844:  19%|█▊        | 44/235 [00:03<00:13, 13.67it/s]\u001b[A\n",
            "Loss: 0.0849:  19%|█▊        | 44/235 [00:03<00:13, 13.67it/s]\u001b[A\n",
            "Loss: 0.0849:  20%|█▉        | 46/235 [00:03<00:13, 13.68it/s]\u001b[A\n",
            "Loss: 0.0914:  20%|█▉        | 46/235 [00:03<00:13, 13.68it/s]\u001b[A\n",
            "Loss: 0.0793:  20%|█▉        | 46/235 [00:03<00:13, 13.68it/s]\u001b[A\n",
            "Loss: 0.0793:  20%|██        | 48/235 [00:03<00:13, 13.72it/s]\u001b[A\n",
            "Loss: 0.0915:  20%|██        | 48/235 [00:03<00:13, 13.72it/s]\u001b[A\n",
            "Loss: 0.0822:  20%|██        | 48/235 [00:03<00:13, 13.72it/s]\u001b[A\n",
            "Loss: 0.0822:  21%|██▏       | 50/235 [00:03<00:13, 13.76it/s]\u001b[A\n",
            "Loss: 0.0855:  21%|██▏       | 50/235 [00:03<00:13, 13.76it/s]\u001b[A\n",
            "Loss: 0.0987:  21%|██▏       | 50/235 [00:03<00:13, 13.76it/s]\u001b[A\n",
            "Loss: 0.0987:  22%|██▏       | 52/235 [00:03<00:13, 13.77it/s]\u001b[A\n",
            "Loss: 0.0797:  22%|██▏       | 52/235 [00:03<00:13, 13.77it/s]\u001b[A\n",
            "Loss: 0.0891:  22%|██▏       | 52/235 [00:03<00:13, 13.77it/s]\u001b[A\n",
            "Loss: 0.0891:  23%|██▎       | 54/235 [00:03<00:13, 13.79it/s]\u001b[A\n",
            "Loss: 0.0926:  23%|██▎       | 54/235 [00:04<00:13, 13.79it/s]\u001b[A\n",
            "Loss: 0.0887:  23%|██▎       | 54/235 [00:04<00:13, 13.79it/s]\u001b[A\n",
            "Loss: 0.0887:  24%|██▍       | 56/235 [00:04<00:12, 13.83it/s]\u001b[A\n",
            "Loss: 0.0991:  24%|██▍       | 56/235 [00:04<00:12, 13.83it/s]\u001b[A\n",
            "Loss: 0.0921:  24%|██▍       | 56/235 [00:04<00:12, 13.83it/s]\u001b[A\n",
            "Loss: 0.0921:  25%|██▍       | 58/235 [00:04<00:12, 13.79it/s]\u001b[A\n",
            "Loss: 0.0898:  25%|██▍       | 58/235 [00:04<00:12, 13.79it/s]\u001b[A\n",
            "Loss: 0.0798:  25%|██▍       | 58/235 [00:04<00:12, 13.79it/s]\u001b[A\n",
            "Loss: 0.0798:  26%|██▌       | 60/235 [00:04<00:12, 13.63it/s]\u001b[A\n",
            "Loss: 0.0892:  26%|██▌       | 60/235 [00:04<00:12, 13.63it/s]\u001b[A\n",
            "Loss: 0.0871:  26%|██▌       | 60/235 [00:04<00:12, 13.63it/s]\u001b[A\n",
            "Loss: 0.0871:  26%|██▋       | 62/235 [00:04<00:12, 13.55it/s]\u001b[A\n",
            "Loss: 0.0792:  26%|██▋       | 62/235 [00:04<00:12, 13.55it/s]\u001b[A\n",
            "Loss: 0.0874:  26%|██▋       | 62/235 [00:04<00:12, 13.55it/s]\u001b[A\n",
            "Loss: 0.0874:  27%|██▋       | 64/235 [00:04<00:12, 13.49it/s]\u001b[A\n",
            "Loss: 0.0822:  27%|██▋       | 64/235 [00:04<00:12, 13.49it/s]\u001b[A\n",
            "Loss: 0.0929:  27%|██▋       | 64/235 [00:04<00:12, 13.49it/s]\u001b[A\n",
            "Loss: 0.0929:  28%|██▊       | 66/235 [00:04<00:12, 13.57it/s]\u001b[A\n",
            "Loss: 0.0861:  28%|██▊       | 66/235 [00:04<00:12, 13.57it/s]\u001b[A\n",
            "Loss: 0.0940:  28%|██▊       | 66/235 [00:05<00:12, 13.57it/s]\u001b[A\n",
            "Loss: 0.0940:  29%|██▉       | 68/235 [00:05<00:12, 13.60it/s]\u001b[A\n",
            "Loss: 0.0921:  29%|██▉       | 68/235 [00:05<00:12, 13.60it/s]\u001b[A\n",
            "Loss: 0.0885:  29%|██▉       | 68/235 [00:05<00:12, 13.60it/s]\u001b[A\n",
            "Loss: 0.0885:  30%|██▉       | 70/235 [00:05<00:12, 13.44it/s]\u001b[A\n",
            "Loss: 0.0888:  30%|██▉       | 70/235 [00:05<00:12, 13.44it/s]\u001b[A\n",
            "Loss: 0.0858:  30%|██▉       | 70/235 [00:05<00:12, 13.44it/s]\u001b[A\n",
            "Loss: 0.0858:  31%|███       | 72/235 [00:05<00:12, 13.41it/s]\u001b[A\n",
            "Loss: 0.0869:  31%|███       | 72/235 [00:05<00:12, 13.41it/s]\u001b[A\n",
            "Loss: 0.0894:  31%|███       | 72/235 [00:05<00:12, 13.41it/s]\u001b[A\n",
            "Loss: 0.0894:  31%|███▏      | 74/235 [00:05<00:11, 13.45it/s]\u001b[A\n",
            "Loss: 0.0920:  31%|███▏      | 74/235 [00:05<00:11, 13.45it/s]\u001b[A\n",
            "Loss: 0.0975:  31%|███▏      | 74/235 [00:05<00:11, 13.45it/s]\u001b[A\n",
            "Loss: 0.0975:  32%|███▏      | 76/235 [00:05<00:12, 13.11it/s]\u001b[A\n",
            "Loss: 0.0901:  32%|███▏      | 76/235 [00:05<00:12, 13.11it/s]\u001b[A\n",
            "Loss: 0.0978:  32%|███▏      | 76/235 [00:05<00:12, 13.11it/s]\u001b[A\n",
            "Loss: 0.0978:  33%|███▎      | 78/235 [00:05<00:11, 13.16it/s]\u001b[A\n",
            "Loss: 0.0806:  33%|███▎      | 78/235 [00:05<00:11, 13.16it/s]\u001b[A\n",
            "Loss: 0.1018:  33%|███▎      | 78/235 [00:05<00:11, 13.16it/s]\u001b[A\n",
            "Loss: 0.1018:  34%|███▍      | 80/235 [00:05<00:11, 13.29it/s]\u001b[A\n",
            "Loss: 0.0810:  34%|███▍      | 80/235 [00:06<00:11, 13.29it/s]\u001b[A\n",
            "Loss: 0.0843:  34%|███▍      | 80/235 [00:06<00:11, 13.29it/s]\u001b[A\n",
            "Loss: 0.0843:  35%|███▍      | 82/235 [00:06<00:11, 13.39it/s]\u001b[A\n",
            "Loss: 0.0895:  35%|███▍      | 82/235 [00:06<00:11, 13.39it/s]\u001b[A\n",
            "Loss: 0.0856:  35%|███▍      | 82/235 [00:06<00:11, 13.39it/s]\u001b[A\n",
            "Loss: 0.0856:  36%|███▌      | 84/235 [00:06<00:11, 13.47it/s]\u001b[A\n",
            "Loss: 0.0891:  36%|███▌      | 84/235 [00:06<00:11, 13.47it/s]\u001b[A\n",
            "Loss: 0.0854:  36%|███▌      | 84/235 [00:06<00:11, 13.47it/s]\u001b[A\n",
            "Loss: 0.0854:  37%|███▋      | 86/235 [00:06<00:11, 13.46it/s]\u001b[A\n",
            "Loss: 0.0941:  37%|███▋      | 86/235 [00:06<00:11, 13.46it/s]\u001b[A\n",
            "Loss: 0.0809:  37%|███▋      | 86/235 [00:06<00:11, 13.46it/s]\u001b[A\n",
            "Loss: 0.0809:  37%|███▋      | 88/235 [00:06<00:10, 13.48it/s]\u001b[A\n",
            "Loss: 0.0840:  37%|███▋      | 88/235 [00:06<00:10, 13.48it/s]\u001b[A\n",
            "Loss: 0.0914:  37%|███▋      | 88/235 [00:06<00:10, 13.48it/s]\u001b[A\n",
            "Loss: 0.0914:  38%|███▊      | 90/235 [00:06<00:10, 13.56it/s]\u001b[A\n",
            "Loss: 0.1051:  38%|███▊      | 90/235 [00:06<00:10, 13.56it/s]\u001b[A\n",
            "Loss: 0.0839:  38%|███▊      | 90/235 [00:06<00:10, 13.56it/s]\u001b[A\n",
            "Loss: 0.0839:  39%|███▉      | 92/235 [00:06<00:10, 13.63it/s]\u001b[A\n",
            "Loss: 0.0860:  39%|███▉      | 92/235 [00:06<00:10, 13.63it/s]\u001b[A\n",
            "Loss: 0.0853:  39%|███▉      | 92/235 [00:06<00:10, 13.63it/s]\u001b[A\n",
            "Loss: 0.0853:  40%|████      | 94/235 [00:06<00:10, 13.71it/s]\u001b[A\n",
            "Loss: 0.0892:  40%|████      | 94/235 [00:07<00:10, 13.71it/s]\u001b[A\n",
            "Loss: 0.0837:  40%|████      | 94/235 [00:07<00:10, 13.71it/s]\u001b[A\n",
            "Loss: 0.0837:  41%|████      | 96/235 [00:07<00:10, 13.71it/s]\u001b[A\n",
            "Loss: 0.0868:  41%|████      | 96/235 [00:07<00:10, 13.71it/s]\u001b[A\n",
            "Loss: 0.0873:  41%|████      | 96/235 [00:07<00:10, 13.71it/s]\u001b[A\n",
            "Loss: 0.0873:  42%|████▏     | 98/235 [00:07<00:10, 13.69it/s]\u001b[A\n",
            "Loss: 0.0924:  42%|████▏     | 98/235 [00:07<00:10, 13.69it/s]\u001b[A\n",
            "Loss: 0.0856:  42%|████▏     | 98/235 [00:07<00:10, 13.69it/s]\u001b[A\n",
            "Loss: 0.0856:  43%|████▎     | 100/235 [00:07<00:09, 13.70it/s]\u001b[A\n",
            "Loss: 0.0953:  43%|████▎     | 100/235 [00:07<00:09, 13.70it/s]\u001b[A\n",
            "Loss: 0.0909:  43%|████▎     | 100/235 [00:07<00:09, 13.70it/s]\u001b[A\n",
            "Loss: 0.0909:  43%|████▎     | 102/235 [00:07<00:09, 13.66it/s]\u001b[A\n",
            "Loss: 0.0841:  43%|████▎     | 102/235 [00:07<00:09, 13.66it/s]\u001b[A\n",
            "Loss: 0.0823:  43%|████▎     | 102/235 [00:07<00:09, 13.66it/s]\u001b[A\n",
            "Loss: 0.0823:  44%|████▍     | 104/235 [00:07<00:09, 13.64it/s]\u001b[A\n",
            "Loss: 0.0855:  44%|████▍     | 104/235 [00:07<00:09, 13.64it/s]\u001b[A\n",
            "Loss: 0.0838:  44%|████▍     | 104/235 [00:07<00:09, 13.64it/s]\u001b[A\n",
            "Loss: 0.0838:  45%|████▌     | 106/235 [00:07<00:09, 13.51it/s]\u001b[A\n",
            "Loss: 0.0836:  45%|████▌     | 106/235 [00:07<00:09, 13.51it/s]\u001b[A\n",
            "Loss: 0.0859:  45%|████▌     | 106/235 [00:07<00:09, 13.51it/s]\u001b[A\n",
            "Loss: 0.0859:  46%|████▌     | 108/235 [00:07<00:09, 13.59it/s]\u001b[A\n",
            "Loss: 0.0898:  46%|████▌     | 108/235 [00:08<00:09, 13.59it/s]\u001b[A\n",
            "Loss: 0.0915:  46%|████▌     | 108/235 [00:08<00:09, 13.59it/s]\u001b[A\n",
            "Loss: 0.0915:  47%|████▋     | 110/235 [00:08<00:09, 13.66it/s]\u001b[A\n",
            "Loss: 0.0875:  47%|████▋     | 110/235 [00:08<00:09, 13.66it/s]\u001b[A\n",
            "Loss: 0.0809:  47%|████▋     | 110/235 [00:08<00:09, 13.66it/s]\u001b[A\n",
            "Loss: 0.0809:  48%|████▊     | 112/235 [00:08<00:08, 13.74it/s]\u001b[A\n",
            "Loss: 0.0869:  48%|████▊     | 112/235 [00:08<00:08, 13.74it/s]\u001b[A\n",
            "Loss: 0.0832:  48%|████▊     | 112/235 [00:08<00:08, 13.74it/s]\u001b[A\n",
            "Loss: 0.0832:  49%|████▊     | 114/235 [00:08<00:08, 13.59it/s]\u001b[A\n",
            "Loss: 0.0820:  49%|████▊     | 114/235 [00:08<00:08, 13.59it/s]\u001b[A\n",
            "Loss: 0.0794:  49%|████▊     | 114/235 [00:08<00:08, 13.59it/s]\u001b[A\n",
            "Loss: 0.0794:  49%|████▉     | 116/235 [00:08<00:08, 13.48it/s]\u001b[A\n",
            "Loss: 0.0980:  49%|████▉     | 116/235 [00:08<00:08, 13.48it/s]\u001b[A\n",
            "Loss: 0.0868:  49%|████▉     | 116/235 [00:08<00:08, 13.48it/s]\u001b[A\n",
            "Loss: 0.0868:  50%|█████     | 118/235 [00:08<00:08, 13.51it/s]\u001b[A\n",
            "Loss: 0.0837:  50%|█████     | 118/235 [00:08<00:08, 13.51it/s]\u001b[A\n",
            "Loss: 0.0825:  50%|█████     | 118/235 [00:08<00:08, 13.51it/s]\u001b[A\n",
            "Loss: 0.0825:  51%|█████     | 120/235 [00:08<00:08, 13.55it/s]\u001b[A\n",
            "Loss: 0.0850:  51%|█████     | 120/235 [00:08<00:08, 13.55it/s]\u001b[A\n",
            "Loss: 0.0813:  51%|█████     | 120/235 [00:09<00:08, 13.55it/s]\u001b[A\n",
            "Loss: 0.0813:  52%|█████▏    | 122/235 [00:09<00:08, 13.57it/s]\u001b[A\n",
            "Loss: 0.0925:  52%|█████▏    | 122/235 [00:09<00:08, 13.57it/s]\u001b[A\n",
            "Loss: 0.0866:  52%|█████▏    | 122/235 [00:09<00:08, 13.57it/s]\u001b[A\n",
            "Loss: 0.0866:  53%|█████▎    | 124/235 [00:09<00:08, 13.25it/s]\u001b[A\n",
            "Loss: 0.0909:  53%|█████▎    | 124/235 [00:09<00:08, 13.25it/s]\u001b[A\n",
            "Loss: 0.0928:  53%|█████▎    | 124/235 [00:09<00:08, 13.25it/s]\u001b[A\n",
            "Loss: 0.0928:  54%|█████▎    | 126/235 [00:09<00:08, 13.29it/s]\u001b[A\n",
            "Loss: 0.0875:  54%|█████▎    | 126/235 [00:09<00:08, 13.29it/s]\u001b[A\n",
            "Loss: 0.0924:  54%|█████▎    | 126/235 [00:09<00:08, 13.29it/s]\u001b[A\n",
            "Loss: 0.0924:  54%|█████▍    | 128/235 [00:09<00:08, 13.33it/s]\u001b[A\n",
            "Loss: 0.0855:  54%|█████▍    | 128/235 [00:09<00:08, 13.33it/s]\u001b[A\n",
            "Loss: 0.0883:  54%|█████▍    | 128/235 [00:09<00:08, 13.33it/s]\u001b[A\n",
            "Loss: 0.0883:  55%|█████▌    | 130/235 [00:09<00:07, 13.34it/s]\u001b[A\n",
            "Loss: 0.0825:  55%|█████▌    | 130/235 [00:09<00:07, 13.34it/s]\u001b[A\n",
            "Loss: 0.0886:  55%|█████▌    | 130/235 [00:09<00:07, 13.34it/s]\u001b[A\n",
            "Loss: 0.0886:  56%|█████▌    | 132/235 [00:09<00:07, 13.39it/s]\u001b[A\n",
            "Loss: 0.0826:  56%|█████▌    | 132/235 [00:09<00:07, 13.39it/s]\u001b[A\n",
            "Loss: 0.0844:  56%|█████▌    | 132/235 [00:09<00:07, 13.39it/s]\u001b[A\n",
            "Loss: 0.0844:  57%|█████▋    | 134/235 [00:09<00:07, 13.42it/s]\u001b[A\n",
            "Loss: 0.0848:  57%|█████▋    | 134/235 [00:09<00:07, 13.42it/s]\u001b[A\n",
            "Loss: 0.0823:  57%|█████▋    | 134/235 [00:10<00:07, 13.42it/s]\u001b[A\n",
            "Loss: 0.0823:  58%|█████▊    | 136/235 [00:10<00:07, 13.45it/s]\u001b[A\n",
            "Loss: 0.0869:  58%|█████▊    | 136/235 [00:10<00:07, 13.45it/s]\u001b[A\n",
            "Loss: 0.0865:  58%|█████▊    | 136/235 [00:10<00:07, 13.45it/s]\u001b[A\n",
            "Loss: 0.0865:  59%|█████▊    | 138/235 [00:10<00:07, 13.43it/s]\u001b[A\n",
            "Loss: 0.0801:  59%|█████▊    | 138/235 [00:10<00:07, 13.43it/s]\u001b[A\n",
            "Loss: 0.0969:  59%|█████▊    | 138/235 [00:10<00:07, 13.43it/s]\u001b[A\n",
            "Loss: 0.0969:  60%|█████▉    | 140/235 [00:10<00:07, 13.26it/s]\u001b[A\n",
            "Loss: 0.0774:  60%|█████▉    | 140/235 [00:10<00:07, 13.26it/s]\u001b[A\n",
            "Loss: 0.0820:  60%|█████▉    | 140/235 [00:10<00:07, 13.26it/s]\u001b[A\n",
            "Loss: 0.0820:  60%|██████    | 142/235 [00:10<00:07, 13.22it/s]\u001b[A\n",
            "Loss: 0.0879:  60%|██████    | 142/235 [00:10<00:07, 13.22it/s]\u001b[A\n",
            "Loss: 0.0869:  60%|██████    | 142/235 [00:10<00:07, 13.22it/s]\u001b[A\n",
            "Loss: 0.0869:  61%|██████▏   | 144/235 [00:10<00:06, 13.24it/s]\u001b[A\n",
            "Loss: 0.0858:  61%|██████▏   | 144/235 [00:10<00:06, 13.24it/s]\u001b[A\n",
            "Loss: 0.0904:  61%|██████▏   | 144/235 [00:10<00:06, 13.24it/s]\u001b[A\n",
            "Loss: 0.0904:  62%|██████▏   | 146/235 [00:10<00:06, 13.32it/s]\u001b[A\n",
            "Loss: 0.0850:  62%|██████▏   | 146/235 [00:10<00:06, 13.32it/s]\u001b[A\n",
            "Loss: 0.0831:  62%|██████▏   | 146/235 [00:10<00:06, 13.32it/s]\u001b[A\n",
            "Loss: 0.0831:  63%|██████▎   | 148/235 [00:10<00:06, 13.39it/s]\u001b[A\n",
            "Loss: 0.0821:  63%|██████▎   | 148/235 [00:11<00:06, 13.39it/s]\u001b[A\n",
            "Loss: 0.0808:  63%|██████▎   | 148/235 [00:11<00:06, 13.39it/s]\u001b[A\n",
            "Loss: 0.0808:  64%|██████▍   | 150/235 [00:11<00:06, 13.46it/s]\u001b[A\n",
            "Loss: 0.0899:  64%|██████▍   | 150/235 [00:11<00:06, 13.46it/s]\u001b[A\n",
            "Loss: 0.0867:  64%|██████▍   | 150/235 [00:11<00:06, 13.46it/s]\u001b[A\n",
            "Loss: 0.0867:  65%|██████▍   | 152/235 [00:11<00:06, 13.53it/s]\u001b[A\n",
            "Loss: 0.0886:  65%|██████▍   | 152/235 [00:11<00:06, 13.53it/s]\u001b[A\n",
            "Loss: 0.0792:  65%|██████▍   | 152/235 [00:11<00:06, 13.53it/s]\u001b[A\n",
            "Loss: 0.0792:  66%|██████▌   | 154/235 [00:11<00:05, 13.55it/s]\u001b[A\n",
            "Loss: 0.0874:  66%|██████▌   | 154/235 [00:11<00:05, 13.55it/s]\u001b[A\n",
            "Loss: 0.0750:  66%|██████▌   | 154/235 [00:11<00:05, 13.55it/s]\u001b[A\n",
            "Loss: 0.0750:  66%|██████▋   | 156/235 [00:11<00:05, 13.49it/s]\u001b[A\n",
            "Loss: 0.0829:  66%|██████▋   | 156/235 [00:11<00:05, 13.49it/s]\u001b[A\n",
            "Loss: 0.0814:  66%|██████▋   | 156/235 [00:11<00:05, 13.49it/s]\u001b[A\n",
            "Loss: 0.0814:  67%|██████▋   | 158/235 [00:11<00:05, 13.50it/s]\u001b[A\n",
            "Loss: 0.0882:  67%|██████▋   | 158/235 [00:11<00:05, 13.50it/s]\u001b[A\n",
            "Loss: 0.0868:  67%|██████▋   | 158/235 [00:11<00:05, 13.50it/s]\u001b[A\n",
            "Loss: 0.0868:  68%|██████▊   | 160/235 [00:11<00:05, 13.50it/s]\u001b[A\n",
            "Loss: 0.0932:  68%|██████▊   | 160/235 [00:11<00:05, 13.50it/s]\u001b[A\n",
            "Loss: 0.0830:  68%|██████▊   | 160/235 [00:12<00:05, 13.50it/s]\u001b[A\n",
            "Loss: 0.0830:  69%|██████▉   | 162/235 [00:12<00:05, 13.42it/s]\u001b[A\n",
            "Loss: 0.0796:  69%|██████▉   | 162/235 [00:12<00:05, 13.42it/s]\u001b[A\n",
            "Loss: 0.0818:  69%|██████▉   | 162/235 [00:12<00:05, 13.42it/s]\u001b[A\n",
            "Loss: 0.0818:  70%|██████▉   | 164/235 [00:12<00:05, 13.45it/s]\u001b[A\n",
            "Loss: 0.0877:  70%|██████▉   | 164/235 [00:12<00:05, 13.45it/s]\u001b[A\n",
            "Loss: 0.0713:  70%|██████▉   | 164/235 [00:12<00:05, 13.45it/s]\u001b[A\n",
            "Loss: 0.0713:  71%|███████   | 166/235 [00:12<00:05, 13.51it/s]\u001b[A\n",
            "Loss: 0.0802:  71%|███████   | 166/235 [00:12<00:05, 13.51it/s]\u001b[A\n",
            "Loss: 0.0823:  71%|███████   | 166/235 [00:12<00:05, 13.51it/s]\u001b[A\n",
            "Loss: 0.0823:  71%|███████▏  | 168/235 [00:12<00:04, 13.50it/s]\u001b[A\n",
            "Loss: 0.0786:  71%|███████▏  | 168/235 [00:12<00:04, 13.50it/s]\u001b[A\n",
            "Loss: 0.0828:  71%|███████▏  | 168/235 [00:12<00:04, 13.50it/s]\u001b[A\n",
            "Loss: 0.0828:  72%|███████▏  | 170/235 [00:12<00:04, 13.46it/s]\u001b[A\n",
            "Loss: 0.0840:  72%|███████▏  | 170/235 [00:12<00:04, 13.46it/s]\u001b[A\n",
            "Loss: 0.0791:  72%|███████▏  | 170/235 [00:12<00:04, 13.46it/s]\u001b[A\n",
            "Loss: 0.0791:  73%|███████▎  | 172/235 [00:12<00:04, 13.55it/s]\u001b[A\n",
            "Loss: 0.0776:  73%|███████▎  | 172/235 [00:12<00:04, 13.55it/s]\u001b[A\n",
            "Loss: 0.0827:  73%|███████▎  | 172/235 [00:12<00:04, 13.55it/s]\u001b[A\n",
            "Loss: 0.0827:  74%|███████▍  | 174/235 [00:12<00:04, 13.57it/s]\u001b[A\n",
            "Loss: 0.0902:  74%|███████▍  | 174/235 [00:12<00:04, 13.57it/s]\u001b[A\n",
            "Loss: 0.0891:  74%|███████▍  | 174/235 [00:13<00:04, 13.57it/s]\u001b[A\n",
            "Loss: 0.0891:  75%|███████▍  | 176/235 [00:13<00:04, 13.61it/s]\u001b[A\n",
            "Loss: 0.0882:  75%|███████▍  | 176/235 [00:13<00:04, 13.61it/s]\u001b[A\n",
            "Loss: 0.0780:  75%|███████▍  | 176/235 [00:13<00:04, 13.61it/s]\u001b[A\n",
            "Loss: 0.0780:  76%|███████▌  | 178/235 [00:13<00:04, 13.56it/s]\u001b[A\n",
            "Loss: 0.0843:  76%|███████▌  | 178/235 [00:13<00:04, 13.56it/s]\u001b[A\n",
            "Loss: 0.0825:  76%|███████▌  | 178/235 [00:13<00:04, 13.56it/s]\u001b[A\n",
            "Loss: 0.0825:  77%|███████▋  | 180/235 [00:13<00:04, 13.55it/s]\u001b[A\n",
            "Loss: 0.0844:  77%|███████▋  | 180/235 [00:13<00:04, 13.55it/s]\u001b[A\n",
            "Loss: 0.0820:  77%|███████▋  | 180/235 [00:13<00:04, 13.55it/s]\u001b[A\n",
            "Loss: 0.0820:  77%|███████▋  | 182/235 [00:13<00:03, 13.51it/s]\u001b[A\n",
            "Loss: 0.0843:  77%|███████▋  | 182/235 [00:13<00:03, 13.51it/s]\u001b[A\n",
            "Loss: 0.0748:  77%|███████▋  | 182/235 [00:13<00:03, 13.51it/s]\u001b[A\n",
            "Loss: 0.0748:  78%|███████▊  | 184/235 [00:13<00:03, 13.48it/s]\u001b[A\n",
            "Loss: 0.0796:  78%|███████▊  | 184/235 [00:13<00:03, 13.48it/s]\u001b[A\n",
            "Loss: 0.0785:  78%|███████▊  | 184/235 [00:13<00:03, 13.48it/s]\u001b[A\n",
            "Loss: 0.0785:  79%|███████▉  | 186/235 [00:13<00:03, 13.44it/s]\u001b[A\n",
            "Loss: 0.0764:  79%|███████▉  | 186/235 [00:13<00:03, 13.44it/s]\u001b[A\n",
            "Loss: 0.0855:  79%|███████▉  | 186/235 [00:13<00:03, 13.44it/s]\u001b[A\n",
            "Loss: 0.0855:  80%|████████  | 188/235 [00:13<00:03, 13.38it/s]\u001b[A\n",
            "Loss: 0.0785:  80%|████████  | 188/235 [00:14<00:03, 13.38it/s]\u001b[A\n",
            "Loss: 0.0911:  80%|████████  | 188/235 [00:14<00:03, 13.38it/s]\u001b[A\n",
            "Loss: 0.0911:  81%|████████  | 190/235 [00:14<00:03, 13.43it/s]\u001b[A\n",
            "Loss: 0.0827:  81%|████████  | 190/235 [00:14<00:03, 13.43it/s]\u001b[A\n",
            "Loss: 0.0874:  81%|████████  | 190/235 [00:14<00:03, 13.43it/s]\u001b[A\n",
            "Loss: 0.0874:  82%|████████▏ | 192/235 [00:14<00:03, 13.41it/s]\u001b[A\n",
            "Loss: 0.0772:  82%|████████▏ | 192/235 [00:14<00:03, 13.41it/s]\u001b[A\n",
            "Loss: 0.0886:  82%|████████▏ | 192/235 [00:14<00:03, 13.41it/s]\u001b[A\n",
            "Loss: 0.0886:  83%|████████▎ | 194/235 [00:14<00:03, 13.43it/s]\u001b[A\n",
            "Loss: 0.0800:  83%|████████▎ | 194/235 [00:14<00:03, 13.43it/s]\u001b[A\n",
            "Loss: 0.0804:  83%|████████▎ | 194/235 [00:14<00:03, 13.43it/s]\u001b[A\n",
            "Loss: 0.0804:  83%|████████▎ | 196/235 [00:14<00:02, 13.47it/s]\u001b[A\n",
            "Loss: 0.0935:  83%|████████▎ | 196/235 [00:14<00:02, 13.47it/s]\u001b[A\n",
            "Loss: 0.0794:  83%|████████▎ | 196/235 [00:14<00:02, 13.47it/s]\u001b[A\n",
            "Loss: 0.0794:  84%|████████▍ | 198/235 [00:14<00:02, 13.42it/s]\u001b[A\n",
            "Loss: 0.0851:  84%|████████▍ | 198/235 [00:14<00:02, 13.42it/s]\u001b[A\n",
            "Loss: 0.0942:  84%|████████▍ | 198/235 [00:14<00:02, 13.42it/s]\u001b[A\n",
            "Loss: 0.0942:  85%|████████▌ | 200/235 [00:14<00:02, 13.51it/s]\u001b[A\n",
            "Loss: 0.0766:  85%|████████▌ | 200/235 [00:14<00:02, 13.51it/s]\u001b[A\n",
            "Loss: 0.0767:  85%|████████▌ | 200/235 [00:14<00:02, 13.51it/s]\u001b[A\n",
            "Loss: 0.0767:  86%|████████▌ | 202/235 [00:14<00:02, 13.51it/s]\u001b[A\n",
            "Loss: 0.0857:  86%|████████▌ | 202/235 [00:15<00:02, 13.51it/s]\u001b[A\n",
            "Loss: 0.0861:  86%|████████▌ | 202/235 [00:15<00:02, 13.51it/s]\u001b[A\n",
            "Loss: 0.0861:  87%|████████▋ | 204/235 [00:15<00:02, 13.48it/s]\u001b[A\n",
            "Loss: 0.0766:  87%|████████▋ | 204/235 [00:15<00:02, 13.48it/s]\u001b[A\n",
            "Loss: 0.0723:  87%|████████▋ | 204/235 [00:15<00:02, 13.48it/s]\u001b[A\n",
            "Loss: 0.0723:  88%|████████▊ | 206/235 [00:15<00:02, 13.36it/s]\u001b[A\n",
            "Loss: 0.0801:  88%|████████▊ | 206/235 [00:15<00:02, 13.36it/s]\u001b[A\n",
            "Loss: 0.0734:  88%|████████▊ | 206/235 [00:15<00:02, 13.36it/s]\u001b[A\n",
            "Loss: 0.0734:  89%|████████▊ | 208/235 [00:15<00:02, 13.39it/s]\u001b[A\n",
            "Loss: 0.0853:  89%|████████▊ | 208/235 [00:15<00:02, 13.39it/s]\u001b[A\n",
            "Loss: 0.0801:  89%|████████▊ | 208/235 [00:15<00:02, 13.39it/s]\u001b[A\n",
            "Loss: 0.0801:  89%|████████▉ | 210/235 [00:15<00:01, 13.29it/s]\u001b[A\n",
            "Loss: 0.0923:  89%|████████▉ | 210/235 [00:15<00:01, 13.29it/s]\u001b[A\n",
            "Loss: 0.0902:  89%|████████▉ | 210/235 [00:15<00:01, 13.29it/s]\u001b[A\n",
            "Loss: 0.0902:  90%|█████████ | 212/235 [00:15<00:01, 13.40it/s]\u001b[A\n",
            "Loss: 0.0894:  90%|█████████ | 212/235 [00:15<00:01, 13.40it/s]\u001b[A\n",
            "Loss: 0.0865:  90%|█████████ | 212/235 [00:15<00:01, 13.40it/s]\u001b[A\n",
            "Loss: 0.0865:  91%|█████████ | 214/235 [00:15<00:01, 13.21it/s]\u001b[A\n",
            "Loss: 0.0790:  91%|█████████ | 214/235 [00:15<00:01, 13.21it/s]\u001b[A\n",
            "Loss: 0.0787:  91%|█████████ | 214/235 [00:16<00:01, 13.21it/s]\u001b[A\n",
            "Loss: 0.0787:  92%|█████████▏| 216/235 [00:16<00:01, 13.23it/s]\u001b[A\n",
            "Loss: 0.0781:  92%|█████████▏| 216/235 [00:16<00:01, 13.23it/s]\u001b[A\n",
            "Loss: 0.0860:  92%|█████████▏| 216/235 [00:16<00:01, 13.23it/s]\u001b[A\n",
            "Loss: 0.0860:  93%|█████████▎| 218/235 [00:16<00:01, 13.18it/s]\u001b[A\n",
            "Loss: 0.0756:  93%|█████████▎| 218/235 [00:16<00:01, 13.18it/s]\u001b[A\n",
            "Loss: 0.0760:  93%|█████████▎| 218/235 [00:16<00:01, 13.18it/s]\u001b[A\n",
            "Loss: 0.0760:  94%|█████████▎| 220/235 [00:16<00:01, 13.24it/s]\u001b[A\n",
            "Loss: 0.0847:  94%|█████████▎| 220/235 [00:16<00:01, 13.24it/s]\u001b[A\n",
            "Loss: 0.0806:  94%|█████████▎| 220/235 [00:16<00:01, 13.24it/s]\u001b[A\n",
            "Loss: 0.0806:  94%|█████████▍| 222/235 [00:16<00:00, 13.14it/s]\u001b[A\n",
            "Loss: 0.0837:  94%|█████████▍| 222/235 [00:16<00:00, 13.14it/s]\u001b[A\n",
            "Loss: 0.0789:  94%|█████████▍| 222/235 [00:16<00:00, 13.14it/s]\u001b[A\n",
            "Loss: 0.0789:  95%|█████████▌| 224/235 [00:16<00:00, 13.27it/s]\u001b[A\n",
            "Loss: 0.0795:  95%|█████████▌| 224/235 [00:16<00:00, 13.27it/s]\u001b[A\n",
            "Loss: 0.0816:  95%|█████████▌| 224/235 [00:16<00:00, 13.27it/s]\u001b[A\n",
            "Loss: 0.0816:  96%|█████████▌| 226/235 [00:16<00:00, 13.17it/s]\u001b[A\n",
            "Loss: 0.0806:  96%|█████████▌| 226/235 [00:16<00:00, 13.17it/s]\u001b[A\n",
            "Loss: 0.0855:  96%|█████████▌| 226/235 [00:16<00:00, 13.17it/s]\u001b[A\n",
            "Loss: 0.0855:  97%|█████████▋| 228/235 [00:16<00:00, 13.23it/s]\u001b[A\n",
            "Loss: 0.0877:  97%|█████████▋| 228/235 [00:17<00:00, 13.23it/s]\u001b[A\n",
            "Loss: 0.0876:  97%|█████████▋| 228/235 [00:17<00:00, 13.23it/s]\u001b[A\n",
            "Loss: 0.0876:  98%|█████████▊| 230/235 [00:17<00:00, 13.22it/s]\u001b[A\n",
            "Loss: 0.0884:  98%|█████████▊| 230/235 [00:17<00:00, 13.22it/s]\u001b[A\n",
            "Loss: 0.0918:  98%|█████████▊| 230/235 [00:17<00:00, 13.22it/s]\u001b[A\n",
            "Loss: 0.0918:  99%|█████████▊| 232/235 [00:17<00:00, 13.09it/s]\u001b[A\n",
            "Loss: 0.0794:  99%|█████████▊| 232/235 [00:17<00:00, 13.09it/s]\u001b[A\n",
            "Loss: 0.0870:  99%|█████████▊| 232/235 [00:17<00:00, 13.09it/s]\u001b[A\n",
            "Loss: 0.0870: 100%|█████████▉| 234/235 [00:17<00:00, 13.23it/s]\u001b[A\n",
            "Loss: 0.0810: 100%|█████████▉| 234/235 [00:17<00:00, 13.23it/s]\u001b[A\n",
            "  3%|▎         | 3/100 [00:52<28:15, 17.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean loss for Epoch 3: 0.0864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 0.0765:   0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 0.0841:   0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 0.0841:   1%|          | 2/235 [00:00<00:17, 13.16it/s]\u001b[A\n",
            "Loss: 0.0849:   1%|          | 2/235 [00:00<00:17, 13.16it/s]\u001b[A\n",
            "Loss: 0.0791:   1%|          | 2/235 [00:00<00:17, 13.16it/s]\u001b[A\n",
            "Loss: 0.0791:   2%|▏         | 4/235 [00:00<00:17, 13.26it/s]\u001b[A\n",
            "Loss: 0.0809:   2%|▏         | 4/235 [00:00<00:17, 13.26it/s]\u001b[A\n",
            "Loss: 0.0786:   2%|▏         | 4/235 [00:00<00:17, 13.26it/s]\u001b[A\n",
            "Loss: 0.0786:   3%|▎         | 6/235 [00:00<00:17, 13.45it/s]\u001b[A\n",
            "Loss: 0.0860:   3%|▎         | 6/235 [00:00<00:17, 13.45it/s]\u001b[A\n",
            "Loss: 0.0853:   3%|▎         | 6/235 [00:00<00:17, 13.45it/s]\u001b[A\n",
            "Loss: 0.0853:   3%|▎         | 8/235 [00:00<00:16, 13.50it/s]\u001b[A\n",
            "Loss: 0.0902:   3%|▎         | 8/235 [00:00<00:16, 13.50it/s]\u001b[A\n",
            "Loss: 0.0801:   3%|▎         | 8/235 [00:00<00:16, 13.50it/s]\u001b[A\n",
            "Loss: 0.0801:   4%|▍         | 10/235 [00:00<00:16, 13.51it/s]\u001b[A\n",
            "Loss: 0.0851:   4%|▍         | 10/235 [00:00<00:16, 13.51it/s]\u001b[A\n",
            "Loss: 0.0803:   4%|▍         | 10/235 [00:00<00:16, 13.51it/s]\u001b[A\n",
            "Loss: 0.0803:   5%|▌         | 12/235 [00:00<00:16, 13.47it/s]\u001b[A\n",
            "Loss: 0.0782:   5%|▌         | 12/235 [00:00<00:16, 13.47it/s]\u001b[A\n",
            "Loss: 0.0804:   5%|▌         | 12/235 [00:01<00:16, 13.47it/s]\u001b[A\n",
            "Loss: 0.0804:   6%|▌         | 14/235 [00:01<00:16, 13.44it/s]\u001b[A\n",
            "Loss: 0.0750:   6%|▌         | 14/235 [00:01<00:16, 13.44it/s]\u001b[A\n",
            "Loss: 0.0779:   6%|▌         | 14/235 [00:01<00:16, 13.44it/s]\u001b[A\n",
            "Loss: 0.0779:   7%|▋         | 16/235 [00:01<00:16, 13.53it/s]\u001b[A\n",
            "Loss: 0.0823:   7%|▋         | 16/235 [00:01<00:16, 13.53it/s]\u001b[A\n",
            "Loss: 0.0847:   7%|▋         | 16/235 [00:01<00:16, 13.53it/s]\u001b[A\n",
            "Loss: 0.0847:   8%|▊         | 18/235 [00:01<00:16, 13.54it/s]\u001b[A\n",
            "Loss: 0.0750:   8%|▊         | 18/235 [00:01<00:16, 13.54it/s]\u001b[A\n",
            "Loss: 0.0778:   8%|▊         | 18/235 [00:01<00:16, 13.54it/s]\u001b[A\n",
            "Loss: 0.0778:   9%|▊         | 20/235 [00:01<00:15, 13.52it/s]\u001b[A\n",
            "Loss: 0.0838:   9%|▊         | 20/235 [00:01<00:15, 13.52it/s]\u001b[A\n",
            "Loss: 0.0724:   9%|▊         | 20/235 [00:01<00:15, 13.52it/s]\u001b[A\n",
            "Loss: 0.0724:   9%|▉         | 22/235 [00:01<00:15, 13.59it/s]\u001b[A\n",
            "Loss: 0.0724:   9%|▉         | 22/235 [00:01<00:15, 13.59it/s]\u001b[A\n",
            "Loss: 0.0808:   9%|▉         | 22/235 [00:01<00:15, 13.59it/s]\u001b[A\n",
            "Loss: 0.0808:  10%|█         | 24/235 [00:01<00:15, 13.61it/s]\u001b[A\n",
            "Loss: 0.0805:  10%|█         | 24/235 [00:01<00:15, 13.61it/s]\u001b[A\n",
            "Loss: 0.0785:  10%|█         | 24/235 [00:01<00:15, 13.61it/s]\u001b[A\n",
            "Loss: 0.0785:  11%|█         | 26/235 [00:01<00:15, 13.54it/s]\u001b[A\n",
            "Loss: 0.0838:  11%|█         | 26/235 [00:01<00:15, 13.54it/s]\u001b[A\n",
            "Loss: 0.0784:  11%|█         | 26/235 [00:02<00:15, 13.54it/s]\u001b[A\n",
            "Loss: 0.0784:  12%|█▏        | 28/235 [00:02<00:15, 13.50it/s]\u001b[A\n",
            "Loss: 0.0775:  12%|█▏        | 28/235 [00:02<00:15, 13.50it/s]\u001b[A\n",
            "Loss: 0.0765:  12%|█▏        | 28/235 [00:02<00:15, 13.50it/s]\u001b[A\n",
            "Loss: 0.0765:  13%|█▎        | 30/235 [00:02<00:15, 13.43it/s]\u001b[A\n",
            "Loss: 0.0762:  13%|█▎        | 30/235 [00:02<00:15, 13.43it/s]\u001b[A\n",
            "Loss: 0.0701:  13%|█▎        | 30/235 [00:02<00:15, 13.43it/s]\u001b[A\n",
            "Loss: 0.0701:  14%|█▎        | 32/235 [00:02<00:15, 13.47it/s]\u001b[A\n",
            "Loss: 0.0872:  14%|█▎        | 32/235 [00:02<00:15, 13.47it/s]\u001b[A\n",
            "Loss: 0.0735:  14%|█▎        | 32/235 [00:02<00:15, 13.47it/s]\u001b[A\n",
            "Loss: 0.0735:  14%|█▍        | 34/235 [00:02<00:14, 13.47it/s]\u001b[A\n",
            "Loss: 0.0799:  14%|█▍        | 34/235 [00:02<00:14, 13.47it/s]\u001b[A\n",
            "Loss: 0.0860:  14%|█▍        | 34/235 [00:02<00:14, 13.47it/s]\u001b[A\n",
            "Loss: 0.0860:  15%|█▌        | 36/235 [00:02<00:14, 13.48it/s]\u001b[A\n",
            "Loss: 0.0765:  15%|█▌        | 36/235 [00:02<00:14, 13.48it/s]\u001b[A\n",
            "Loss: 0.0755:  15%|█▌        | 36/235 [00:02<00:14, 13.48it/s]\u001b[A\n",
            "Loss: 0.0755:  16%|█▌        | 38/235 [00:02<00:14, 13.50it/s]\u001b[A\n",
            "Loss: 0.0790:  16%|█▌        | 38/235 [00:02<00:14, 13.50it/s]\u001b[A\n",
            "Loss: 0.0846:  16%|█▌        | 38/235 [00:02<00:14, 13.50it/s]\u001b[A\n",
            "Loss: 0.0846:  17%|█▋        | 40/235 [00:02<00:14, 13.49it/s]\u001b[A\n",
            "Loss: 0.0734:  17%|█▋        | 40/235 [00:03<00:14, 13.49it/s]\u001b[A\n",
            "Loss: 0.0749:  17%|█▋        | 40/235 [00:03<00:14, 13.49it/s]\u001b[A\n",
            "Loss: 0.0749:  18%|█▊        | 42/235 [00:03<00:14, 13.46it/s]\u001b[A\n",
            "Loss: 0.0778:  18%|█▊        | 42/235 [00:03<00:14, 13.46it/s]\u001b[A\n",
            "Loss: 0.0788:  18%|█▊        | 42/235 [00:03<00:14, 13.46it/s]\u001b[A\n",
            "Loss: 0.0788:  19%|█▊        | 44/235 [00:03<00:14, 13.52it/s]\u001b[A\n",
            "Loss: 0.0837:  19%|█▊        | 44/235 [00:03<00:14, 13.52it/s]\u001b[A\n",
            "Loss: 0.0726:  19%|█▊        | 44/235 [00:03<00:14, 13.52it/s]\u001b[A\n",
            "Loss: 0.0726:  20%|█▉        | 46/235 [00:03<00:14, 13.47it/s]\u001b[A\n",
            "Loss: 0.0779:  20%|█▉        | 46/235 [00:03<00:14, 13.47it/s]\u001b[A\n",
            "Loss: 0.0745:  20%|█▉        | 46/235 [00:03<00:14, 13.47it/s]\u001b[A\n",
            "Loss: 0.0745:  20%|██        | 48/235 [00:03<00:13, 13.42it/s]\u001b[A\n",
            "Loss: 0.0776:  20%|██        | 48/235 [00:03<00:13, 13.42it/s]\u001b[A\n",
            "Loss: 0.0747:  20%|██        | 48/235 [00:03<00:13, 13.42it/s]\u001b[A\n",
            "Loss: 0.0747:  21%|██▏       | 50/235 [00:03<00:13, 13.45it/s]\u001b[A\n",
            "Loss: 0.0753:  21%|██▏       | 50/235 [00:03<00:13, 13.45it/s]\u001b[A\n",
            "Loss: 0.0734:  21%|██▏       | 50/235 [00:03<00:13, 13.45it/s]\u001b[A\n",
            "Loss: 0.0734:  22%|██▏       | 52/235 [00:03<00:13, 13.55it/s]\u001b[A\n",
            "Loss: 0.0902:  22%|██▏       | 52/235 [00:03<00:13, 13.55it/s]\u001b[A\n",
            "Loss: 0.0775:  22%|██▏       | 52/235 [00:04<00:13, 13.55it/s]\u001b[A\n",
            "Loss: 0.0775:  23%|██▎       | 54/235 [00:04<00:13, 13.53it/s]\u001b[A\n",
            "Loss: 0.0752:  23%|██▎       | 54/235 [00:04<00:13, 13.53it/s]\u001b[A\n",
            "Loss: 0.0749:  23%|██▎       | 54/235 [00:04<00:13, 13.53it/s]\u001b[A\n",
            "Loss: 0.0749:  24%|██▍       | 56/235 [00:04<00:13, 13.58it/s]\u001b[A\n",
            "Loss: 0.0753:  24%|██▍       | 56/235 [00:04<00:13, 13.58it/s]\u001b[A\n",
            "Loss: 0.0787:  24%|██▍       | 56/235 [00:04<00:13, 13.58it/s]\u001b[A\n",
            "Loss: 0.0787:  25%|██▍       | 58/235 [00:04<00:13, 13.55it/s]\u001b[A\n",
            "Loss: 0.0742:  25%|██▍       | 58/235 [00:04<00:13, 13.55it/s]\u001b[A\n",
            "Loss: 0.0810:  25%|██▍       | 58/235 [00:04<00:13, 13.55it/s]\u001b[A\n",
            "Loss: 0.0810:  26%|██▌       | 60/235 [00:04<00:13, 13.46it/s]\u001b[A\n",
            "Loss: 0.0733:  26%|██▌       | 60/235 [00:04<00:13, 13.46it/s]\u001b[A\n",
            "Loss: 0.0786:  26%|██▌       | 60/235 [00:04<00:13, 13.46it/s]\u001b[A\n",
            "Loss: 0.0786:  26%|██▋       | 62/235 [00:04<00:12, 13.44it/s]\u001b[A\n",
            "Loss: 0.0881:  26%|██▋       | 62/235 [00:04<00:12, 13.44it/s]\u001b[A\n",
            "Loss: 0.0753:  26%|██▋       | 62/235 [00:04<00:12, 13.44it/s]\u001b[A\n",
            "Loss: 0.0753:  27%|██▋       | 64/235 [00:04<00:12, 13.52it/s]\u001b[A\n",
            "Loss: 0.0802:  27%|██▋       | 64/235 [00:04<00:12, 13.52it/s]\u001b[A\n",
            "Loss: 0.0783:  27%|██▋       | 64/235 [00:04<00:12, 13.52it/s]\u001b[A\n",
            "Loss: 0.0783:  28%|██▊       | 66/235 [00:04<00:12, 13.45it/s]\u001b[A\n",
            "Loss: 0.0763:  28%|██▊       | 66/235 [00:04<00:12, 13.45it/s]\u001b[A\n",
            "Loss: 0.0729:  28%|██▊       | 66/235 [00:05<00:12, 13.45it/s]\u001b[A\n",
            "Loss: 0.0729:  29%|██▉       | 68/235 [00:05<00:12, 13.50it/s]\u001b[A\n",
            "Loss: 0.0772:  29%|██▉       | 68/235 [00:05<00:12, 13.50it/s]\u001b[A\n",
            "Loss: 0.0701:  29%|██▉       | 68/235 [00:05<00:12, 13.50it/s]\u001b[A\n",
            "Loss: 0.0701:  30%|██▉       | 70/235 [00:05<00:12, 13.53it/s]\u001b[A\n",
            "Loss: 0.0855:  30%|██▉       | 70/235 [00:05<00:12, 13.53it/s]\u001b[A\n",
            "Loss: 0.0747:  30%|██▉       | 70/235 [00:05<00:12, 13.53it/s]\u001b[A\n",
            "Loss: 0.0747:  31%|███       | 72/235 [00:05<00:11, 13.64it/s]\u001b[A\n",
            "Loss: 0.0779:  31%|███       | 72/235 [00:05<00:11, 13.64it/s]\u001b[A\n",
            "Loss: 0.0798:  31%|███       | 72/235 [00:05<00:11, 13.64it/s]\u001b[A\n",
            "Loss: 0.0798:  31%|███▏      | 74/235 [00:05<00:11, 13.69it/s]\u001b[A\n",
            "Loss: 0.0765:  31%|███▏      | 74/235 [00:05<00:11, 13.69it/s]\u001b[A\n",
            "Loss: 0.0747:  31%|███▏      | 74/235 [00:05<00:11, 13.69it/s]\u001b[A\n",
            "Loss: 0.0747:  32%|███▏      | 76/235 [00:05<00:11, 13.70it/s]\u001b[A\n",
            "Loss: 0.0744:  32%|███▏      | 76/235 [00:05<00:11, 13.70it/s]\u001b[A\n",
            "Loss: 0.0831:  32%|███▏      | 76/235 [00:05<00:11, 13.70it/s]\u001b[A\n",
            "Loss: 0.0831:  33%|███▎      | 78/235 [00:05<00:11, 13.63it/s]\u001b[A\n",
            "Loss: 0.0795:  33%|███▎      | 78/235 [00:05<00:11, 13.63it/s]\u001b[A\n",
            "Loss: 0.0780:  33%|███▎      | 78/235 [00:05<00:11, 13.63it/s]\u001b[A\n",
            "Loss: 0.0780:  34%|███▍      | 80/235 [00:05<00:11, 13.55it/s]\u001b[A\n",
            "Loss: 0.0787:  34%|███▍      | 80/235 [00:05<00:11, 13.55it/s]\u001b[A\n",
            "Loss: 0.0758:  34%|███▍      | 80/235 [00:06<00:11, 13.55it/s]\u001b[A\n",
            "Loss: 0.0758:  35%|███▍      | 82/235 [00:06<00:11, 13.61it/s]\u001b[A\n",
            "Loss: 0.0807:  35%|███▍      | 82/235 [00:06<00:11, 13.61it/s]\u001b[A\n",
            "Loss: 0.0798:  35%|███▍      | 82/235 [00:06<00:11, 13.61it/s]\u001b[A\n",
            "Loss: 0.0798:  36%|███▌      | 84/235 [00:06<00:11, 13.52it/s]\u001b[A\n",
            "Loss: 0.0765:  36%|███▌      | 84/235 [00:06<00:11, 13.52it/s]\u001b[A\n",
            "Loss: 0.0800:  36%|███▌      | 84/235 [00:06<00:11, 13.52it/s]\u001b[A\n",
            "Loss: 0.0800:  37%|███▋      | 86/235 [00:06<00:11, 13.51it/s]\u001b[A\n",
            "Loss: 0.0729:  37%|███▋      | 86/235 [00:06<00:11, 13.51it/s]\u001b[A\n",
            "Loss: 0.0748:  37%|███▋      | 86/235 [00:06<00:11, 13.51it/s]\u001b[A\n",
            "Loss: 0.0748:  37%|███▋      | 88/235 [00:06<00:11, 13.33it/s]\u001b[A\n",
            "Loss: 0.0831:  37%|███▋      | 88/235 [00:06<00:11, 13.33it/s]\u001b[A\n",
            "Loss: 0.0782:  37%|███▋      | 88/235 [00:06<00:11, 13.33it/s]\u001b[A\n",
            "Loss: 0.0782:  38%|███▊      | 90/235 [00:06<00:10, 13.40it/s]\u001b[A\n",
            "Loss: 0.0803:  38%|███▊      | 90/235 [00:06<00:10, 13.40it/s]\u001b[A\n",
            "Loss: 0.0839:  38%|███▊      | 90/235 [00:06<00:10, 13.40it/s]\u001b[A\n",
            "Loss: 0.0839:  39%|███▉      | 92/235 [00:06<00:10, 13.35it/s]\u001b[A\n",
            "Loss: 0.0765:  39%|███▉      | 92/235 [00:06<00:10, 13.35it/s]\u001b[A\n",
            "Loss: 0.0854:  39%|███▉      | 92/235 [00:06<00:10, 13.35it/s]\u001b[A\n",
            "Loss: 0.0854:  40%|████      | 94/235 [00:06<00:10, 13.40it/s]\u001b[A\n",
            "Loss: 0.0782:  40%|████      | 94/235 [00:07<00:10, 13.40it/s]\u001b[A\n",
            "Loss: 0.0761:  40%|████      | 94/235 [00:07<00:10, 13.40it/s]\u001b[A\n",
            "Loss: 0.0761:  41%|████      | 96/235 [00:07<00:10, 13.35it/s]\u001b[A\n",
            "Loss: 0.0828:  41%|████      | 96/235 [00:07<00:10, 13.35it/s]\u001b[A\n",
            "Loss: 0.0763:  41%|████      | 96/235 [00:07<00:10, 13.35it/s]\u001b[A\n",
            "Loss: 0.0763:  42%|████▏     | 98/235 [00:07<00:10, 13.36it/s]\u001b[A\n",
            "Loss: 0.0803:  42%|████▏     | 98/235 [00:07<00:10, 13.36it/s]\u001b[A\n",
            "Loss: 0.0777:  42%|████▏     | 98/235 [00:07<00:10, 13.36it/s]\u001b[A\n",
            "Loss: 0.0777:  43%|████▎     | 100/235 [00:07<00:10, 13.25it/s]\u001b[A\n",
            "Loss: 0.0804:  43%|████▎     | 100/235 [00:07<00:10, 13.25it/s]\u001b[A\n",
            "Loss: 0.0745:  43%|████▎     | 100/235 [00:07<00:10, 13.25it/s]\u001b[A\n",
            "Loss: 0.0745:  43%|████▎     | 102/235 [00:07<00:10, 13.23it/s]\u001b[A\n",
            "Loss: 0.0747:  43%|████▎     | 102/235 [00:07<00:10, 13.23it/s]\u001b[A\n",
            "Loss: 0.0737:  43%|████▎     | 102/235 [00:07<00:10, 13.23it/s]\u001b[A\n",
            "Loss: 0.0737:  44%|████▍     | 104/235 [00:07<00:09, 13.23it/s]\u001b[A\n",
            "Loss: 0.0730:  44%|████▍     | 104/235 [00:07<00:09, 13.23it/s]\u001b[A\n",
            "Loss: 0.0731:  44%|████▍     | 104/235 [00:07<00:09, 13.23it/s]\u001b[A\n",
            "Loss: 0.0731:  45%|████▌     | 106/235 [00:07<00:09, 13.27it/s]\u001b[A\n",
            "Loss: 0.0706:  45%|████▌     | 106/235 [00:07<00:09, 13.27it/s]\u001b[A\n",
            "Loss: 0.0766:  45%|████▌     | 106/235 [00:08<00:09, 13.27it/s]\u001b[A\n",
            "Loss: 0.0766:  46%|████▌     | 108/235 [00:08<00:09, 13.20it/s]\u001b[A\n",
            "Loss: 0.0797:  46%|████▌     | 108/235 [00:08<00:09, 13.20it/s]\u001b[A\n",
            "Loss: 0.0811:  46%|████▌     | 108/235 [00:08<00:09, 13.20it/s]\u001b[A\n",
            "Loss: 0.0811:  47%|████▋     | 110/235 [00:08<00:09, 13.23it/s]\u001b[A\n",
            "Loss: 0.0782:  47%|████▋     | 110/235 [00:08<00:09, 13.23it/s]\u001b[A\n",
            "Loss: 0.0727:  47%|████▋     | 110/235 [00:08<00:09, 13.23it/s]\u001b[A\n",
            "Loss: 0.0727:  48%|████▊     | 112/235 [00:08<00:09, 13.26it/s]\u001b[A\n",
            "Loss: 0.0773:  48%|████▊     | 112/235 [00:08<00:09, 13.26it/s]\u001b[A\n",
            "Loss: 0.0764:  48%|████▊     | 112/235 [00:08<00:09, 13.26it/s]\u001b[A\n",
            "Loss: 0.0764:  49%|████▊     | 114/235 [00:08<00:09, 13.28it/s]\u001b[A\n",
            "Loss: 0.0745:  49%|████▊     | 114/235 [00:08<00:09, 13.28it/s]\u001b[A\n",
            "Loss: 0.0793:  49%|████▊     | 114/235 [00:08<00:09, 13.28it/s]\u001b[A\n",
            "Loss: 0.0793:  49%|████▉     | 116/235 [00:08<00:08, 13.42it/s]\u001b[A\n",
            "Loss: 0.0718:  49%|████▉     | 116/235 [00:08<00:08, 13.42it/s]\u001b[A\n",
            "Loss: 0.0751:  49%|████▉     | 116/235 [00:08<00:08, 13.42it/s]\u001b[A\n",
            "Loss: 0.0751:  50%|█████     | 118/235 [00:08<00:08, 13.46it/s]\u001b[A\n",
            "Loss: 0.0779:  50%|█████     | 118/235 [00:08<00:08, 13.46it/s]\u001b[A\n",
            "Loss: 0.0687:  50%|█████     | 118/235 [00:08<00:08, 13.46it/s]\u001b[A\n",
            "Loss: 0.0687:  51%|█████     | 120/235 [00:08<00:08, 13.44it/s]\u001b[A\n",
            "Loss: 0.0724:  51%|█████     | 120/235 [00:08<00:08, 13.44it/s]\u001b[A\n",
            "Loss: 0.0784:  51%|█████     | 120/235 [00:09<00:08, 13.44it/s]\u001b[A\n",
            "Loss: 0.0784:  52%|█████▏    | 122/235 [00:09<00:08, 13.37it/s]\u001b[A\n",
            "Loss: 0.0726:  52%|█████▏    | 122/235 [00:09<00:08, 13.37it/s]\u001b[A\n",
            "Loss: 0.0842:  52%|█████▏    | 122/235 [00:09<00:08, 13.37it/s]\u001b[A\n",
            "Loss: 0.0842:  53%|█████▎    | 124/235 [00:09<00:08, 13.32it/s]\u001b[A\n",
            "Loss: 0.0766:  53%|█████▎    | 124/235 [00:09<00:08, 13.32it/s]\u001b[A\n",
            "Loss: 0.0781:  53%|█████▎    | 124/235 [00:09<00:08, 13.32it/s]\u001b[A\n",
            "Loss: 0.0781:  54%|█████▎    | 126/235 [00:09<00:08, 13.30it/s]\u001b[A\n",
            "Loss: 0.0822:  54%|█████▎    | 126/235 [00:09<00:08, 13.30it/s]\u001b[A\n",
            "Loss: 0.0763:  54%|█████▎    | 126/235 [00:09<00:08, 13.30it/s]\u001b[A\n",
            "Loss: 0.0763:  54%|█████▍    | 128/235 [00:09<00:08, 13.22it/s]\u001b[A\n",
            "Loss: 0.0751:  54%|█████▍    | 128/235 [00:09<00:08, 13.22it/s]\u001b[A\n",
            "Loss: 0.0733:  54%|█████▍    | 128/235 [00:09<00:08, 13.22it/s]\u001b[A\n",
            "Loss: 0.0733:  55%|█████▌    | 130/235 [00:09<00:07, 13.17it/s]\u001b[A\n",
            "Loss: 0.0805:  55%|█████▌    | 130/235 [00:09<00:07, 13.17it/s]\u001b[A\n",
            "Loss: 0.0724:  55%|█████▌    | 130/235 [00:09<00:07, 13.17it/s]\u001b[A\n",
            "Loss: 0.0724:  56%|█████▌    | 132/235 [00:09<00:07, 13.01it/s]\u001b[A\n",
            "Loss: 0.0778:  56%|█████▌    | 132/235 [00:09<00:07, 13.01it/s]\u001b[A\n",
            "Loss: 0.0795:  56%|█████▌    | 132/235 [00:09<00:07, 13.01it/s]\u001b[A\n",
            "Loss: 0.0795:  57%|█████▋    | 134/235 [00:09<00:07, 12.96it/s]\u001b[A\n",
            "Loss: 0.0756:  57%|█████▋    | 134/235 [00:10<00:07, 12.96it/s]\u001b[A\n",
            "Loss: 0.0793:  57%|█████▋    | 134/235 [00:10<00:07, 12.96it/s]\u001b[A\n",
            "Loss: 0.0793:  58%|█████▊    | 136/235 [00:10<00:07, 12.94it/s]\u001b[A\n",
            "Loss: 0.0688:  58%|█████▊    | 136/235 [00:10<00:07, 12.94it/s]\u001b[A\n",
            "Loss: 0.0770:  58%|█████▊    | 136/235 [00:10<00:07, 12.94it/s]\u001b[A\n",
            "Loss: 0.0770:  59%|█████▊    | 138/235 [00:10<00:07, 12.94it/s]\u001b[A\n",
            "Loss: 0.0788:  59%|█████▊    | 138/235 [00:10<00:07, 12.94it/s]\u001b[A\n",
            "Loss: 0.0684:  59%|█████▊    | 138/235 [00:10<00:07, 12.94it/s]\u001b[A\n",
            "Loss: 0.0684:  60%|█████▉    | 140/235 [00:10<00:07, 12.90it/s]\u001b[A\n",
            "Loss: 0.0742:  60%|█████▉    | 140/235 [00:10<00:07, 12.90it/s]\u001b[A\n",
            "Loss: 0.0787:  60%|█████▉    | 140/235 [00:10<00:07, 12.90it/s]\u001b[A\n",
            "Loss: 0.0787:  60%|██████    | 142/235 [00:10<00:07, 12.81it/s]\u001b[A\n",
            "Loss: 0.0760:  60%|██████    | 142/235 [00:10<00:07, 12.81it/s]\u001b[A\n",
            "Loss: 0.0729:  60%|██████    | 142/235 [00:10<00:07, 12.81it/s]\u001b[A\n",
            "Loss: 0.0729:  61%|██████▏   | 144/235 [00:10<00:07, 12.86it/s]\u001b[A\n",
            "Loss: 0.0747:  61%|██████▏   | 144/235 [00:10<00:07, 12.86it/s]\u001b[A\n",
            "Loss: 0.0817:  61%|██████▏   | 144/235 [00:10<00:07, 12.86it/s]\u001b[A\n",
            "Loss: 0.0817:  62%|██████▏   | 146/235 [00:10<00:06, 12.77it/s]\u001b[A\n",
            "Loss: 0.0807:  62%|██████▏   | 146/235 [00:11<00:06, 12.77it/s]\u001b[A\n",
            "Loss: 0.0785:  62%|██████▏   | 146/235 [00:11<00:06, 12.77it/s]\u001b[A\n",
            "Loss: 0.0785:  63%|██████▎   | 148/235 [00:11<00:06, 12.87it/s]\u001b[A\n",
            "Loss: 0.0766:  63%|██████▎   | 148/235 [00:11<00:06, 12.87it/s]\u001b[A\n",
            "Loss: 0.0784:  63%|██████▎   | 148/235 [00:11<00:06, 12.87it/s]\u001b[A\n",
            "Loss: 0.0784:  64%|██████▍   | 150/235 [00:11<00:06, 13.00it/s]\u001b[A\n",
            "Loss: 0.0733:  64%|██████▍   | 150/235 [00:11<00:06, 13.00it/s]\u001b[A\n",
            "Loss: 0.0833:  64%|██████▍   | 150/235 [00:11<00:06, 13.00it/s]\u001b[A\n",
            "Loss: 0.0833:  65%|██████▍   | 152/235 [00:11<00:06, 13.08it/s]\u001b[A\n",
            "Loss: 0.0685:  65%|██████▍   | 152/235 [00:11<00:06, 13.08it/s]\u001b[A\n",
            "Loss: 0.0742:  65%|██████▍   | 152/235 [00:11<00:06, 13.08it/s]\u001b[A\n",
            "Loss: 0.0742:  66%|██████▌   | 154/235 [00:11<00:06, 13.11it/s]\u001b[A\n",
            "Loss: 0.0700:  66%|██████▌   | 154/235 [00:11<00:06, 13.11it/s]\u001b[A\n",
            "Loss: 0.0763:  66%|██████▌   | 154/235 [00:11<00:06, 13.11it/s]\u001b[A\n",
            "Loss: 0.0763:  66%|██████▋   | 156/235 [00:11<00:06, 13.15it/s]\u001b[A\n",
            "Loss: 0.0765:  66%|██████▋   | 156/235 [00:11<00:06, 13.15it/s]\u001b[A\n",
            "Loss: 0.0785:  66%|██████▋   | 156/235 [00:11<00:06, 13.15it/s]\u001b[A\n",
            "Loss: 0.0785:  67%|██████▋   | 158/235 [00:11<00:05, 13.18it/s]\u001b[A\n",
            "Loss: 0.0806:  67%|██████▋   | 158/235 [00:11<00:05, 13.18it/s]\u001b[A\n",
            "Loss: 0.0807:  67%|██████▋   | 158/235 [00:11<00:05, 13.18it/s]\u001b[A\n",
            "Loss: 0.0807:  68%|██████▊   | 160/235 [00:11<00:05, 13.14it/s]\u001b[A\n",
            "Loss: 0.0689:  68%|██████▊   | 160/235 [00:12<00:05, 13.14it/s]\u001b[A\n",
            "Loss: 0.0826:  68%|██████▊   | 160/235 [00:12<00:05, 13.14it/s]\u001b[A\n",
            "Loss: 0.0826:  69%|██████▉   | 162/235 [00:12<00:05, 13.11it/s]\u001b[A\n",
            "Loss: 0.0718:  69%|██████▉   | 162/235 [00:12<00:05, 13.11it/s]\u001b[A\n",
            "Loss: 0.0728:  69%|██████▉   | 162/235 [00:12<00:05, 13.11it/s]\u001b[A\n",
            "Loss: 0.0728:  70%|██████▉   | 164/235 [00:12<00:05, 13.15it/s]\u001b[A\n",
            "Loss: 0.0764:  70%|██████▉   | 164/235 [00:12<00:05, 13.15it/s]\u001b[A\n",
            "Loss: 0.0793:  70%|██████▉   | 164/235 [00:12<00:05, 13.15it/s]\u001b[A\n",
            "Loss: 0.0793:  71%|███████   | 166/235 [00:12<00:05, 13.19it/s]\u001b[A\n",
            "Loss: 0.0729:  71%|███████   | 166/235 [00:12<00:05, 13.19it/s]\u001b[A\n",
            "Loss: 0.0849:  71%|███████   | 166/235 [00:12<00:05, 13.19it/s]\u001b[A\n",
            "Loss: 0.0849:  71%|███████▏  | 168/235 [00:12<00:05, 13.23it/s]\u001b[A\n",
            "Loss: 0.0739:  71%|███████▏  | 168/235 [00:12<00:05, 13.23it/s]\u001b[A\n",
            "Loss: 0.0764:  71%|███████▏  | 168/235 [00:12<00:05, 13.23it/s]\u001b[A\n",
            "Loss: 0.0764:  72%|███████▏  | 170/235 [00:12<00:04, 13.23it/s]\u001b[A\n",
            "Loss: 0.0758:  72%|███████▏  | 170/235 [00:12<00:04, 13.23it/s]\u001b[A\n",
            "Loss: 0.0765:  72%|███████▏  | 170/235 [00:12<00:04, 13.23it/s]\u001b[A\n",
            "Loss: 0.0765:  73%|███████▎  | 172/235 [00:12<00:04, 13.23it/s]\u001b[A\n",
            "Loss: 0.0745:  73%|███████▎  | 172/235 [00:12<00:04, 13.23it/s]\u001b[A\n",
            "Loss: 0.0840:  73%|███████▎  | 172/235 [00:13<00:04, 13.23it/s]\u001b[A\n",
            "Loss: 0.0840:  74%|███████▍  | 174/235 [00:13<00:04, 13.17it/s]\u001b[A\n",
            "Loss: 0.0748:  74%|███████▍  | 174/235 [00:13<00:04, 13.17it/s]\u001b[A\n",
            "Loss: 0.0683:  74%|███████▍  | 174/235 [00:13<00:04, 13.17it/s]\u001b[A\n",
            "Loss: 0.0683:  75%|███████▍  | 176/235 [00:13<00:04, 13.08it/s]\u001b[A\n",
            "Loss: 0.0792:  75%|███████▍  | 176/235 [00:13<00:04, 13.08it/s]\u001b[A\n",
            "Loss: 0.0718:  75%|███████▍  | 176/235 [00:13<00:04, 13.08it/s]\u001b[A\n",
            "Loss: 0.0718:  76%|███████▌  | 178/235 [00:13<00:04, 13.04it/s]\u001b[A\n",
            "Loss: 0.0730:  76%|███████▌  | 178/235 [00:13<00:04, 13.04it/s]\u001b[A\n",
            "Loss: 0.0708:  76%|███████▌  | 178/235 [00:13<00:04, 13.04it/s]\u001b[A\n",
            "Loss: 0.0708:  77%|███████▋  | 180/235 [00:13<00:04, 13.06it/s]\u001b[A\n",
            "Loss: 0.0781:  77%|███████▋  | 180/235 [00:13<00:04, 13.06it/s]\u001b[A\n",
            "Loss: 0.0698:  77%|███████▋  | 180/235 [00:13<00:04, 13.06it/s]\u001b[A\n",
            "Loss: 0.0698:  77%|███████▋  | 182/235 [00:13<00:04, 13.12it/s]\u001b[A\n",
            "Loss: 0.0752:  77%|███████▋  | 182/235 [00:13<00:04, 13.12it/s]\u001b[A\n",
            "Loss: 0.0781:  77%|███████▋  | 182/235 [00:13<00:04, 13.12it/s]\u001b[A\n",
            "Loss: 0.0781:  78%|███████▊  | 184/235 [00:13<00:03, 13.06it/s]\u001b[A\n",
            "Loss: 0.0863:  78%|███████▊  | 184/235 [00:13<00:03, 13.06it/s]\u001b[A\n",
            "Loss: 0.0758:  78%|███████▊  | 184/235 [00:13<00:03, 13.06it/s]\u001b[A\n",
            "Loss: 0.0758:  79%|███████▉  | 186/235 [00:13<00:03, 13.00it/s]\u001b[A\n",
            "Loss: 0.0737:  79%|███████▉  | 186/235 [00:14<00:03, 13.00it/s]\u001b[A\n",
            "Loss: 0.0718:  79%|███████▉  | 186/235 [00:14<00:03, 13.00it/s]\u001b[A\n",
            "Loss: 0.0718:  80%|████████  | 188/235 [00:14<00:03, 13.01it/s]\u001b[A\n",
            "Loss: 0.0781:  80%|████████  | 188/235 [00:14<00:03, 13.01it/s]\u001b[A\n",
            "Loss: 0.0736:  80%|████████  | 188/235 [00:14<00:03, 13.01it/s]\u001b[A\n",
            "Loss: 0.0736:  81%|████████  | 190/235 [00:14<00:03, 13.06it/s]\u001b[A\n",
            "Loss: 0.0779:  81%|████████  | 190/235 [00:14<00:03, 13.06it/s]\u001b[A\n",
            "Loss: 0.0744:  81%|████████  | 190/235 [00:14<00:03, 13.06it/s]\u001b[A\n",
            "Loss: 0.0744:  82%|████████▏ | 192/235 [00:14<00:03, 13.03it/s]\u001b[A\n",
            "Loss: 0.0728:  82%|████████▏ | 192/235 [00:14<00:03, 13.03it/s]\u001b[A\n",
            "Loss: 0.0741:  82%|████████▏ | 192/235 [00:14<00:03, 13.03it/s]\u001b[A\n",
            "Loss: 0.0741:  83%|████████▎ | 194/235 [00:14<00:03, 13.09it/s]\u001b[A\n",
            "Loss: 0.0755:  83%|████████▎ | 194/235 [00:14<00:03, 13.09it/s]\u001b[A\n",
            "Loss: 0.0699:  83%|████████▎ | 194/235 [00:14<00:03, 13.09it/s]\u001b[A\n",
            "Loss: 0.0699:  83%|████████▎ | 196/235 [00:14<00:02, 13.16it/s]\u001b[A\n",
            "Loss: 0.0724:  83%|████████▎ | 196/235 [00:14<00:02, 13.16it/s]\u001b[A\n",
            "Loss: 0.0690:  83%|████████▎ | 196/235 [00:14<00:02, 13.16it/s]\u001b[A\n",
            "Loss: 0.0690:  84%|████████▍ | 198/235 [00:14<00:02, 13.23it/s]\u001b[A\n",
            "Loss: 0.0717:  84%|████████▍ | 198/235 [00:14<00:02, 13.23it/s]\u001b[A\n",
            "Loss: 0.0711:  84%|████████▍ | 198/235 [00:15<00:02, 13.23it/s]\u001b[A\n",
            "Loss: 0.0711:  85%|████████▌ | 200/235 [00:15<00:02, 13.21it/s]\u001b[A\n",
            "Loss: 0.0725:  85%|████████▌ | 200/235 [00:15<00:02, 13.21it/s]\u001b[A\n",
            "Loss: 0.0812:  85%|████████▌ | 200/235 [00:15<00:02, 13.21it/s]\u001b[A\n",
            "Loss: 0.0812:  86%|████████▌ | 202/235 [00:15<00:02, 13.22it/s]\u001b[A\n",
            "Loss: 0.0699:  86%|████████▌ | 202/235 [00:15<00:02, 13.22it/s]\u001b[A\n",
            "Loss: 0.0737:  86%|████████▌ | 202/235 [00:15<00:02, 13.22it/s]\u001b[A\n",
            "Loss: 0.0737:  87%|████████▋ | 204/235 [00:15<00:02, 13.30it/s]\u001b[A\n",
            "Loss: 0.0769:  87%|████████▋ | 204/235 [00:15<00:02, 13.30it/s]\u001b[A\n",
            "Loss: 0.0814:  87%|████████▋ | 204/235 [00:15<00:02, 13.30it/s]\u001b[A\n",
            "Loss: 0.0814:  88%|████████▊ | 206/235 [00:15<00:02, 13.16it/s]\u001b[A\n",
            "Loss: 0.0733:  88%|████████▊ | 206/235 [00:15<00:02, 13.16it/s]\u001b[A\n",
            "Loss: 0.0792:  88%|████████▊ | 206/235 [00:15<00:02, 13.16it/s]\u001b[A\n",
            "Loss: 0.0792:  89%|████████▊ | 208/235 [00:15<00:02, 13.27it/s]\u001b[A\n",
            "Loss: 0.0764:  89%|████████▊ | 208/235 [00:15<00:02, 13.27it/s]\u001b[A\n",
            "Loss: 0.0744:  89%|████████▊ | 208/235 [00:15<00:02, 13.27it/s]\u001b[A\n",
            "Loss: 0.0744:  89%|████████▉ | 210/235 [00:15<00:01, 13.26it/s]\u001b[A\n",
            "Loss: 0.0848:  89%|████████▉ | 210/235 [00:15<00:01, 13.26it/s]\u001b[A\n",
            "Loss: 0.0734:  89%|████████▉ | 210/235 [00:15<00:01, 13.26it/s]\u001b[A\n",
            "Loss: 0.0734:  90%|█████████ | 212/235 [00:15<00:01, 12.80it/s]\u001b[A\n",
            "Loss: 0.0738:  90%|█████████ | 212/235 [00:16<00:01, 12.80it/s]\u001b[A\n",
            "Loss: 0.0820:  90%|█████████ | 212/235 [00:16<00:01, 12.80it/s]\u001b[A\n",
            "Loss: 0.0820:  91%|█████████ | 214/235 [00:16<00:01, 12.86it/s]\u001b[A\n",
            "Loss: 0.0736:  91%|█████████ | 214/235 [00:16<00:01, 12.86it/s]\u001b[A\n",
            "Loss: 0.0750:  91%|█████████ | 214/235 [00:16<00:01, 12.86it/s]\u001b[A\n",
            "Loss: 0.0750:  92%|█████████▏| 216/235 [00:16<00:01, 12.93it/s]\u001b[A\n",
            "Loss: 0.0731:  92%|█████████▏| 216/235 [00:16<00:01, 12.93it/s]\u001b[A\n",
            "Loss: 0.0695:  92%|█████████▏| 216/235 [00:16<00:01, 12.93it/s]\u001b[A\n",
            "Loss: 0.0695:  93%|█████████▎| 218/235 [00:16<00:01, 12.95it/s]\u001b[A\n",
            "Loss: 0.0772:  93%|█████████▎| 218/235 [00:16<00:01, 12.95it/s]\u001b[A\n",
            "Loss: 0.0749:  93%|█████████▎| 218/235 [00:16<00:01, 12.95it/s]\u001b[A\n",
            "Loss: 0.0749:  94%|█████████▎| 220/235 [00:16<00:01, 12.93it/s]\u001b[A\n",
            "Loss: 0.0731:  94%|█████████▎| 220/235 [00:16<00:01, 12.93it/s]\u001b[A\n",
            "Loss: 0.0715:  94%|█████████▎| 220/235 [00:16<00:01, 12.93it/s]\u001b[A\n",
            "Loss: 0.0715:  94%|█████████▍| 222/235 [00:16<00:01, 12.87it/s]\u001b[A\n",
            "Loss: 0.0756:  94%|█████████▍| 222/235 [00:16<00:01, 12.87it/s]\u001b[A\n",
            "Loss: 0.0839:  94%|█████████▍| 222/235 [00:16<00:01, 12.87it/s]\u001b[A\n",
            "Loss: 0.0839:  95%|█████████▌| 224/235 [00:16<00:00, 12.97it/s]\u001b[A\n",
            "Loss: 0.0764:  95%|█████████▌| 224/235 [00:16<00:00, 12.97it/s]\u001b[A\n",
            "Loss: 0.0746:  95%|█████████▌| 224/235 [00:17<00:00, 12.97it/s]\u001b[A\n",
            "Loss: 0.0746:  96%|█████████▌| 226/235 [00:17<00:00, 12.94it/s]\u001b[A\n",
            "Loss: 0.0774:  96%|█████████▌| 226/235 [00:17<00:00, 12.94it/s]\u001b[A\n",
            "Loss: 0.0748:  96%|█████████▌| 226/235 [00:17<00:00, 12.94it/s]\u001b[A\n",
            "Loss: 0.0748:  97%|█████████▋| 228/235 [00:17<00:00, 12.90it/s]\u001b[A\n",
            "Loss: 0.0684:  97%|█████████▋| 228/235 [00:17<00:00, 12.90it/s]\u001b[A\n",
            "Loss: 0.0749:  97%|█████████▋| 228/235 [00:17<00:00, 12.90it/s]\u001b[A\n",
            "Loss: 0.0749:  98%|█████████▊| 230/235 [00:17<00:00, 12.93it/s]\u001b[A\n",
            "Loss: 0.0920:  98%|█████████▊| 230/235 [00:17<00:00, 12.93it/s]\u001b[A\n",
            "Loss: 0.0759:  98%|█████████▊| 230/235 [00:17<00:00, 12.93it/s]\u001b[A\n",
            "Loss: 0.0759:  99%|█████████▊| 232/235 [00:17<00:00, 12.99it/s]\u001b[A\n",
            "Loss: 0.0829:  99%|█████████▊| 232/235 [00:17<00:00, 12.99it/s]\u001b[A\n",
            "Loss: 0.0765:  99%|█████████▊| 232/235 [00:17<00:00, 12.99it/s]\u001b[A\n",
            "Loss: 0.0765: 100%|█████████▉| 234/235 [00:17<00:00, 13.03it/s]\u001b[A\n",
            "Loss: 0.0748: 100%|█████████▉| 234/235 [00:17<00:00, 13.03it/s]\u001b[A\n",
            "  4%|▍         | 4/100 [01:10<28:08, 17.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean loss for Epoch 4: 0.0771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 0.0847:   0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 0.0843:   0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 0.0843:   1%|          | 2/235 [00:00<00:18, 12.94it/s]\u001b[A\n",
            "Loss: 0.0746:   1%|          | 2/235 [00:00<00:18, 12.94it/s]\u001b[A\n",
            "Loss: 0.0795:   1%|          | 2/235 [00:00<00:18, 12.94it/s]\u001b[A\n",
            "Loss: 0.0795:   2%|▏         | 4/235 [00:00<00:17, 12.90it/s]\u001b[A\n",
            "Loss: 0.0769:   2%|▏         | 4/235 [00:00<00:17, 12.90it/s]\u001b[A\n",
            "Loss: 0.0785:   2%|▏         | 4/235 [00:00<00:17, 12.90it/s]\u001b[A\n",
            "Loss: 0.0785:   3%|▎         | 6/235 [00:00<00:17, 12.96it/s]\u001b[A\n",
            "Loss: 0.0768:   3%|▎         | 6/235 [00:00<00:17, 12.96it/s]\u001b[A\n",
            "Loss: 0.0721:   3%|▎         | 6/235 [00:00<00:17, 12.96it/s]\u001b[A\n",
            "Loss: 0.0721:   3%|▎         | 8/235 [00:00<00:17, 12.95it/s]\u001b[A\n",
            "Loss: 0.0863:   3%|▎         | 8/235 [00:00<00:17, 12.95it/s]\u001b[A\n",
            "Loss: 0.0712:   3%|▎         | 8/235 [00:00<00:17, 12.95it/s]\u001b[A\n",
            "Loss: 0.0712:   4%|▍         | 10/235 [00:00<00:17, 12.97it/s]\u001b[A\n",
            "Loss: 0.0777:   4%|▍         | 10/235 [00:00<00:17, 12.97it/s]\u001b[A\n",
            "Loss: 0.0772:   4%|▍         | 10/235 [00:00<00:17, 12.97it/s]\u001b[A\n",
            "Loss: 0.0772:   5%|▌         | 12/235 [00:00<00:17, 13.05it/s]\u001b[A\n",
            "Loss: 0.0746:   5%|▌         | 12/235 [00:00<00:17, 13.05it/s]\u001b[A\n",
            "Loss: 0.0755:   5%|▌         | 12/235 [00:01<00:17, 13.05it/s]\u001b[A\n",
            "Loss: 0.0755:   6%|▌         | 14/235 [00:01<00:16, 13.12it/s]\u001b[A\n",
            "Loss: 0.0759:   6%|▌         | 14/235 [00:01<00:16, 13.12it/s]\u001b[A\n",
            "Loss: 0.0733:   6%|▌         | 14/235 [00:01<00:16, 13.12it/s]\u001b[A\n",
            "Loss: 0.0733:   7%|▋         | 16/235 [00:01<00:16, 13.17it/s]\u001b[A\n",
            "Loss: 0.0712:   7%|▋         | 16/235 [00:01<00:16, 13.17it/s]\u001b[A\n",
            "Loss: 0.0775:   7%|▋         | 16/235 [00:01<00:16, 13.17it/s]\u001b[A\n",
            "Loss: 0.0775:   8%|▊         | 18/235 [00:01<00:16, 13.08it/s]\u001b[A\n",
            "Loss: 0.0639:   8%|▊         | 18/235 [00:01<00:16, 13.08it/s]\u001b[A\n",
            "Loss: 0.0895:   8%|▊         | 18/235 [00:01<00:16, 13.08it/s]\u001b[A\n",
            "Loss: 0.0895:   9%|▊         | 20/235 [00:01<00:16, 13.03it/s]\u001b[A\n",
            "Loss: 0.0692:   9%|▊         | 20/235 [00:01<00:16, 13.03it/s]\u001b[A\n",
            "Loss: 0.0752:   9%|▊         | 20/235 [00:01<00:16, 13.03it/s]\u001b[A\n",
            "Loss: 0.0752:   9%|▉         | 22/235 [00:01<00:16, 12.97it/s]\u001b[A\n",
            "Loss: 0.0876:   9%|▉         | 22/235 [00:01<00:16, 12.97it/s]\u001b[A\n",
            "Loss: 0.0895:   9%|▉         | 22/235 [00:01<00:16, 12.97it/s]\u001b[A\n",
            "Loss: 0.0895:  10%|█         | 24/235 [00:01<00:16, 12.99it/s]\u001b[A\n",
            "Loss: 0.0727:  10%|█         | 24/235 [00:01<00:16, 12.99it/s]\u001b[A\n",
            "Loss: 0.0736:  10%|█         | 24/235 [00:01<00:16, 12.99it/s]\u001b[A\n",
            "Loss: 0.0736:  11%|█         | 26/235 [00:01<00:16, 13.06it/s]\u001b[A\n",
            "Loss: 0.0721:  11%|█         | 26/235 [00:02<00:16, 13.06it/s]\u001b[A\n",
            "Loss: 0.0746:  11%|█         | 26/235 [00:02<00:16, 13.06it/s]\u001b[A\n",
            "Loss: 0.0746:  12%|█▏        | 28/235 [00:02<00:15, 13.12it/s]\u001b[A\n",
            "Loss: 0.0756:  12%|█▏        | 28/235 [00:02<00:15, 13.12it/s]\u001b[A\n",
            "Loss: 0.0765:  12%|█▏        | 28/235 [00:02<00:15, 13.12it/s]\u001b[A\n",
            "Loss: 0.0765:  13%|█▎        | 30/235 [00:02<00:15, 13.13it/s]\u001b[A\n",
            "Loss: 0.0753:  13%|█▎        | 30/235 [00:02<00:15, 13.13it/s]\u001b[A\n",
            "Loss: 0.0711:  13%|█▎        | 30/235 [00:02<00:15, 13.13it/s]\u001b[A\n",
            "Loss: 0.0711:  14%|█▎        | 32/235 [00:02<00:15, 13.12it/s]\u001b[A\n",
            "Loss: 0.0791:  14%|█▎        | 32/235 [00:02<00:15, 13.12it/s]\u001b[A\n",
            "Loss: 0.0700:  14%|█▎        | 32/235 [00:02<00:15, 13.12it/s]\u001b[A\n",
            "Loss: 0.0700:  14%|█▍        | 34/235 [00:02<00:15, 13.12it/s]\u001b[A\n",
            "Loss: 0.0785:  14%|█▍        | 34/235 [00:02<00:15, 13.12it/s]\u001b[A\n",
            "Loss: 0.0678:  14%|█▍        | 34/235 [00:02<00:15, 13.12it/s]\u001b[A\n",
            "Loss: 0.0678:  15%|█▌        | 36/235 [00:02<00:15, 13.13it/s]\u001b[A\n",
            "Loss: 0.0755:  15%|█▌        | 36/235 [00:02<00:15, 13.13it/s]\u001b[A\n",
            "Loss: 0.0716:  15%|█▌        | 36/235 [00:02<00:15, 13.13it/s]\u001b[A\n",
            "Loss: 0.0716:  16%|█▌        | 38/235 [00:02<00:14, 13.24it/s]\u001b[A\n",
            "Loss: 0.0724:  16%|█▌        | 38/235 [00:02<00:14, 13.24it/s]\u001b[A\n",
            "Loss: 0.0673:  16%|█▌        | 38/235 [00:03<00:14, 13.24it/s]\u001b[A\n",
            "Loss: 0.0673:  17%|█▋        | 40/235 [00:03<00:14, 13.37it/s]\u001b[A\n",
            "Loss: 0.0827:  17%|█▋        | 40/235 [00:03<00:14, 13.37it/s]\u001b[A\n",
            "Loss: 0.0778:  17%|█▋        | 40/235 [00:03<00:14, 13.37it/s]\u001b[A\n",
            "Loss: 0.0778:  18%|█▊        | 42/235 [00:03<00:14, 13.32it/s]\u001b[A\n",
            "Loss: 0.0692:  18%|█▊        | 42/235 [00:03<00:14, 13.32it/s]\u001b[A\n",
            "Loss: 0.0790:  18%|█▊        | 42/235 [00:03<00:14, 13.32it/s]\u001b[A\n",
            "Loss: 0.0790:  19%|█▊        | 44/235 [00:03<00:14, 13.24it/s]\u001b[A\n",
            "Loss: 0.0732:  19%|█▊        | 44/235 [00:03<00:14, 13.24it/s]\u001b[A\n",
            "Loss: 0.0785:  19%|█▊        | 44/235 [00:03<00:14, 13.24it/s]\u001b[A\n",
            "Loss: 0.0785:  20%|█▉        | 46/235 [00:03<00:14, 13.13it/s]\u001b[A\n",
            "Loss: 0.0741:  20%|█▉        | 46/235 [00:03<00:14, 13.13it/s]\u001b[A\n",
            "Loss: 0.0712:  20%|█▉        | 46/235 [00:03<00:14, 13.13it/s]\u001b[A\n",
            "Loss: 0.0712:  20%|██        | 48/235 [00:03<00:14, 13.12it/s]\u001b[A\n",
            "Loss: 0.0743:  20%|██        | 48/235 [00:03<00:14, 13.12it/s]\u001b[A\n",
            "Loss: 0.0777:  20%|██        | 48/235 [00:03<00:14, 13.12it/s]\u001b[A\n",
            "Loss: 0.0777:  21%|██▏       | 50/235 [00:03<00:13, 13.26it/s]\u001b[A\n",
            "Loss: 0.0717:  21%|██▏       | 50/235 [00:03<00:13, 13.26it/s]\u001b[A\n",
            "Loss: 0.0690:  21%|██▏       | 50/235 [00:03<00:13, 13.26it/s]\u001b[A\n",
            "Loss: 0.0690:  22%|██▏       | 52/235 [00:03<00:13, 13.22it/s]\u001b[A\n",
            "Loss: 0.0672:  22%|██▏       | 52/235 [00:04<00:13, 13.22it/s]\u001b[A\n",
            "Loss: 0.0734:  22%|██▏       | 52/235 [00:04<00:13, 13.22it/s]\u001b[A\n",
            "Loss: 0.0734:  23%|██▎       | 54/235 [00:04<00:13, 13.33it/s]\u001b[A\n",
            "Loss: 0.0706:  23%|██▎       | 54/235 [00:04<00:13, 13.33it/s]\u001b[A\n",
            "Loss: 0.0803:  23%|██▎       | 54/235 [00:04<00:13, 13.33it/s]\u001b[A\n",
            "Loss: 0.0803:  24%|██▍       | 56/235 [00:04<00:13, 13.29it/s]\u001b[A\n",
            "Loss: 0.0704:  24%|██▍       | 56/235 [00:04<00:13, 13.29it/s]\u001b[A\n",
            "Loss: 0.0729:  24%|██▍       | 56/235 [00:04<00:13, 13.29it/s]\u001b[A\n",
            "Loss: 0.0729:  25%|██▍       | 58/235 [00:04<00:13, 13.14it/s]\u001b[A\n",
            "Loss: 0.0684:  25%|██▍       | 58/235 [00:04<00:13, 13.14it/s]\u001b[A\n",
            "Loss: 0.0836:  25%|██▍       | 58/235 [00:04<00:13, 13.14it/s]\u001b[A\n",
            "Loss: 0.0836:  26%|██▌       | 60/235 [00:04<00:13, 13.02it/s]\u001b[A\n",
            "Loss: 0.0756:  26%|██▌       | 60/235 [00:04<00:13, 13.02it/s]\u001b[A\n",
            "Loss: 0.0806:  26%|██▌       | 60/235 [00:04<00:13, 13.02it/s]\u001b[A\n",
            "Loss: 0.0806:  26%|██▋       | 62/235 [00:04<00:13, 12.70it/s]\u001b[A\n",
            "Loss: 0.0768:  26%|██▋       | 62/235 [00:04<00:13, 12.70it/s]\u001b[A\n",
            "Loss: 0.0814:  26%|██▋       | 62/235 [00:04<00:13, 12.70it/s]\u001b[A\n",
            "Loss: 0.0814:  27%|██▋       | 64/235 [00:04<00:13, 12.92it/s]\u001b[A\n",
            "Loss: 0.0724:  27%|██▋       | 64/235 [00:04<00:13, 12.92it/s]\u001b[A\n",
            "Loss: 0.0781:  27%|██▋       | 64/235 [00:05<00:13, 12.92it/s]\u001b[A\n",
            "Loss: 0.0781:  28%|██▊       | 66/235 [00:05<00:12, 13.10it/s]\u001b[A\n",
            "Loss: 0.0743:  28%|██▊       | 66/235 [00:05<00:12, 13.10it/s]\u001b[A\n",
            "Loss: 0.0749:  28%|██▊       | 66/235 [00:05<00:12, 13.10it/s]\u001b[A\n",
            "Loss: 0.0749:  29%|██▉       | 68/235 [00:05<00:12, 13.30it/s]\u001b[A\n",
            "Loss: 0.0777:  29%|██▉       | 68/235 [00:05<00:12, 13.30it/s]\u001b[A\n",
            "Loss: 0.0711:  29%|██▉       | 68/235 [00:05<00:12, 13.30it/s]\u001b[A\n",
            "Loss: 0.0711:  30%|██▉       | 70/235 [00:05<00:12, 13.28it/s]\u001b[A\n",
            "Loss: 0.0692:  30%|██▉       | 70/235 [00:05<00:12, 13.28it/s]\u001b[A\n",
            "Loss: 0.0715:  30%|██▉       | 70/235 [00:05<00:12, 13.28it/s]\u001b[A\n",
            "Loss: 0.0715:  31%|███       | 72/235 [00:05<00:12, 13.26it/s]\u001b[A\n",
            "Loss: 0.0712:  31%|███       | 72/235 [00:05<00:12, 13.26it/s]\u001b[A\n",
            "Loss: 0.0725:  31%|███       | 72/235 [00:05<00:12, 13.26it/s]\u001b[A\n",
            "Loss: 0.0725:  31%|███▏      | 74/235 [00:05<00:12, 13.33it/s]\u001b[A\n",
            "Loss: 0.0681:  31%|███▏      | 74/235 [00:05<00:12, 13.33it/s]\u001b[A\n",
            "Loss: 0.0710:  31%|███▏      | 74/235 [00:05<00:12, 13.33it/s]\u001b[A\n",
            "Loss: 0.0710:  32%|███▏      | 76/235 [00:05<00:11, 13.35it/s]\u001b[A\n",
            "Loss: 0.0664:  32%|███▏      | 76/235 [00:05<00:11, 13.35it/s]\u001b[A\n",
            "Loss: 0.0696:  32%|███▏      | 76/235 [00:05<00:11, 13.35it/s]\u001b[A\n",
            "Loss: 0.0696:  33%|███▎      | 78/235 [00:05<00:11, 13.29it/s]\u001b[A\n",
            "Loss: 0.0795:  33%|███▎      | 78/235 [00:06<00:11, 13.29it/s]\u001b[A\n",
            "Loss: 0.0729:  33%|███▎      | 78/235 [00:06<00:11, 13.29it/s]\u001b[A\n",
            "Loss: 0.0729:  34%|███▍      | 80/235 [00:06<00:11, 13.35it/s]\u001b[A\n",
            "Loss: 0.0706:  34%|███▍      | 80/235 [00:06<00:11, 13.35it/s]\u001b[A\n",
            "Loss: 0.0717:  34%|███▍      | 80/235 [00:06<00:11, 13.35it/s]\u001b[A\n",
            "Loss: 0.0717:  35%|███▍      | 82/235 [00:06<00:11, 13.35it/s]\u001b[A\n",
            "Loss: 0.0797:  35%|███▍      | 82/235 [00:06<00:11, 13.35it/s]\u001b[A\n",
            "Loss: 0.0681:  35%|███▍      | 82/235 [00:06<00:11, 13.35it/s]\u001b[A\n",
            "Loss: 0.0681:  36%|███▌      | 84/235 [00:06<00:11, 13.25it/s]\u001b[A\n",
            "Loss: 0.0684:  36%|███▌      | 84/235 [00:06<00:11, 13.25it/s]\u001b[A\n",
            "Loss: 0.0739:  36%|███▌      | 84/235 [00:06<00:11, 13.25it/s]\u001b[A\n",
            "Loss: 0.0739:  37%|███▋      | 86/235 [00:06<00:11, 13.27it/s]\u001b[A\n",
            "Loss: 0.0785:  37%|███▋      | 86/235 [00:06<00:11, 13.27it/s]\u001b[A\n",
            "Loss: 0.0717:  37%|███▋      | 86/235 [00:06<00:11, 13.27it/s]\u001b[A\n",
            "Loss: 0.0717:  37%|███▋      | 88/235 [00:06<00:11, 13.35it/s]\u001b[A\n",
            "Loss: 0.0683:  37%|███▋      | 88/235 [00:06<00:11, 13.35it/s]\u001b[A\n",
            "Loss: 0.0703:  37%|███▋      | 88/235 [00:06<00:11, 13.35it/s]\u001b[A\n",
            "Loss: 0.0703:  38%|███▊      | 90/235 [00:06<00:10, 13.45it/s]\u001b[A\n",
            "Loss: 0.0746:  38%|███▊      | 90/235 [00:06<00:10, 13.45it/s]\u001b[A\n",
            "Loss: 0.0686:  38%|███▊      | 90/235 [00:06<00:10, 13.45it/s]\u001b[A\n",
            "Loss: 0.0686:  39%|███▉      | 92/235 [00:06<00:10, 13.54it/s]\u001b[A\n",
            "Loss: 0.0793:  39%|███▉      | 92/235 [00:07<00:10, 13.54it/s]\u001b[A\n",
            "Loss: 0.0764:  39%|███▉      | 92/235 [00:07<00:10, 13.54it/s]\u001b[A\n",
            "Loss: 0.0764:  40%|████      | 94/235 [00:07<00:10, 13.55it/s]\u001b[A\n",
            "Loss: 0.0720:  40%|████      | 94/235 [00:07<00:10, 13.55it/s]\u001b[A\n",
            "Loss: 0.0755:  40%|████      | 94/235 [00:07<00:10, 13.55it/s]\u001b[A\n",
            "Loss: 0.0755:  41%|████      | 96/235 [00:07<00:10, 13.56it/s]\u001b[A\n",
            "Loss: 0.0708:  41%|████      | 96/235 [00:07<00:10, 13.56it/s]\u001b[A\n",
            "Loss: 0.0749:  41%|████      | 96/235 [00:07<00:10, 13.56it/s]\u001b[A\n",
            "Loss: 0.0749:  42%|████▏     | 98/235 [00:07<00:10, 13.50it/s]\u001b[A\n",
            "Loss: 0.0692:  42%|████▏     | 98/235 [00:07<00:10, 13.50it/s]\u001b[A\n",
            "Loss: 0.0693:  42%|████▏     | 98/235 [00:07<00:10, 13.50it/s]\u001b[A\n",
            "Loss: 0.0693:  43%|████▎     | 100/235 [00:07<00:10, 13.50it/s]\u001b[A\n",
            "Loss: 0.0722:  43%|████▎     | 100/235 [00:07<00:10, 13.50it/s]\u001b[A\n",
            "Loss: 0.0645:  43%|████▎     | 100/235 [00:07<00:10, 13.50it/s]\u001b[A\n",
            "Loss: 0.0645:  43%|████▎     | 102/235 [00:07<00:09, 13.47it/s]\u001b[A\n",
            "Loss: 0.0763:  43%|████▎     | 102/235 [00:07<00:09, 13.47it/s]\u001b[A\n",
            "Loss: 0.0688:  43%|████▎     | 102/235 [00:07<00:09, 13.47it/s]\u001b[A\n",
            "Loss: 0.0688:  44%|████▍     | 104/235 [00:07<00:09, 13.47it/s]\u001b[A\n",
            "Loss: 0.0671:  44%|████▍     | 104/235 [00:07<00:09, 13.47it/s]\u001b[A\n",
            "Loss: 0.0769:  44%|████▍     | 104/235 [00:08<00:09, 13.47it/s]\u001b[A\n",
            "Loss: 0.0769:  45%|████▌     | 106/235 [00:08<00:09, 13.52it/s]\u001b[A\n",
            "Loss: 0.0701:  45%|████▌     | 106/235 [00:08<00:09, 13.52it/s]\u001b[A\n",
            "Loss: 0.0793:  45%|████▌     | 106/235 [00:08<00:09, 13.52it/s]\u001b[A\n",
            "Loss: 0.0793:  46%|████▌     | 108/235 [00:08<00:09, 13.47it/s]\u001b[A\n",
            "Loss: 0.0786:  46%|████▌     | 108/235 [00:08<00:09, 13.47it/s]\u001b[A\n",
            "Loss: 0.0650:  46%|████▌     | 108/235 [00:08<00:09, 13.47it/s]\u001b[A\n",
            "Loss: 0.0650:  47%|████▋     | 110/235 [00:08<00:09, 13.50it/s]\u001b[A\n",
            "Loss: 0.0658:  47%|████▋     | 110/235 [00:08<00:09, 13.50it/s]\u001b[A\n",
            "Loss: 0.0680:  47%|████▋     | 110/235 [00:08<00:09, 13.50it/s]\u001b[A\n",
            "Loss: 0.0680:  48%|████▊     | 112/235 [00:08<00:09, 13.41it/s]\u001b[A\n",
            "Loss: 0.0692:  48%|████▊     | 112/235 [00:08<00:09, 13.41it/s]\u001b[A\n",
            "Loss: 0.0717:  48%|████▊     | 112/235 [00:08<00:09, 13.41it/s]\u001b[A\n",
            "Loss: 0.0717:  49%|████▊     | 114/235 [00:08<00:08, 13.47it/s]\u001b[A\n",
            "Loss: 0.0809:  49%|████▊     | 114/235 [00:08<00:08, 13.47it/s]\u001b[A\n",
            "Loss: 0.0761:  49%|████▊     | 114/235 [00:08<00:08, 13.47it/s]\u001b[A\n",
            "Loss: 0.0761:  49%|████▉     | 116/235 [00:08<00:08, 13.49it/s]\u001b[A\n",
            "Loss: 0.0745:  49%|████▉     | 116/235 [00:08<00:08, 13.49it/s]\u001b[A\n",
            "Loss: 0.0720:  49%|████▉     | 116/235 [00:08<00:08, 13.49it/s]\u001b[A\n",
            "Loss: 0.0720:  50%|█████     | 118/235 [00:08<00:08, 13.56it/s]\u001b[A\n",
            "Loss: 0.0687:  50%|█████     | 118/235 [00:08<00:08, 13.56it/s]\u001b[A\n",
            "Loss: 0.0783:  50%|█████     | 118/235 [00:09<00:08, 13.56it/s]\u001b[A\n",
            "Loss: 0.0783:  51%|█████     | 120/235 [00:09<00:08, 13.64it/s]\u001b[A\n",
            "Loss: 0.0679:  51%|█████     | 120/235 [00:09<00:08, 13.64it/s]\u001b[A\n",
            "Loss: 0.0717:  51%|█████     | 120/235 [00:09<00:08, 13.64it/s]\u001b[A\n",
            "Loss: 0.0717:  52%|█████▏    | 122/235 [00:09<00:08, 13.67it/s]\u001b[A\n",
            "Loss: 0.0686:  52%|█████▏    | 122/235 [00:09<00:08, 13.67it/s]\u001b[A\n",
            "Loss: 0.0745:  52%|█████▏    | 122/235 [00:09<00:08, 13.67it/s]\u001b[A\n",
            "Loss: 0.0745:  53%|█████▎    | 124/235 [00:09<00:08, 13.59it/s]\u001b[A\n",
            "Loss: 0.0698:  53%|█████▎    | 124/235 [00:09<00:08, 13.59it/s]\u001b[A\n",
            "Loss: 0.0694:  53%|█████▎    | 124/235 [00:09<00:08, 13.59it/s]\u001b[A\n",
            "Loss: 0.0694:  54%|█████▎    | 126/235 [00:09<00:08, 13.48it/s]\u001b[A\n",
            "Loss: 0.0710:  54%|█████▎    | 126/235 [00:09<00:08, 13.48it/s]\u001b[A\n",
            "Loss: 0.0723:  54%|█████▎    | 126/235 [00:09<00:08, 13.48it/s]\u001b[A\n",
            "Loss: 0.0723:  54%|█████▍    | 128/235 [00:09<00:08, 13.30it/s]\u001b[A\n",
            "Loss: 0.0648:  54%|█████▍    | 128/235 [00:09<00:08, 13.30it/s]\u001b[A\n",
            "Loss: 0.0833:  54%|█████▍    | 128/235 [00:09<00:08, 13.30it/s]\u001b[A\n",
            "Loss: 0.0833:  55%|█████▌    | 130/235 [00:09<00:07, 13.29it/s]\u001b[A\n",
            "Loss: 0.0745:  55%|█████▌    | 130/235 [00:09<00:07, 13.29it/s]\u001b[A\n",
            "Loss: 0.0755:  55%|█████▌    | 130/235 [00:09<00:07, 13.29it/s]\u001b[A\n",
            "Loss: 0.0755:  56%|█████▌    | 132/235 [00:09<00:07, 13.38it/s]\u001b[A\n",
            "Loss: 0.0659:  56%|█████▌    | 132/235 [00:10<00:07, 13.38it/s]\u001b[A\n",
            "Loss: 0.0662:  56%|█████▌    | 132/235 [00:10<00:07, 13.38it/s]\u001b[A\n",
            "Loss: 0.0662:  57%|█████▋    | 134/235 [00:10<00:07, 13.36it/s]\u001b[A\n",
            "Loss: 0.0782:  57%|█████▋    | 134/235 [00:10<00:07, 13.36it/s]\u001b[A\n",
            "Loss: 0.0689:  57%|█████▋    | 134/235 [00:10<00:07, 13.36it/s]\u001b[A\n",
            "Loss: 0.0689:  58%|█████▊    | 136/235 [00:10<00:07, 13.35it/s]\u001b[A\n",
            "Loss: 0.0781:  58%|█████▊    | 136/235 [00:10<00:07, 13.35it/s]\u001b[A\n",
            "Loss: 0.0723:  58%|█████▊    | 136/235 [00:10<00:07, 13.35it/s]\u001b[A\n",
            "Loss: 0.0723:  59%|█████▊    | 138/235 [00:10<00:07, 13.21it/s]\u001b[A\n",
            "Loss: 0.0691:  59%|█████▊    | 138/235 [00:10<00:07, 13.21it/s]\u001b[A\n",
            "Loss: 0.0769:  59%|█████▊    | 138/235 [00:10<00:07, 13.21it/s]\u001b[A\n",
            "Loss: 0.0769:  60%|█████▉    | 140/235 [00:10<00:07, 13.29it/s]\u001b[A\n",
            "Loss: 0.0758:  60%|█████▉    | 140/235 [00:10<00:07, 13.29it/s]\u001b[A\n",
            "Loss: 0.0696:  60%|█████▉    | 140/235 [00:10<00:07, 13.29it/s]\u001b[A\n",
            "Loss: 0.0696:  60%|██████    | 142/235 [00:10<00:06, 13.32it/s]\u001b[A\n",
            "Loss: 0.0707:  60%|██████    | 142/235 [00:10<00:06, 13.32it/s]\u001b[A\n",
            "Loss: 0.0729:  60%|██████    | 142/235 [00:10<00:06, 13.32it/s]\u001b[A\n",
            "Loss: 0.0729:  61%|██████▏   | 144/235 [00:10<00:06, 13.35it/s]\u001b[A\n",
            "Loss: 0.0727:  61%|██████▏   | 144/235 [00:10<00:06, 13.35it/s]\u001b[A\n",
            "Loss: 0.0698:  61%|██████▏   | 144/235 [00:10<00:06, 13.35it/s]\u001b[A\n",
            "Loss: 0.0698:  62%|██████▏   | 146/235 [00:10<00:06, 13.30it/s]\u001b[A\n",
            "Loss: 0.0706:  62%|██████▏   | 146/235 [00:11<00:06, 13.30it/s]\u001b[A\n",
            "Loss: 0.0725:  62%|██████▏   | 146/235 [00:11<00:06, 13.30it/s]\u001b[A\n",
            "Loss: 0.0725:  63%|██████▎   | 148/235 [00:11<00:06, 13.28it/s]\u001b[A\n",
            "Loss: 0.0692:  63%|██████▎   | 148/235 [00:11<00:06, 13.28it/s]\u001b[A\n",
            "Loss: 0.0736:  63%|██████▎   | 148/235 [00:11<00:06, 13.28it/s]\u001b[A\n",
            "Loss: 0.0736:  64%|██████▍   | 150/235 [00:11<00:06, 13.21it/s]\u001b[A\n",
            "Loss: 0.0684:  64%|██████▍   | 150/235 [00:11<00:06, 13.21it/s]\u001b[A\n",
            "Loss: 0.0760:  64%|██████▍   | 150/235 [00:11<00:06, 13.21it/s]\u001b[A\n",
            "Loss: 0.0760:  65%|██████▍   | 152/235 [00:11<00:06, 13.27it/s]\u001b[A\n",
            "Loss: 0.0689:  65%|██████▍   | 152/235 [00:11<00:06, 13.27it/s]\u001b[A\n",
            "Loss: 0.0710:  65%|██████▍   | 152/235 [00:11<00:06, 13.27it/s]\u001b[A\n",
            "Loss: 0.0710:  66%|██████▌   | 154/235 [00:11<00:06, 13.30it/s]\u001b[A\n",
            "Loss: 0.0681:  66%|██████▌   | 154/235 [00:11<00:06, 13.30it/s]\u001b[A\n",
            "Loss: 0.0764:  66%|██████▌   | 154/235 [00:11<00:06, 13.30it/s]\u001b[A\n",
            "Loss: 0.0764:  66%|██████▋   | 156/235 [00:11<00:05, 13.33it/s]\u001b[A\n",
            "Loss: 0.0655:  66%|██████▋   | 156/235 [00:11<00:05, 13.33it/s]\u001b[A\n",
            "Loss: 0.0705:  66%|██████▋   | 156/235 [00:11<00:05, 13.33it/s]\u001b[A\n",
            "Loss: 0.0705:  67%|██████▋   | 158/235 [00:11<00:05, 13.32it/s]\u001b[A\n",
            "Loss: 0.0726:  67%|██████▋   | 158/235 [00:11<00:05, 13.32it/s]\u001b[A\n",
            "Loss: 0.0677:  67%|██████▋   | 158/235 [00:12<00:05, 13.32it/s]\u001b[A\n",
            "Loss: 0.0677:  68%|██████▊   | 160/235 [00:12<00:05, 13.38it/s]\u001b[A\n",
            "Loss: 0.0693:  68%|██████▊   | 160/235 [00:12<00:05, 13.38it/s]\u001b[A\n",
            "Loss: 0.0756:  68%|██████▊   | 160/235 [00:12<00:05, 13.38it/s]\u001b[A\n",
            "Loss: 0.0756:  69%|██████▉   | 162/235 [00:12<00:05, 13.42it/s]\u001b[A\n",
            "Loss: 0.0691:  69%|██████▉   | 162/235 [00:12<00:05, 13.42it/s]\u001b[A\n",
            "Loss: 0.0809:  69%|██████▉   | 162/235 [00:12<00:05, 13.42it/s]\u001b[A\n",
            "Loss: 0.0809:  70%|██████▉   | 164/235 [00:12<00:05, 13.49it/s]\u001b[A\n",
            "Loss: 0.0712:  70%|██████▉   | 164/235 [00:12<00:05, 13.49it/s]\u001b[A\n",
            "Loss: 0.0812:  70%|██████▉   | 164/235 [00:12<00:05, 13.49it/s]\u001b[A\n",
            "Loss: 0.0812:  71%|███████   | 166/235 [00:12<00:05, 13.56it/s]\u001b[A\n",
            "Loss: 0.0705:  71%|███████   | 166/235 [00:12<00:05, 13.56it/s]\u001b[A\n",
            "Loss: 0.0741:  71%|███████   | 166/235 [00:12<00:05, 13.56it/s]\u001b[A\n",
            "Loss: 0.0741:  71%|███████▏  | 168/235 [00:12<00:04, 13.51it/s]\u001b[A\n",
            "Loss: 0.0691:  71%|███████▏  | 168/235 [00:12<00:04, 13.51it/s]\u001b[A\n",
            "Loss: 0.0701:  71%|███████▏  | 168/235 [00:12<00:04, 13.51it/s]\u001b[A\n",
            "Loss: 0.0701:  72%|███████▏  | 170/235 [00:12<00:04, 13.43it/s]\u001b[A\n",
            "Loss: 0.0683:  72%|███████▏  | 170/235 [00:12<00:04, 13.43it/s]\u001b[A\n",
            "Loss: 0.0757:  72%|███████▏  | 170/235 [00:12<00:04, 13.43it/s]\u001b[A\n",
            "Loss: 0.0757:  73%|███████▎  | 172/235 [00:12<00:04, 13.46it/s]\u001b[A\n",
            "Loss: 0.0768:  73%|███████▎  | 172/235 [00:13<00:04, 13.46it/s]\u001b[A\n",
            "Loss: 0.0713:  73%|███████▎  | 172/235 [00:13<00:04, 13.46it/s]\u001b[A\n",
            "Loss: 0.0713:  74%|███████▍  | 174/235 [00:13<00:04, 13.51it/s]\u001b[A\n",
            "Loss: 0.0733:  74%|███████▍  | 174/235 [00:13<00:04, 13.51it/s]\u001b[A\n",
            "Loss: 0.0817:  74%|███████▍  | 174/235 [00:13<00:04, 13.51it/s]\u001b[A\n",
            "Loss: 0.0817:  75%|███████▍  | 176/235 [00:13<00:04, 13.43it/s]\u001b[A\n",
            "Loss: 0.0726:  75%|███████▍  | 176/235 [00:13<00:04, 13.43it/s]\u001b[A\n",
            "Loss: 0.0773:  75%|███████▍  | 176/235 [00:13<00:04, 13.43it/s]\u001b[A\n",
            "Loss: 0.0773:  76%|███████▌  | 178/235 [00:13<00:04, 13.39it/s]\u001b[A\n",
            "Loss: 0.0715:  76%|███████▌  | 178/235 [00:13<00:04, 13.39it/s]\u001b[A\n",
            "Loss: 0.0703:  76%|███████▌  | 178/235 [00:13<00:04, 13.39it/s]\u001b[A\n",
            "Loss: 0.0703:  77%|███████▋  | 180/235 [00:13<00:04, 13.46it/s]\u001b[A\n",
            "Loss: 0.0751:  77%|███████▋  | 180/235 [00:13<00:04, 13.46it/s]\u001b[A\n",
            "Loss: 0.0686:  77%|███████▋  | 180/235 [00:13<00:04, 13.46it/s]\u001b[A\n",
            "Loss: 0.0686:  77%|███████▋  | 182/235 [00:13<00:03, 13.38it/s]\u001b[A\n",
            "Loss: 0.0683:  77%|███████▋  | 182/235 [00:13<00:03, 13.38it/s]\u001b[A\n",
            "Loss: 0.0699:  77%|███████▋  | 182/235 [00:13<00:03, 13.38it/s]\u001b[A\n",
            "Loss: 0.0699:  78%|███████▊  | 184/235 [00:13<00:03, 13.42it/s]\u001b[A\n",
            "Loss: 0.0738:  78%|███████▊  | 184/235 [00:13<00:03, 13.42it/s]\u001b[A\n",
            "Loss: 0.0773:  78%|███████▊  | 184/235 [00:13<00:03, 13.42it/s]\u001b[A\n",
            "Loss: 0.0773:  79%|███████▉  | 186/235 [00:13<00:03, 13.43it/s]\u001b[A\n",
            "Loss: 0.0701:  79%|███████▉  | 186/235 [00:14<00:03, 13.43it/s]\u001b[A\n",
            "Loss: 0.0706:  79%|███████▉  | 186/235 [00:14<00:03, 13.43it/s]\u001b[A\n",
            "Loss: 0.0706:  80%|████████  | 188/235 [00:14<00:03, 13.49it/s]\u001b[A\n",
            "Loss: 0.0758:  80%|████████  | 188/235 [00:14<00:03, 13.49it/s]\u001b[A\n",
            "Loss: 0.0682:  80%|████████  | 188/235 [00:14<00:03, 13.49it/s]\u001b[A\n",
            "Loss: 0.0682:  81%|████████  | 190/235 [00:14<00:03, 13.50it/s]\u001b[A\n",
            "Loss: 0.0681:  81%|████████  | 190/235 [00:14<00:03, 13.50it/s]\u001b[A\n",
            "Loss: 0.0659:  81%|████████  | 190/235 [00:14<00:03, 13.50it/s]\u001b[A\n",
            "Loss: 0.0659:  82%|████████▏ | 192/235 [00:14<00:03, 13.54it/s]\u001b[A\n",
            "Loss: 0.0654:  82%|████████▏ | 192/235 [00:14<00:03, 13.54it/s]\u001b[A\n",
            "Loss: 0.0747:  82%|████████▏ | 192/235 [00:14<00:03, 13.54it/s]\u001b[A\n",
            "Loss: 0.0747:  83%|████████▎ | 194/235 [00:14<00:03, 13.51it/s]\u001b[A\n",
            "Loss: 0.0758:  83%|████████▎ | 194/235 [00:14<00:03, 13.51it/s]\u001b[A\n",
            "Loss: 0.0730:  83%|████████▎ | 194/235 [00:14<00:03, 13.51it/s]\u001b[A\n",
            "Loss: 0.0730:  83%|████████▎ | 196/235 [00:14<00:02, 13.42it/s]\u001b[A\n",
            "Loss: 0.0655:  83%|████████▎ | 196/235 [00:14<00:02, 13.42it/s]\u001b[A\n",
            "Loss: 0.0641:  83%|████████▎ | 196/235 [00:14<00:02, 13.42it/s]\u001b[A\n",
            "Loss: 0.0641:  84%|████████▍ | 198/235 [00:14<00:02, 13.18it/s]\u001b[A\n",
            "Loss: 0.0704:  84%|████████▍ | 198/235 [00:14<00:02, 13.18it/s]\u001b[A\n",
            "Loss: 0.0798:  84%|████████▍ | 198/235 [00:15<00:02, 13.18it/s]\u001b[A\n",
            "Loss: 0.0798:  85%|████████▌ | 200/235 [00:15<00:02, 13.12it/s]\u001b[A\n",
            "Loss: 0.0856:  85%|████████▌ | 200/235 [00:15<00:02, 13.12it/s]\u001b[A\n",
            "Loss: 0.0804:  85%|████████▌ | 200/235 [00:15<00:02, 13.12it/s]\u001b[A\n",
            "Loss: 0.0804:  86%|████████▌ | 202/235 [00:15<00:02, 13.15it/s]\u001b[A\n",
            "Loss: 0.0845:  86%|████████▌ | 202/235 [00:15<00:02, 13.15it/s]\u001b[A\n",
            "Loss: 0.0735:  86%|████████▌ | 202/235 [00:15<00:02, 13.15it/s]\u001b[A\n",
            "Loss: 0.0735:  87%|████████▋ | 204/235 [00:15<00:02, 13.15it/s]\u001b[A\n",
            "Loss: 0.0728:  87%|████████▋ | 204/235 [00:15<00:02, 13.15it/s]\u001b[A\n",
            "Loss: 0.0770:  87%|████████▋ | 204/235 [00:15<00:02, 13.15it/s]\u001b[A\n",
            "Loss: 0.0770:  88%|████████▊ | 206/235 [00:15<00:02, 13.21it/s]\u001b[A\n",
            "Loss: 0.0675:  88%|████████▊ | 206/235 [00:15<00:02, 13.21it/s]\u001b[A\n",
            "Loss: 0.0631:  88%|████████▊ | 206/235 [00:15<00:02, 13.21it/s]\u001b[A\n",
            "Loss: 0.0631:  89%|████████▊ | 208/235 [00:15<00:02, 13.20it/s]\u001b[A\n",
            "Loss: 0.0709:  89%|████████▊ | 208/235 [00:15<00:02, 13.20it/s]\u001b[A\n",
            "Loss: 0.0862:  89%|████████▊ | 208/235 [00:15<00:02, 13.20it/s]\u001b[A\n",
            "Loss: 0.0862:  89%|████████▉ | 210/235 [00:15<00:01, 13.15it/s]\u001b[A\n",
            "Loss: 0.0700:  89%|████████▉ | 210/235 [00:15<00:01, 13.15it/s]\u001b[A\n",
            "Loss: 0.0853:  89%|████████▉ | 210/235 [00:15<00:01, 13.15it/s]\u001b[A\n",
            "Loss: 0.0853:  90%|█████████ | 212/235 [00:15<00:01, 13.21it/s]\u001b[A\n",
            "Loss: 0.0758:  90%|█████████ | 212/235 [00:16<00:01, 13.21it/s]\u001b[A\n",
            "Loss: 0.0822:  90%|█████████ | 212/235 [00:16<00:01, 13.21it/s]\u001b[A\n",
            "Loss: 0.0822:  91%|█████████ | 214/235 [00:16<00:01, 13.24it/s]\u001b[A\n",
            "Loss: 0.0713:  91%|█████████ | 214/235 [00:16<00:01, 13.24it/s]\u001b[A\n",
            "Loss: 0.0728:  91%|█████████ | 214/235 [00:16<00:01, 13.24it/s]\u001b[A\n",
            "Loss: 0.0728:  92%|█████████▏| 216/235 [00:16<00:01, 13.07it/s]\u001b[A\n",
            "Loss: 0.0707:  92%|█████████▏| 216/235 [00:16<00:01, 13.07it/s]\u001b[A\n",
            "Loss: 0.0754:  92%|█████████▏| 216/235 [00:16<00:01, 13.07it/s]\u001b[A\n",
            "Loss: 0.0754:  93%|█████████▎| 218/235 [00:16<00:01, 13.13it/s]\u001b[A\n",
            "Loss: 0.0676:  93%|█████████▎| 218/235 [00:16<00:01, 13.13it/s]\u001b[A\n",
            "Loss: 0.0736:  93%|█████████▎| 218/235 [00:16<00:01, 13.13it/s]\u001b[A\n",
            "Loss: 0.0736:  94%|█████████▎| 220/235 [00:16<00:01, 13.24it/s]\u001b[A\n",
            "Loss: 0.0849:  94%|█████████▎| 220/235 [00:16<00:01, 13.24it/s]\u001b[A\n",
            "Loss: 0.0690:  94%|█████████▎| 220/235 [00:16<00:01, 13.24it/s]\u001b[A\n",
            "Loss: 0.0690:  94%|█████████▍| 222/235 [00:16<00:00, 13.32it/s]\u001b[A\n",
            "Loss: 0.0814:  94%|█████████▍| 222/235 [00:16<00:00, 13.32it/s]\u001b[A\n",
            "Loss: 0.0856:  94%|█████████▍| 222/235 [00:16<00:00, 13.32it/s]\u001b[A\n",
            "Loss: 0.0856:  95%|█████████▌| 224/235 [00:16<00:00, 13.44it/s]\u001b[A\n",
            "Loss: 0.0688:  95%|█████████▌| 224/235 [00:16<00:00, 13.44it/s]\u001b[A\n",
            "Loss: 0.0776:  95%|█████████▌| 224/235 [00:16<00:00, 13.44it/s]\u001b[A\n",
            "Loss: 0.0776:  96%|█████████▌| 226/235 [00:16<00:00, 13.51it/s]\u001b[A\n",
            "Loss: 0.0638:  96%|█████████▌| 226/235 [00:17<00:00, 13.51it/s]\u001b[A\n",
            "Loss: 0.0743:  96%|█████████▌| 226/235 [00:17<00:00, 13.51it/s]\u001b[A\n",
            "Loss: 0.0743:  97%|█████████▋| 228/235 [00:17<00:00, 13.57it/s]\u001b[A\n",
            "Loss: 0.0700:  97%|█████████▋| 228/235 [00:17<00:00, 13.57it/s]\u001b[A\n",
            "Loss: 0.0724:  97%|█████████▋| 228/235 [00:17<00:00, 13.57it/s]\u001b[A\n",
            "Loss: 0.0724:  98%|█████████▊| 230/235 [00:17<00:00, 13.48it/s]\u001b[A\n",
            "Loss: 0.0700:  98%|█████████▊| 230/235 [00:17<00:00, 13.48it/s]\u001b[A\n",
            "Loss: 0.0634:  98%|█████████▊| 230/235 [00:17<00:00, 13.48it/s]\u001b[A\n",
            "Loss: 0.0634:  99%|█████████▊| 232/235 [00:17<00:00, 13.54it/s]\u001b[A\n",
            "Loss: 0.0684:  99%|█████████▊| 232/235 [00:17<00:00, 13.54it/s]\u001b[A\n",
            "Loss: 0.0749:  99%|█████████▊| 232/235 [00:17<00:00, 13.54it/s]\u001b[A\n",
            "Loss: 0.0749: 100%|█████████▉| 234/235 [00:17<00:00, 13.54it/s]\u001b[A\n",
            "Loss: 0.0863: 100%|█████████▉| 234/235 [00:17<00:00, 13.54it/s]\u001b[A\n",
            "  5%|▌         | 5/100 [01:27<27:53, 17.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean loss for Epoch 5: 0.0734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 0.0751:   0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 0.0777:   0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\n",
            "Loss: 0.0777:   1%|          | 2/235 [00:00<00:17, 13.39it/s]\u001b[A\n",
            "Loss: 0.0731:   1%|          | 2/235 [00:00<00:17, 13.39it/s]\u001b[A\n",
            "Loss: 0.0746:   1%|          | 2/235 [00:00<00:17, 13.39it/s]\u001b[A\n",
            "Loss: 0.0746:   2%|▏         | 4/235 [00:00<00:17, 13.43it/s]\u001b[A\n",
            "Loss: 0.0665:   2%|▏         | 4/235 [00:00<00:17, 13.43it/s]\u001b[A\n",
            "Loss: 0.0739:   2%|▏         | 4/235 [00:00<00:17, 13.43it/s]\u001b[A\n",
            "Loss: 0.0739:   3%|▎         | 6/235 [00:00<00:16, 13.57it/s]\u001b[A\n",
            "Loss: 0.0673:   3%|▎         | 6/235 [00:00<00:16, 13.57it/s]\u001b[A\n",
            "Loss: 0.0737:   3%|▎         | 6/235 [00:00<00:16, 13.57it/s]\u001b[A\n",
            "Loss: 0.0737:   3%|▎         | 8/235 [00:00<00:16, 13.51it/s]\u001b[A\n",
            "Loss: 0.0685:   3%|▎         | 8/235 [00:00<00:16, 13.51it/s]\u001b[A\n",
            "Loss: 0.0701:   3%|▎         | 8/235 [00:00<00:16, 13.51it/s]\u001b[A\n",
            "Loss: 0.0701:   4%|▍         | 10/235 [00:00<00:16, 13.51it/s]\u001b[A\n",
            "Loss: 0.0767:   4%|▍         | 10/235 [00:00<00:16, 13.51it/s]\u001b[A\n",
            "Loss: 0.0795:   4%|▍         | 10/235 [00:00<00:16, 13.51it/s]\u001b[A\n",
            "Loss: 0.0795:   5%|▌         | 12/235 [00:00<00:16, 13.43it/s]\u001b[A\n",
            "Loss: 0.0698:   5%|▌         | 12/235 [00:00<00:16, 13.43it/s]\u001b[A\n",
            "Loss: 0.0651:   5%|▌         | 12/235 [00:01<00:16, 13.43it/s]\u001b[A\n",
            "Loss: 0.0651:   6%|▌         | 14/235 [00:01<00:16, 13.28it/s]\u001b[A\n",
            "Loss: 0.0750:   6%|▌         | 14/235 [00:01<00:16, 13.28it/s]\u001b[A\n",
            "Loss: 0.0710:   6%|▌         | 14/235 [00:01<00:16, 13.28it/s]\u001b[A\n",
            "Loss: 0.0710:   7%|▋         | 16/235 [00:01<00:16, 13.33it/s]\u001b[A\n",
            "Loss: 0.0724:   7%|▋         | 16/235 [00:01<00:16, 13.33it/s]\u001b[A\n",
            "Loss: 0.0808:   7%|▋         | 16/235 [00:01<00:16, 13.33it/s]\u001b[A\n",
            "Loss: 0.0808:   8%|▊         | 18/235 [00:01<00:16, 13.38it/s]\u001b[A\n",
            "Loss: 0.0630:   8%|▊         | 18/235 [00:01<00:16, 13.38it/s]\u001b[A\n",
            "Loss: 0.0677:   8%|▊         | 18/235 [00:01<00:16, 13.38it/s]\u001b[A\n",
            "Loss: 0.0677:   9%|▊         | 20/235 [00:01<00:15, 13.46it/s]\u001b[A\n",
            "Loss: 0.0614:   9%|▊         | 20/235 [00:01<00:15, 13.46it/s]\u001b[A\n",
            "Loss: 0.0773:   9%|▊         | 20/235 [00:01<00:15, 13.46it/s]\u001b[A\n",
            "Loss: 0.0773:   9%|▉         | 22/235 [00:01<00:15, 13.51it/s]\u001b[A\n",
            "Loss: 0.0684:   9%|▉         | 22/235 [00:01<00:15, 13.51it/s]\u001b[A\n",
            "Loss: 0.0660:   9%|▉         | 22/235 [00:01<00:15, 13.51it/s]\u001b[A\n",
            "Loss: 0.0660:  10%|█         | 24/235 [00:01<00:15, 13.45it/s]\u001b[A\n",
            "Loss: 0.0704:  10%|█         | 24/235 [00:01<00:15, 13.45it/s]\u001b[A\n",
            "Loss: 0.0766:  10%|█         | 24/235 [00:01<00:15, 13.45it/s]\u001b[A\n",
            "Loss: 0.0766:  11%|█         | 26/235 [00:01<00:15, 13.56it/s]\u001b[A\n",
            "Loss: 0.0693:  11%|█         | 26/235 [00:02<00:15, 13.56it/s]\u001b[A\n",
            "Loss: 0.0729:  11%|█         | 26/235 [00:02<00:15, 13.56it/s]\u001b[A\n",
            "Loss: 0.0729:  12%|█▏        | 28/235 [00:02<00:15, 13.62it/s]\u001b[A\n",
            "Loss: 0.0738:  12%|█▏        | 28/235 [00:02<00:15, 13.62it/s]\u001b[A\n",
            "Loss: 0.0748:  12%|█▏        | 28/235 [00:02<00:15, 13.62it/s]\u001b[A\n",
            "Loss: 0.0748:  13%|█▎        | 30/235 [00:02<00:14, 13.67it/s]\u001b[A\n",
            "Loss: 0.0685:  13%|█▎        | 30/235 [00:02<00:14, 13.67it/s]\u001b[A\n",
            "Loss: 0.0742:  13%|█▎        | 30/235 [00:02<00:14, 13.67it/s]\u001b[A\n",
            "Loss: 0.0742:  14%|█▎        | 32/235 [00:02<00:14, 13.66it/s]\u001b[A\n",
            "Loss: 0.0693:  14%|█▎        | 32/235 [00:02<00:14, 13.66it/s]\u001b[A\n",
            "Loss: 0.0668:  14%|█▎        | 32/235 [00:02<00:14, 13.66it/s]\u001b[A\n",
            "Loss: 0.0668:  14%|█▍        | 34/235 [00:02<00:14, 13.70it/s]\u001b[A\n",
            "Loss: 0.0707:  14%|█▍        | 34/235 [00:02<00:14, 13.70it/s]\u001b[A\n",
            "Loss: 0.0777:  14%|█▍        | 34/235 [00:02<00:14, 13.70it/s]\u001b[A\n",
            "Loss: 0.0777:  15%|█▌        | 36/235 [00:02<00:14, 13.64it/s]\u001b[A\n",
            "Loss: 0.0701:  15%|█▌        | 36/235 [00:02<00:14, 13.64it/s]\u001b[A\n",
            "Loss: 0.0730:  15%|█▌        | 36/235 [00:02<00:14, 13.64it/s]\u001b[A\n",
            "Loss: 0.0730:  16%|█▌        | 38/235 [00:02<00:14, 13.68it/s]\u001b[A\n",
            "Loss: 0.0669:  16%|█▌        | 38/235 [00:02<00:14, 13.68it/s]\u001b[A\n",
            "Loss: 0.0721:  16%|█▌        | 38/235 [00:02<00:14, 13.68it/s]\u001b[A\n",
            "Loss: 0.0721:  17%|█▋        | 40/235 [00:02<00:14, 13.51it/s]\u001b[A\n",
            "Loss: 0.0692:  17%|█▋        | 40/235 [00:03<00:14, 13.51it/s]\u001b[A\n",
            "Loss: 0.0729:  17%|█▋        | 40/235 [00:03<00:14, 13.51it/s]\u001b[A\n",
            "Loss: 0.0729:  18%|█▊        | 42/235 [00:03<00:14, 13.37it/s]\u001b[A\n",
            "Loss: 0.0632:  18%|█▊        | 42/235 [00:03<00:14, 13.37it/s]\u001b[A\n",
            "Loss: 0.0626:  18%|█▊        | 42/235 [00:03<00:14, 13.37it/s]\u001b[A\n",
            "Loss: 0.0626:  19%|█▊        | 44/235 [00:03<00:14, 13.38it/s]\u001b[A\n",
            "Loss: 0.0747:  19%|█▊        | 44/235 [00:03<00:14, 13.38it/s]\u001b[A\n",
            "Loss: 0.0684:  19%|█▊        | 44/235 [00:03<00:14, 13.38it/s]\u001b[A\n",
            "Loss: 0.0684:  20%|█▉        | 46/235 [00:03<00:14, 13.43it/s]\u001b[A\n",
            "Loss: 0.0702:  20%|█▉        | 46/235 [00:03<00:14, 13.43it/s]\u001b[A\n",
            "Loss: 0.0723:  20%|█▉        | 46/235 [00:03<00:14, 13.43it/s]\u001b[A\n",
            "Loss: 0.0723:  20%|██        | 48/235 [00:03<00:13, 13.41it/s]\u001b[A\n",
            "Loss: 0.0662:  20%|██        | 48/235 [00:03<00:13, 13.41it/s]\u001b[A\n",
            "Loss: 0.0683:  20%|██        | 48/235 [00:03<00:13, 13.41it/s]\u001b[A\n",
            "Loss: 0.0683:  21%|██▏       | 50/235 [00:03<00:13, 13.51it/s]\u001b[A\n",
            "Loss: 0.0664:  21%|██▏       | 50/235 [00:03<00:13, 13.51it/s]\u001b[A\n",
            "Loss: 0.0656:  21%|██▏       | 50/235 [00:03<00:13, 13.51it/s]\u001b[A\n",
            "Loss: 0.0656:  22%|██▏       | 52/235 [00:03<00:13, 13.42it/s]\u001b[A\n",
            "Loss: 0.0737:  22%|██▏       | 52/235 [00:03<00:13, 13.42it/s]\u001b[A\n",
            "Loss: 0.0787:  22%|██▏       | 52/235 [00:04<00:13, 13.42it/s]\u001b[A\n",
            "Loss: 0.0787:  23%|██▎       | 54/235 [00:04<00:13, 13.45it/s]\u001b[A\n",
            "Loss: 0.0730:  23%|██▎       | 54/235 [00:04<00:13, 13.45it/s]\u001b[A\n",
            "Loss: 0.0686:  23%|██▎       | 54/235 [00:04<00:13, 13.45it/s]\u001b[A\n",
            "Loss: 0.0686:  24%|██▍       | 56/235 [00:04<00:13, 13.46it/s]\u001b[A\n",
            "Loss: 0.0753:  24%|██▍       | 56/235 [00:04<00:13, 13.46it/s]\u001b[A\n",
            "Loss: 0.0713:  24%|██▍       | 56/235 [00:04<00:13, 13.46it/s]\u001b[A\n",
            "Loss: 0.0713:  25%|██▍       | 58/235 [00:04<00:13, 13.44it/s]\u001b[A\n",
            "Loss: 0.0715:  25%|██▍       | 58/235 [00:04<00:13, 13.44it/s]\u001b[A\n",
            "Loss: 0.0742:  25%|██▍       | 58/235 [00:04<00:13, 13.44it/s]\u001b[A\n",
            "Loss: 0.0742:  26%|██▌       | 60/235 [00:04<00:12, 13.47it/s]\u001b[A\n",
            "Loss: 0.0703:  26%|██▌       | 60/235 [00:04<00:12, 13.47it/s]\u001b[A\n",
            "Loss: 0.0700:  26%|██▌       | 60/235 [00:04<00:12, 13.47it/s]\u001b[A\n",
            "Loss: 0.0700:  26%|██▋       | 62/235 [00:04<00:12, 13.46it/s]\u001b[A\n",
            "Loss: 0.0824:  26%|██▋       | 62/235 [00:04<00:12, 13.46it/s]\u001b[A\n",
            "Loss: 0.0817:  26%|██▋       | 62/235 [00:04<00:12, 13.46it/s]\u001b[A\n",
            "Loss: 0.0817:  27%|██▋       | 64/235 [00:04<00:12, 13.36it/s]\u001b[A\n",
            "Loss: 0.0707:  27%|██▋       | 64/235 [00:04<00:12, 13.36it/s]\u001b[A\n",
            "Loss: 0.0706:  27%|██▋       | 64/235 [00:04<00:12, 13.36it/s]\u001b[A\n",
            "Loss: 0.0706:  28%|██▊       | 66/235 [00:04<00:12, 13.31it/s]\u001b[A\n",
            "Loss: 0.0657:  28%|██▊       | 66/235 [00:04<00:12, 13.31it/s]\u001b[A\n",
            "Loss: 0.0683:  28%|██▊       | 66/235 [00:05<00:12, 13.31it/s]\u001b[A\n",
            "Loss: 0.0683:  29%|██▉       | 68/235 [00:05<00:12, 13.31it/s]\u001b[A\n",
            "Loss: 0.0724:  29%|██▉       | 68/235 [00:05<00:12, 13.31it/s]\u001b[A\n",
            "Loss: 0.0661:  29%|██▉       | 68/235 [00:05<00:12, 13.31it/s]\u001b[A\n",
            "Loss: 0.0661:  30%|██▉       | 70/235 [00:05<00:12, 13.42it/s]\u001b[A\n",
            "Loss: 0.0738:  30%|██▉       | 70/235 [00:05<00:12, 13.42it/s]\u001b[A\n",
            "Loss: 0.0702:  30%|██▉       | 70/235 [00:05<00:12, 13.42it/s]\u001b[A\n",
            "Loss: 0.0702:  31%|███       | 72/235 [00:05<00:12, 13.55it/s]\u001b[A\n",
            "Loss: 0.0746:  31%|███       | 72/235 [00:05<00:12, 13.55it/s]\u001b[A\n",
            "Loss: 0.0751:  31%|███       | 72/235 [00:05<00:12, 13.55it/s]\u001b[A\n",
            "Loss: 0.0751:  31%|███▏      | 74/235 [00:05<00:11, 13.52it/s]\u001b[A\n",
            "Loss: 0.0711:  31%|███▏      | 74/235 [00:05<00:11, 13.52it/s]\u001b[A\n",
            "Loss: 0.0707:  31%|███▏      | 74/235 [00:05<00:11, 13.52it/s]\u001b[A\n",
            "Loss: 0.0707:  32%|███▏      | 76/235 [00:05<00:11, 13.46it/s]\u001b[A\n",
            "Loss: 0.0649:  32%|███▏      | 76/235 [00:05<00:11, 13.46it/s]\u001b[A\n",
            "Loss: 0.0677:  32%|███▏      | 76/235 [00:05<00:11, 13.46it/s]\u001b[A\n",
            "Loss: 0.0677:  33%|███▎      | 78/235 [00:05<00:11, 13.36it/s]\u001b[A\n",
            "Loss: 0.0617:  33%|███▎      | 78/235 [00:05<00:11, 13.36it/s]\u001b[A\n",
            "Loss: 0.0706:  33%|███▎      | 78/235 [00:05<00:11, 13.36it/s]\u001b[A\n",
            "Loss: 0.0706:  34%|███▍      | 80/235 [00:05<00:11, 13.42it/s]\u001b[A\n",
            "Loss: 0.0781:  34%|███▍      | 80/235 [00:06<00:11, 13.42it/s]\u001b[A\n",
            "Loss: 0.0682:  34%|███▍      | 80/235 [00:06<00:11, 13.42it/s]\u001b[A\n",
            "Loss: 0.0682:  35%|███▍      | 82/235 [00:06<00:11, 13.39it/s]\u001b[A\n",
            "Loss: 0.0695:  35%|███▍      | 82/235 [00:06<00:11, 13.39it/s]\u001b[A\n",
            "Loss: 0.0754:  35%|███▍      | 82/235 [00:06<00:11, 13.39it/s]\u001b[A\n",
            "Loss: 0.0754:  36%|███▌      | 84/235 [00:06<00:11, 13.44it/s]\u001b[A\n",
            "Loss: 0.0646:  36%|███▌      | 84/235 [00:06<00:11, 13.44it/s]\u001b[A\n",
            "Loss: 0.0798:  36%|███▌      | 84/235 [00:06<00:11, 13.44it/s]\u001b[A\n",
            "Loss: 0.0798:  37%|███▋      | 86/235 [00:06<00:11, 13.52it/s]\u001b[A\n",
            "Loss: 0.0684:  37%|███▋      | 86/235 [00:06<00:11, 13.52it/s]\u001b[A\n",
            "Loss: 0.0701:  37%|███▋      | 86/235 [00:06<00:11, 13.52it/s]\u001b[A\n",
            "Loss: 0.0701:  37%|███▋      | 88/235 [00:06<00:10, 13.57it/s]\u001b[A\n",
            "Loss: 0.0688:  37%|███▋      | 88/235 [00:06<00:10, 13.57it/s]\u001b[A\n",
            "Loss: 0.0710:  37%|███▋      | 88/235 [00:06<00:10, 13.57it/s]\u001b[A\n",
            "Loss: 0.0710:  38%|███▊      | 90/235 [00:06<00:10, 13.54it/s]\u001b[A\n",
            "Loss: 0.0721:  38%|███▊      | 90/235 [00:06<00:10, 13.54it/s]\u001b[A\n",
            "Loss: 0.0748:  38%|███▊      | 90/235 [00:06<00:10, 13.54it/s]\u001b[A\n",
            "Loss: 0.0748:  39%|███▉      | 92/235 [00:06<00:10, 13.45it/s]\u001b[A\n",
            "Loss: 0.0776:  39%|███▉      | 92/235 [00:06<00:10, 13.45it/s]\u001b[A\n",
            "Loss: 0.0712:  39%|███▉      | 92/235 [00:06<00:10, 13.45it/s]\u001b[A\n",
            "Loss: 0.0712:  40%|████      | 94/235 [00:06<00:10, 13.51it/s]\u001b[A\n",
            "Loss: 0.0724:  40%|████      | 94/235 [00:07<00:10, 13.51it/s]\u001b[A\n",
            "Loss: 0.0717:  40%|████      | 94/235 [00:07<00:10, 13.51it/s]\u001b[A\n",
            "Loss: 0.0717:  41%|████      | 96/235 [00:07<00:10, 13.48it/s]\u001b[A\n",
            "Loss: 0.0714:  41%|████      | 96/235 [00:07<00:10, 13.48it/s]\u001b[A\n",
            "Loss: 0.0673:  41%|████      | 96/235 [00:07<00:10, 13.48it/s]\u001b[A\n",
            "Loss: 0.0673:  42%|████▏     | 98/235 [00:07<00:10, 13.47it/s]\u001b[A\n",
            "Loss: 0.0781:  42%|████▏     | 98/235 [00:07<00:10, 13.47it/s]\u001b[A\n",
            "Loss: 0.0676:  42%|████▏     | 98/235 [00:07<00:10, 13.47it/s]\u001b[A\n",
            "Loss: 0.0676:  43%|████▎     | 100/235 [00:07<00:09, 13.52it/s]\u001b[A\n",
            "Loss: 0.0661:  43%|████▎     | 100/235 [00:07<00:09, 13.52it/s]\u001b[A\n",
            "Loss: 0.0721:  43%|████▎     | 100/235 [00:07<00:09, 13.52it/s]\u001b[A\n",
            "Loss: 0.0721:  43%|████▎     | 102/235 [00:07<00:09, 13.55it/s]\u001b[A\n",
            "Loss: 0.0815:  43%|████▎     | 102/235 [00:07<00:09, 13.55it/s]\u001b[A\n",
            "Loss: 0.0645:  43%|████▎     | 102/235 [00:07<00:09, 13.55it/s]\u001b[A\n",
            "Loss: 0.0645:  44%|████▍     | 104/235 [00:07<00:09, 13.55it/s]\u001b[A\n",
            "Loss: 0.0634:  44%|████▍     | 104/235 [00:07<00:09, 13.55it/s]\u001b[A\n",
            "Loss: 0.0758:  44%|████▍     | 104/235 [00:07<00:09, 13.55it/s]\u001b[A\n",
            "Loss: 0.0758:  45%|████▌     | 106/235 [00:07<00:09, 13.58it/s]\u001b[A\n",
            "Loss: 0.0673:  45%|████▌     | 106/235 [00:07<00:09, 13.58it/s]\u001b[A\n",
            "Loss: 0.0704:  45%|████▌     | 106/235 [00:08<00:09, 13.58it/s]\u001b[A\n",
            "Loss: 0.0704:  46%|████▌     | 108/235 [00:08<00:09, 13.51it/s]\u001b[A\n",
            "Loss: 0.0652:  46%|████▌     | 108/235 [00:08<00:09, 13.51it/s]\u001b[A\n",
            "Loss: 0.0698:  46%|████▌     | 108/235 [00:08<00:09, 13.51it/s]\u001b[A\n",
            "Loss: 0.0698:  47%|████▋     | 110/235 [00:08<00:09, 13.57it/s]\u001b[A\n",
            "Loss: 0.0707:  47%|████▋     | 110/235 [00:08<00:09, 13.57it/s]\u001b[A\n",
            "Loss: 0.0691:  47%|████▋     | 110/235 [00:08<00:09, 13.57it/s]\u001b[A\n",
            "Loss: 0.0691:  48%|████▊     | 112/235 [00:08<00:09, 13.59it/s]\u001b[A\n",
            "Loss: 0.0628:  48%|████▊     | 112/235 [00:08<00:09, 13.59it/s]\u001b[A\n",
            "Loss: 0.0780:  48%|████▊     | 112/235 [00:08<00:09, 13.59it/s]\u001b[A\n",
            "Loss: 0.0780:  49%|████▊     | 114/235 [00:08<00:08, 13.65it/s]\u001b[A\n",
            "Loss: 0.0657:  49%|████▊     | 114/235 [00:08<00:08, 13.65it/s]\u001b[A\n",
            "Loss: 0.0693:  49%|████▊     | 114/235 [00:08<00:08, 13.65it/s]\u001b[A\n",
            "Loss: 0.0693:  49%|████▉     | 116/235 [00:08<00:08, 13.50it/s]\u001b[A\n",
            "Loss: 0.0798:  49%|████▉     | 116/235 [00:08<00:08, 13.50it/s]\u001b[A\n",
            "Loss: 0.0723:  49%|████▉     | 116/235 [00:08<00:08, 13.50it/s]\u001b[A\n",
            "Loss: 0.0723:  50%|█████     | 118/235 [00:08<00:08, 13.44it/s]\u001b[A\n",
            "Loss: 0.0695:  50%|█████     | 118/235 [00:08<00:08, 13.44it/s]\u001b[A\n",
            "Loss: 0.0678:  50%|█████     | 118/235 [00:08<00:08, 13.44it/s]\u001b[A\n",
            "Loss: 0.0678:  51%|█████     | 120/235 [00:08<00:08, 13.49it/s]\u001b[A\n",
            "Loss: 0.0657:  51%|█████     | 120/235 [00:08<00:08, 13.49it/s]\u001b[A\n",
            "Loss: 0.0738:  51%|█████     | 120/235 [00:09<00:08, 13.49it/s]\u001b[A\n",
            "Loss: 0.0738:  52%|█████▏    | 122/235 [00:09<00:08, 13.51it/s]\u001b[A\n",
            "Loss: 0.0663:  52%|█████▏    | 122/235 [00:09<00:08, 13.51it/s]\u001b[A\n",
            "Loss: 0.0632:  52%|█████▏    | 122/235 [00:09<00:08, 13.51it/s]\u001b[A\n",
            "Loss: 0.0632:  53%|█████▎    | 124/235 [00:09<00:08, 13.50it/s]\u001b[A\n",
            "Loss: 0.0644:  53%|█████▎    | 124/235 [00:09<00:08, 13.50it/s]\u001b[A\n",
            "Loss: 0.0684:  53%|█████▎    | 124/235 [00:09<00:08, 13.50it/s]\u001b[A\n",
            "Loss: 0.0684:  54%|█████▎    | 126/235 [00:09<00:08, 13.57it/s]\u001b[A\n",
            "Loss: 0.0682:  54%|█████▎    | 126/235 [00:09<00:08, 13.57it/s]\u001b[A\n",
            "Loss: 0.0698:  54%|█████▎    | 126/235 [00:09<00:08, 13.57it/s]\u001b[A\n",
            "Loss: 0.0698:  54%|█████▍    | 128/235 [00:09<00:07, 13.56it/s]\u001b[A\n",
            "Loss: 0.0637:  54%|█████▍    | 128/235 [00:09<00:07, 13.56it/s]\u001b[A\n",
            "Loss: 0.0632:  54%|█████▍    | 128/235 [00:09<00:07, 13.56it/s]\u001b[A\n",
            "Loss: 0.0632:  55%|█████▌    | 130/235 [00:09<00:07, 13.55it/s]\u001b[A\n",
            "Loss: 0.0689:  55%|█████▌    | 130/235 [00:09<00:07, 13.55it/s]\u001b[A\n",
            "Loss: 0.0639:  55%|█████▌    | 130/235 [00:09<00:07, 13.55it/s]\u001b[A\n",
            "Loss: 0.0639:  56%|█████▌    | 132/235 [00:09<00:07, 13.33it/s]\u001b[A\n",
            "Loss: 0.0650:  56%|█████▌    | 132/235 [00:09<00:07, 13.33it/s]\u001b[A\n",
            "Loss: 0.0661:  56%|█████▌    | 132/235 [00:09<00:07, 13.33it/s]\u001b[A\n",
            "Loss: 0.0661:  57%|█████▋    | 134/235 [00:09<00:07, 13.26it/s]\u001b[A\n",
            "Loss: 0.0756:  57%|█████▋    | 134/235 [00:10<00:07, 13.26it/s]\u001b[A\n",
            "Loss: 0.0587:  57%|█████▋    | 134/235 [00:10<00:07, 13.26it/s]\u001b[A\n",
            "Loss: 0.0587:  58%|█████▊    | 136/235 [00:10<00:07, 13.33it/s]\u001b[A\n",
            "Loss: 0.0689:  58%|█████▊    | 136/235 [00:10<00:07, 13.33it/s]\u001b[A\n",
            "Loss: 0.0714:  58%|█████▊    | 136/235 [00:10<00:07, 13.33it/s]\u001b[A\n",
            "Loss: 0.0714:  59%|█████▊    | 138/235 [00:10<00:07, 13.30it/s]\u001b[A\n",
            "Loss: 0.0636:  59%|█████▊    | 138/235 [00:10<00:07, 13.30it/s]\u001b[A\n",
            "Loss: 0.0619:  59%|█████▊    | 138/235 [00:10<00:07, 13.30it/s]\u001b[A\n",
            "Loss: 0.0619:  60%|█████▉    | 140/235 [00:10<00:07, 13.42it/s]\u001b[A\n",
            "Loss: 0.0641:  60%|█████▉    | 140/235 [00:10<00:07, 13.42it/s]\u001b[A\n",
            "Loss: 0.0665:  60%|█████▉    | 140/235 [00:10<00:07, 13.42it/s]\u001b[A\n",
            "Loss: 0.0665:  60%|██████    | 142/235 [00:10<00:06, 13.36it/s]\u001b[A\n",
            "Loss: 0.0768:  60%|██████    | 142/235 [00:10<00:06, 13.36it/s]\u001b[A\n",
            "Loss: 0.0624:  60%|██████    | 142/235 [00:10<00:06, 13.36it/s]\u001b[A\n",
            "Loss: 0.0624:  61%|██████▏   | 144/235 [00:10<00:06, 13.37it/s]\u001b[A\n",
            "Loss: 0.0618:  61%|██████▏   | 144/235 [00:10<00:06, 13.37it/s]\u001b[A\n",
            "Loss: 0.0612:  61%|██████▏   | 144/235 [00:10<00:06, 13.37it/s]\u001b[A\n",
            "Loss: 0.0612:  62%|██████▏   | 146/235 [00:10<00:06, 13.43it/s]\u001b[A\n",
            "Loss: 0.0621:  62%|██████▏   | 146/235 [00:10<00:06, 13.43it/s]\u001b[A\n",
            "Loss: 0.0718:  62%|██████▏   | 146/235 [00:10<00:06, 13.43it/s]\u001b[A\n",
            "Loss: 0.0718:  63%|██████▎   | 148/235 [00:10<00:06, 13.48it/s]\u001b[A\n",
            "Loss: 0.0651:  63%|██████▎   | 148/235 [00:11<00:06, 13.48it/s]\u001b[A\n",
            "Loss: 0.0746:  63%|██████▎   | 148/235 [00:11<00:06, 13.48it/s]\u001b[A\n",
            "Loss: 0.0746:  64%|██████▍   | 150/235 [00:11<00:06, 13.58it/s]\u001b[A\n",
            "Loss: 0.0674:  64%|██████▍   | 150/235 [00:11<00:06, 13.58it/s]\u001b[A\n",
            "Loss: 0.0744:  64%|██████▍   | 150/235 [00:11<00:06, 13.58it/s]\u001b[A\n",
            "Loss: 0.0744:  65%|██████▍   | 152/235 [00:11<00:06, 13.65it/s]\u001b[A\n",
            "Loss: 0.0690:  65%|██████▍   | 152/235 [00:11<00:06, 13.65it/s]\u001b[A\n",
            "Loss: 0.0694:  65%|██████▍   | 152/235 [00:11<00:06, 13.65it/s]\u001b[A\n",
            "Loss: 0.0694:  66%|██████▌   | 154/235 [00:11<00:05, 13.71it/s]\u001b[A\n",
            "Loss: 0.0714:  66%|██████▌   | 154/235 [00:11<00:05, 13.71it/s]\u001b[A\n",
            "Loss: 0.0654:  66%|██████▌   | 154/235 [00:11<00:05, 13.71it/s]\u001b[A\n",
            "Loss: 0.0654:  66%|██████▋   | 156/235 [00:11<00:05, 13.64it/s]\u001b[A\n",
            "Loss: 0.0747:  66%|██████▋   | 156/235 [00:11<00:05, 13.64it/s]\u001b[A\n",
            "Loss: 0.0692:  66%|██████▋   | 156/235 [00:11<00:05, 13.64it/s]\u001b[A\n",
            "Loss: 0.0692:  67%|██████▋   | 158/235 [00:11<00:05, 13.60it/s]\u001b[A\n",
            "Loss: 0.0654:  67%|██████▋   | 158/235 [00:11<00:05, 13.60it/s]\u001b[A\n",
            "Loss: 0.0638:  67%|██████▋   | 158/235 [00:11<00:05, 13.60it/s]\u001b[A\n",
            "Loss: 0.0638:  68%|██████▊   | 160/235 [00:11<00:05, 13.63it/s]\u001b[A\n",
            "Loss: 0.0751:  68%|██████▊   | 160/235 [00:11<00:05, 13.63it/s]\u001b[A\n",
            "Loss: 0.0707:  68%|██████▊   | 160/235 [00:12<00:05, 13.63it/s]\u001b[A\n",
            "Loss: 0.0707:  69%|██████▉   | 162/235 [00:12<00:05, 13.64it/s]\u001b[A\n",
            "Loss: 0.0643:  69%|██████▉   | 162/235 [00:12<00:05, 13.64it/s]\u001b[A\n",
            "Loss: 0.0641:  69%|██████▉   | 162/235 [00:12<00:05, 13.64it/s]\u001b[A\n",
            "Loss: 0.0641:  70%|██████▉   | 164/235 [00:12<00:05, 13.66it/s]\u001b[A\n",
            "Loss: 0.0700:  70%|██████▉   | 164/235 [00:12<00:05, 13.66it/s]\u001b[A\n",
            "Loss: 0.0709:  70%|██████▉   | 164/235 [00:12<00:05, 13.66it/s]\u001b[A\n",
            "Loss: 0.0709:  71%|███████   | 166/235 [00:12<00:05, 13.66it/s]\u001b[A\n",
            "Loss: 0.0699:  71%|███████   | 166/235 [00:12<00:05, 13.66it/s]\u001b[A\n",
            "Loss: 0.0618:  71%|███████   | 166/235 [00:12<00:05, 13.66it/s]\u001b[A\n",
            "Loss: 0.0618:  71%|███████▏  | 168/235 [00:12<00:04, 13.74it/s]\u001b[A\n",
            "Loss: 0.0764:  71%|███████▏  | 168/235 [00:12<00:04, 13.74it/s]\u001b[A\n",
            "Loss: 0.0631:  71%|███████▏  | 168/235 [00:12<00:04, 13.74it/s]\u001b[A\n",
            "Loss: 0.0631:  72%|███████▏  | 170/235 [00:12<00:04, 13.71it/s]\u001b[A\n",
            "Loss: 0.0728:  72%|███████▏  | 170/235 [00:12<00:04, 13.71it/s]\u001b[A\n",
            "Loss: 0.0680:  72%|███████▏  | 170/235 [00:12<00:04, 13.71it/s]\u001b[A\n",
            "Loss: 0.0680:  73%|███████▎  | 172/235 [00:12<00:04, 13.65it/s]\u001b[A\n",
            "Loss: 0.0705:  73%|███████▎  | 172/235 [00:12<00:04, 13.65it/s]\u001b[A\n",
            "Loss: 0.0705:  73%|███████▎  | 172/235 [00:12<00:04, 13.65it/s]\u001b[A\n",
            "Loss: 0.0705:  74%|███████▍  | 174/235 [00:12<00:04, 13.69it/s]\u001b[A\n",
            "Loss: 0.0708:  74%|███████▍  | 174/235 [00:12<00:04, 13.69it/s]\u001b[A\n",
            "Loss: 0.0704:  74%|███████▍  | 174/235 [00:13<00:04, 13.69it/s]\u001b[A\n",
            "Loss: 0.0704:  75%|███████▍  | 176/235 [00:13<00:04, 13.45it/s]\u001b[A\n",
            "Loss: 0.0723:  75%|███████▍  | 176/235 [00:13<00:04, 13.45it/s]\u001b[A\n",
            "Loss: 0.0726:  75%|███████▍  | 176/235 [00:13<00:04, 13.45it/s]\u001b[A\n",
            "Loss: 0.0726:  76%|███████▌  | 178/235 [00:13<00:04, 13.47it/s]\u001b[A\n",
            "Loss: 0.0666:  76%|███████▌  | 178/235 [00:13<00:04, 13.47it/s]\u001b[A\n",
            "Loss: 0.0688:  76%|███████▌  | 178/235 [00:13<00:04, 13.47it/s]\u001b[A\n",
            "Loss: 0.0688:  77%|███████▋  | 180/235 [00:13<00:04, 13.44it/s]\u001b[A\n",
            "Loss: 0.0719:  77%|███████▋  | 180/235 [00:13<00:04, 13.44it/s]\u001b[A\n",
            "Loss: 0.0669:  77%|███████▋  | 180/235 [00:13<00:04, 13.44it/s]\u001b[A\n",
            "Loss: 0.0669:  77%|███████▋  | 182/235 [00:13<00:03, 13.51it/s]\u001b[A\n",
            "Loss: 0.0806:  77%|███████▋  | 182/235 [00:13<00:03, 13.51it/s]\u001b[A\n",
            "Loss: 0.0634:  77%|███████▋  | 182/235 [00:13<00:03, 13.51it/s]\u001b[A\n",
            "Loss: 0.0634:  78%|███████▊  | 184/235 [00:13<00:03, 13.50it/s]\u001b[A\n",
            "Loss: 0.0660:  78%|███████▊  | 184/235 [00:13<00:03, 13.50it/s]\u001b[A\n",
            "Loss: 0.0616:  78%|███████▊  | 184/235 [00:13<00:03, 13.50it/s]\u001b[A\n",
            "Loss: 0.0616:  79%|███████▉  | 186/235 [00:13<00:03, 13.45it/s]\u001b[A\n",
            "  5%|▌         | 5/100 [01:41<32:13, 20.35s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-53ed8b890293>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprogress_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;31m# Sampling t, epsilon, and diffused image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inference_unet.py\n",
        "\"\"\"\n",
        "Marcelo Gennari do Nascimento, 2022\n",
        "marcelogennari@outlook.com\n",
        "\n",
        "This script performs the sampling given the trained UNet model\n",
        "\"\"\"\n",
        "from tqdm import trange\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Prepare model\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    batch_size = 100\n",
        "    model = ConditionalUNet().to(device)\n",
        "    model.load_state_dict(torch.load(\"unet_mnist.pth\"))\n",
        "    process = DiffusionProcess()\n",
        "\n",
        "    # Sampling\n",
        "    xt = torch.randn(batch_size, 1, 28, 28)\n",
        "    digit_to_sample = torch.Tensor([9]).to(dtype=torch.long).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for t in trange(999, -1, -1):\n",
        "            time = torch.ones(batch_size) * t\n",
        "            et = model(xt.to(device), time.to(device), digit_to_sample)  # predict noise\n",
        "            xt = process.inverse(xt, et.cpu(), t)\n",
        "\n",
        "    labels = [\"Generated Images\"] * 9\n",
        "\n",
        "    for i in range(9):\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "        plt.tight_layout()\n",
        "        plt.imshow(xt[i][0], cmap=\"gray\", interpolation=\"none\")\n",
        "        plt.title(labels[i])\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "chyi8ZK5QhEF",
        "outputId": "f419b69b-2a11-4b27-fcb3-fca52ab8c729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:06<00:00, 163.11it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}